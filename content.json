{"meta":{"title":"韬光养月巴的技术博客","subtitle":"","description":"","author":"韬光养月巴","url":"http://blog.tgyf.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-02-22T13:20:16.531Z","updated":"2020-02-22T12:01:21.685Z","comments":false,"path":"/404.html","permalink":"http://blog.tgyf.com/404.html","excerpt":"","text":""},{"title":"书单","date":"2020-02-22T13:20:16.520Z","updated":"2020-02-22T12:01:21.688Z","comments":false,"path":"books/index.html","permalink":"http://blog.tgyf.com/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-03-04T03:34:15.353Z","updated":"2020-03-04T03:34:15.289Z","comments":false,"path":"about/index.html","permalink":"http://blog.tgyf.com/about/index.html","excerpt":"","text":"欢迎访问我的博客，我会保持不定期更新。 123456789101112131415161718192021222324252627282930313233343536 _______ ______ __ __ _____ /\\_______)\\/_/\\___\\/\\ /\\ /\\ /\\_____\\ \\(___ __\\/) ) ___/\\ \\ \\/ / /( ( ___/ / / / /_/ / ___\\ \\__/ / \\ \\ \\_ ( ( ( \\ \\ \\_/\\__\\\\__/ / / / /_\\ \\ \\ \\ )_) \\/ _// / / / /____/ /_/_/ \\_\\____/ \\/_/ \\/_/ &#123; \"name\": \"韬光养月巴\", \"age\": 30, \"gender\": \"男\", \"profession\": \"Java Developer &amp; Designer\", \"experience\": \"5年\", \"address\": \"四川省成都市\", \"education\": \"本科\", \"github\": \"https://github.com/tgyf\", \"blog\": \"http://blog.tgyf.com\", \"email\": \"back_up[a]foxmail.com\", \"skills\":[ [\"SpringFramework\", \"Netty\", \"Dubbo\", \"Mybatis\"], [\"Html\", \"Javascript\", \"jQuery\", \"CSS\"], [\"Mysql\",\"Orcal\",\"Redis\",\"MongoDB\"], [\"Docker\", \"Swarm\",\"K8s\"], [\"Git\", \"SVN\"], ], \"devTools\":[ [\"IntelliJ IDEA \", \"VisualStudioCode\", \"Notepad++\"], [\"SourceTree\", \"TortoiseSVN\"], [\"Navicat\", \"RedisDesktopManager\",\"Robo3t\"], [\"MobaXterm\",\"Xshell\"] ] &#125;"},{"title":"分类","date":"2020-02-22T13:20:16.515Z","updated":"2020-02-22T13:07:14.116Z","comments":false,"path":"categories/index.html","permalink":"http://blog.tgyf.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-02-22T13:20:16.505Z","updated":"2020-02-22T12:01:21.688Z","comments":true,"path":"links/index.html","permalink":"http://blog.tgyf.com/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-02-22T13:20:16.499Z","updated":"2020-02-22T12:01:21.689Z","comments":false,"path":"repository/index.html","permalink":"http://blog.tgyf.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-02-22T13:20:16.510Z","updated":"2020-02-22T12:01:21.689Z","comments":false,"path":"tags/index.html","permalink":"http://blog.tgyf.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JVM调优到底调什么怎么调?","slug":"Java虚拟机/JVM调优到底调什么怎么调","date":"2020-03-04T14:00:51.177Z","updated":"2020-03-04T14:00:51.177Z","comments":true,"path":"2020/03/04/Java虚拟机/JVM调优到底调什么怎么调/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/JVM%E8%B0%83%E4%BC%98%E5%88%B0%E5%BA%95%E8%B0%83%E4%BB%80%E4%B9%88%E6%80%8E%E4%B9%88%E8%B0%83/","excerpt":"","text":"调优三步曲(发现/分析/解决) 通过监控, 客户, 老板得知问题 分析定位问题 调优解决问题 发现 JVM性能指标 JVM性能指标简单说有三点：CPU、IO、内存 基本检测工具 CPU检测工具 12top, vmstat, ps, jpstop -Hp &lt;pid&gt; IO检测工具 1vmstat,netstat, iostat , pidstat 内存(JVM内存)检测工具 1234567891011jps -lvm 查看当前用户下java应用进程jinfo &lt;pid&gt; 查看进程信息及jvm垃圾回收参数jstat -gcutil &lt;pid&gt; period count jvm统计信息监控jmap -heap &lt;pid&gt; 内存映射工具jhat jstack -l &lt;pid&gt; 堆栈跟踪工具jcmdjvisualvm jconsolejmcgcview gclog图形化查看 分析/解决 情景一：内存泄漏 Java heap space java.lang.OutOfMemoryError:Java heap space Java heap space，Java应用程序创建的对象存放在这片区域，垃圾回收（Garbage Collection）也发生在这块区域。导致该异常通常有：创建大量的对象，层次比较深的递归操作等。 解决方案有两种: 一是优化应用，找到消耗大量内存的地方，然后优化代码或者算法。这种方式比较推荐，但是难度比较大，尤其是在生产环境中出现这种问题，开发人员不能很好的重现问题。 第二种方案是提升Java heap size，这种方式虽然感觉有点治标不治本，但是可行性非常高，操作简单。 对于一般的应用，采用如下方式即可（数字根据自己的需要调整）： -Xms -Set initial Java heap size -Xmx -Set maximum Java heap size 如: java -Xms512m -Xmx1024m JavaApp 如果是在tomcat中，出现的这种问题，解决办法是在{tomcat_dir}/bin/catalina.bat加上一行（内存设置大小根据自己的需要调整）： set CATALINA_OPTS=-Xms512m -Xmx512m 情景二：内存泄漏 PermGen space java.lang.OutOfMemoryError:PermGen space Perm Gen Size（Permanent Generation Size），用来存储被加载的类的定义（class definition）和元数据（metadata），比如：Class Object和Method Object等。这是内存中的一块永久保存区域，JVM的垃圾回收不会触及这块区域。通常在加载一个大项目的时候才会出现该异常。 对于一般的应用，采用如下方式即可（数字根据自己的需要调整）： -XX:PermSize -Set initial PermGen Size. -XX:MaxPermSize -Set the maximum PermGen Size. 如: java -XX:PermSize=64m -XX:MaxPermSize=128m JavaApp 如果是在tomcat中出现这个问题，解决办法是在{tomcat_dir}/bin/catalina.bat中添加如下一行： set CATALINA_OPTS=-server -Xms256m -Xmx1024m -XX:PermSize=512m -XX:MaxPermSize=512m 情景三：内存泄漏 Metaspace java.lang.OutOfMemoryError:Metaspace 在Java8中,将之前PermGen 中的所有内容, 都移到了Metaspace 空间。 例如: class 名称, 字段, 方法, 字节码, 常量池, JIT优化代码, 等等。 -XX:MaxMetaspaceSize=64m 情景三：内存泄漏 GC overhead limit exceeded java.lang.OutOfMemoryError:GC overhead limit exceeded 这个错误会出现在这个场景中：GC占用了多于98%（默认值）的CPU时间却只回收了少于2%（默认值）的堆空间。目的是为了让应用终止，给开发者机会去诊断问题。 一般是应用程序在有限的内存上创建了大量的临时对象或者弱引用对象，从而导致该异常。虽然加大内存可以暂时解决这个问题，但是还是强烈建议去优化代码，后者更加有效。 首先，你可以关闭JVM这个默认的策略：java -XX:-UseGCOverheadLimit JavaApp 其次，你也可以尝试去加大Heap Size：java -Xmx512m JavaApp JVM启动参数 标准参数 参数 参数说明 -version -Dkey=value -Dfile.encoding=UTF-8 用于指定文件编码格式 -Djava.awt.headless=true #Headless模式是系统的一种配置模式。在该模式下，系统缺少了显示设备、键盘或鼠标。 -Djava.library.path=/bin/native 指定非java类包的位置（如：dll，so） -Djava.security.egd=file:/dev/./urandom 使用伪随机数-verbose:class输出jvm载入类的相关信息，当jvm报告说找不到类或者类冲突时可此进行诊断。 -verbose:gc 输出每次GC的相关情况。 -verbose:jni 输出native方法调用的相关情况，一般用于诊断jni调用错误信息。 非标准参数 -X 参数 参数说明 -Xmsn 指定jvm堆的初始大小，默认为物理内存的1/64，最小为1M；可以指定单位，比如k、m，若不指定，则默认为字节。 -Xmxn 指定jvm堆的最大值，默认为物理内存的1/4或者1G，最小为2M；单位与-Xms一致。 -Xmnn 指定jvm堆中年轻代的大小 -Xssn 设置单个线程栈的大小，一般默认为512k。 -Xint 设置jvm以解释模式运行，所有的字节码将被直接执行，而不会编译成本地码。 -Xbatch 关闭后台代码编译，强制在前台编译，编译完成之后才能进行代码执行；默认情况下，jvm在后台进行编译，若没有编译完成，则前台运行代码时以解释模式运行。 -Xbootclasspath:bootclasspath 让jvm从指定路径（可以是分号分隔的目录、jar、或者zip）中加载bootclass，用来替换jdk的rt.jar；若非必要，一般不会用到； -Xbootclasspath/a:path 将指定路径的所有文件追加到默认bootstrap路径中； -Xbootclasspath/p:path 让jvm优先于bootstrap默认路径加载指定路径的所有文件； -Xcheck:jni 对JNI函数进行附加check；此时jvm将校验传递给JNI函数参数的合法性，在本地代码中遇到非法数据时，jmv将报一个致命错误而终止；使用该参数后将造成性能下降，请慎用。 -Xfuture 让jvm对类文件执行严格的格式检查（默认jvm不进行严格格式检查），以符合类文件格式规范，推荐开发人员使用该参数。 -Xnoclassgc 关闭针对class的gc功能；因为其阻止内存回收，所以可能会导致OutOfMemoryError错误，慎用； -Xincgc 开启增量gc（默认为关闭）；这有助于减少长时间GC时应用程序出现的停顿；但由于可能和应用程序并发执行，所以会降低CPU对应用的处理能力。 -Xloggc:file 与-verbose:gc功能类似，只是将每次GC事件的相关情况记录到一个文件中，文件的位置最好在本地，以避免网络的潜在问题。若与verbose命令同时出现在命令行中，则以-Xloggc为准。 扩展参数，非Stable -XX 行为参数 参数 参数说明 -XX:-DisableExplicitGC 禁止调用System.gc()；但jvm的gc仍然有效 -XX:+MaxFDLimit 最大化文件描述符的数量限制 -XX:+ScavengeBeforeFullGC 新生代GC优先于Full GC执行 -XX:+UseGCOverheadLimit 在抛出OOM之前限制jvm耗费在GC上的时间比例 -XX:-UseConcMarkSweepGC 对老生代采用并发标记交换算法进行GC -XX:-UseParallelGC 启用并行GC -XX:-UseParallelOldGC 对Full GC启用并行，当-XX:-UseParallelGC启用时该项自动启用 -XX:-UseSerialGC 启用串行GC -XX:+UseThreadPriorities 启用本地线程优先级 性能调优参数 参数 参数说明 -XX:LargePageSizeInBytes=4m 设置用于Java堆的大页面尺寸 -XX:MaxHeapFreeRatio=70 GC后java堆中空闲量占的最大比例 -XX:MaxNewSize=size 新生成对象能占用内存的最大值 -XX:MaxPermSize=64m 老生代对象能占用内存的最大值 -XX:MinHeapFreeRatio=40 GC后java堆中空闲量占的最小比例 -XX:NewRatio=2 老年代内存容量与新生代内存容量的比例，此处表示新生代为1/3，老年代为2/3。 -XX:SurvivorRatio=3 新生代中eden区和survivor区的比例，此处表示Eden:survivor:survivor=3:1:1，即Eden占新生代2/5。 -XX:NewSize=2.125m 新生代对象生成时占用内存的默认值-XX:PretenureSizeThreshold大于这个设置值(单位：byte)的对象直接在老年代分配。 -XX:MaxTenuringThreshold 对象晋升老年代的年龄阈值（默认为15岁）,如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。(动态对象年龄判定) -XX:ReservedCodeCacheSize=32m 保留代码占用的内存容量 -XX:ThreadStackSize=512 设置线程栈大小，若为0则使用系统默认值 -XX:+UseLargePages 使用大页面内存 调试参数 参数 参数说明 -XX:-CITime 打印消耗在JIT编译的时间 -XX:ErrorFile=./hs_err_pid.log 保存错误日志或者数据到文件中 -XX:-ExtendedDTraceProbes 开启solaris特有的dtrace探针 -XX:HeapDumpPath=./java_pid.hprof 指定导出堆信息时的路径或文件名 -XX:-HeapDumpOnOutOfMemoryError 当首次遭遇OOM时导出此时堆中相关信息 -XX:OnError=&quot;;&quot; 出现致命ERROR之后运行自定义命令 -XX:OnOutOfMemoryError=&quot;;&quot; 当首次遭遇OOM时执行自定义命令 -XX:-PrintClassHistogram 遇到Ctrl-Break后打印类实例的柱状信息，与jmap -histo功能相同 -XX:-PrintConcurrentLocks 遇到Ctrl-Break后打印并发锁的相关信息，与jstack -l功能相同 -XX:-PrintCommandLineFlags 打印在命令行中出现过的标记 -XX:-PrintCompilation 当一个方法被编译时打印相关信息 -XX:-PrintGC 每次GC时打印相关信息 -XX:-PrintGCDetails 每次GC时打印详细信息 -XX:-PrintGCTimeStamps 打印每次GC的时间戳 -XX:-TraceClassLoading 跟踪类的加载信息 -XX:-TraceClassLoadingPreorder 跟踪被引用到的所有类的加载信息 -XX:-TraceClassResolution 跟踪常量池 -XX:-TraceClassUnloading 跟踪类的卸载信息 -XX:-TraceLoaderConstraints 跟踪类加载器约束的相关信息","categories":[{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/tags/JVM/"}]},{"title":"JVM内存模型及垃圾回收","slug":"Java虚拟机/JVM内存模型及垃圾回收","date":"2020-03-04T12:08:31.852Z","updated":"2020-03-04T12:08:31.852Z","comments":true,"path":"2020/03/04/Java虚拟机/JVM内存模型及垃圾回收/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"内存布局 示意图 基本介绍 方法区和堆是所有线程共享的内存区域；而java栈、本地方法栈和程序计数器是运行时线程私有的内存区域。堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用; Java堆（Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 方法区（MethodArea）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 程序计数器（ProgramCounterRegister）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。 JVM栈（JVMStacks）全称Java虚拟机栈（JavaVirtualMachineStacks）与程序计数器一样，也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（StackFrame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 本地方法栈（NativeMethodStacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。 类生命周期 类生命周期(内存中) 加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象。 连接，连接又包含三块内容：验证、准备、解析。 1231）验证，文件格式、元数据、字节码、符号引用验证；2）准备，为类的静态变量分配内存，并将其初始化为默认值；3）解析，把类中的符号引用转换为直接引用； 初始化，为类的静态变量赋予正确的初始值。 使用，new出对象程序中使用。 卸载，执行垃圾回收。 堆及垃圾回收 堆及垃圾回收（空间使用方式） 整个堆大小=年轻代大小+年老代大小+持久代大小； 年轻代分三个区。一个Eden区，两个Survivor区(一般而言)。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从 第 一 个S u r v i v o r区 复 制 过 来 的 并 且 此 时 还 存 活 的 对 象，将被复制“年 老 区( Te n u r e d )”；-XX:PretenureSizeThreshold即对象的大小大于此值，就会绕过新生代，直接在老年代分配； 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象； 持久代:用于存放静态文件，如今Java类、方法等。-XX:MaxPermSize（JDK8去除了永久代，引入了元空间Metaspace，-XX:MaxMetaspaceSize=64m） 垃圾回收算法 引用计数 比较古老的回收算法。 原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。 标记-清除（Mark-Sweep） 此算法执行分两阶段。 第一阶段从引用根节点开始标记所有被引用的对象 第二阶段遍历整个堆，把未标记的对象清除 此算法需要暂停整个应用，同时，会产生内存碎片。碎片太多可能引发另一次GC； 复制（Copying） 此算法把内存空间划为两个相等的区域，每次只使用其中一个区域。 垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。 此方法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。 当然，此算法的缺点也是很明显的，就是需要两倍内存空间。 4. 标记-整理（Mark-Compact） 此算法结合了“标记-清除”和“复制”两个算法的优点。 也是分两阶段: 第一阶段从根节点开始标记所有被引用对象， 第二阶段遍历整个堆，清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。 此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。 垃圾回收性能指标 吞吐量（用户时间占比） 1吞吐量（Throughput）=运行用户代码时间/（运行用户代码时间+垃圾收集时间） 系统停顿时间（用户时间延迟） 1GC造成的用户线程最长停顿时间 垃圾回收器（算法实现） Serial串行收集器 特点: 仅仅使用单线程进行内存回收； 它是独占式的内存回收； 进行内存回收时,暂停所有的工作线程(“Stop-The-World”)； 使用复制算法； 适合CPU等硬件一般的场合； 到JDK1.7为止，是JVMClient模式下默认的新生代收集器； 设置参数: 1-XX:+UseSerialGC指定使用新生代SerialGC和老年代SerialOldGC SerialOld收集器（单线程独占，标记整理算法） 特点: 同新生代Serial收集器一样，单线程、独占式的垃圾收集器； 使用“标记-整理”算法； 通常老年代内存回收比新生代内存回收要更长时间，所以可能会使应用程序停顿较长时间； 设置参数: 123-XX:+UseSerialGC新生代、老年代都使用串行GC；（分别是Serial和SerialOld）-XX:+UseParNewGC新生代使用ParNew，老年代使用SerialOld；-XX:+UseParallelGC新生代使用Parallel，老年代使用SerialOld； ParNew收集器，并行GC 特点: Serial的多线程版本； 使用复制算法； 垃圾回收时，应用程序仍会暂停，只不过由于是多线程回收，在多核CPU上，回收效率会高于串行GC。反之在单核CPU，效率会不如串行GC； 设置参数: 123-XX:+UseParNewGC新生代使用ParNew，老年代使用SerialOld；-XX:+UseConcMarkSweepGC新生代使用ParNew，老年代使用CMS；-XX:ParallelGCThreads=n指定ParNew收集器工作时的收集线程数，当CPU核数小于8时，默认开启的线程数等于CPU数量，当高于8时，可使用公式：3+((5*CPU_count)/8)。 在JVMServer模式下首选的新生代收集器，其中一个很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器(并发GC)配合工作。 ParNew收集器在单CPU环境中绝对不会有比Serial收集器更好的效果。 Parallel收集器 特点: 同ParNew回收器一样，不同的地方在于，它非常关注系统的吞吐量(通过参数控制)； 使用复制算法； 支持自适应的GC调节策略； 设置参数: 12345-XX:+UseParallelGC新生代使用Parallel，老年代使用SerialOld；-XX:+UseParallelOldGC新生代使用Parallel，老年代使用ParallelOld；-XX:MaxGCPauseMillis=n设置内存回收的最大停顿时间，单位ms；-XX:GCTimeRatio=n设置吞吐量的大小，假设值为n(在0-100之间)，那么系统将花费不超过1/(n+1)的时间用于内存回收。默认值为99，就是允许最大1%的垃圾收集时间；-XX:+UseAdaptiveSizePolicy自适应GC策略的开关参数。 ParallelOld收集器 特点: 关注吞吐量的老年代并发收集器； 使用“标记-整理”算法； 设置参数: 1-XX:+UseParallelOldGC新生代使用Parallel，老年代使用ParallelOld。这个收集器是在JDK1.6中才开始提供，在此之前，如果新生代选择了Parallel收集器，老年代除了SerialOld收集器外别无选择。 CMS收集器（Concurrent Mark Sweep） 特点: 非独占式的老年代并发收集器，大部分时候应用程序不会停止运行；–使用“标记-清除”算法，因此回收后会有内存碎片，可设置参数进行内存碎片的压缩整理； 与Parallel和ParallelOld不同，CMS主要关注系统停顿时间； 缺点: 对CPU资源敏感； 无法处理浮动垃圾（FloatingGarbage）； 内存碎片问题 设置参数: 12345678-XX:-CMSPrecleaningEnabled关闭预清理，默认在并发标记后会有一个预清理的操作；-XX:+UseConcMarkSweepGC新生代使用ParNew，老年代使用CMS-XX:ConcGCThreads=n设置并发线程数；（早期版本是-XX:ParallelCMSThreads=n）-XX:CMSInitiatingOccupancyFraction=n指定老年代回收阀值，默认值为68；-XX:+UseCMSCompactAtFullCollection开启内存碎片整理；-XX:CMSFullGCsBeforeCompation=n指定进行多少次CMS垃圾回收后再进行一次内存压缩；-XX:+CMSParallelRemarkEnabled在使用UseParNewGC参数的情况下，尽量减少mark(标记)的时间；-XX:+UseCMSInitiatingOccupancyOnly表示只有达到阀值时才进行CMS垃圾回收 G1 取代了CMS 由于G1的出现，CMS在Java9中已被废弃；http://openjdk.java.net/jeps/291 G1（GarbageFirst）是一个横跨新生代和老年代的垃圾回收器。实际上，它已经打乱了前面所说的堆结构，直接将堆分成极其多个区域。每个区域都可以充当Eden区、Survivor区或者老年代中的一个。它采用的是标记-压缩算法(标记-清除-整理)，所以不会产生内存碎片。而且和CMS一样都能够在应用程序运行过程中并发地进行垃圾回收。 G1是逻辑分代，物理不分代 除此之外不仅逻辑分代，而且物理分代 G1能够针对每个细分的区域来进行垃圾回收。在选择进行垃圾回收的区域时，它会优先回收死亡对象较多的区域。这也是G1名字的由来。 https://blog.csdn.net/baiye_xing/article/details/73743395 关于G1的细节，如果想了解得更多，可以参考如下资料： http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html https://www.zhihu.com/question/50398881/answer/120831226 ZGC “Zero”零暂停垃圾回收器暂停时间不超过10ms 参考如下资料： http://openjdk.java.net/projects/zgc/ 垃圾回收器组合 查看命令 1java -XX:+PrintCommandLineFlags -version 在网上找了张图，这样可以直观的展示出他们是怎样组合的. 上图展示了JDK1.7+后，Hotspot JVM的所有垃圾收集器以及它们适用的“代”,适合新生代的垃圾收集器有：Serial、ParNew、Parallel Scavenge、G1。适合年老代的垃圾收集器有：CMS、Serial Old、Parallel Old、G1。它们之间的组合关系如上图连线（粗线相连的是最佳组合），其中G1是JDK1.7 Update14这个版本中正式提供的商业收集器，它可以同时适用于新生代和年老代。 组合相关JVM参数，如图： 第一个组合：Serial + Serial Old Serial作为年轻代回收器和Serial Old垃圾回收器(JDK1.3版本之前)作为老年代回收器。在JDK1.3版本之前是唯一选择，现在基本不用，因为是单进程收集器，没有发挥出现在多核并行处理的优势。 第二个组合：ParNew + CMS ParNew作为年轻代回收器，CMS作为老年代回收器,一般需要手动指定，参数是： -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 因为现在jdk7,8默认不是使用这个策略。而是使用的下面的Parallel Scavenge + Parallel Old。其基本收集原理和下面的Parallel Scavenge + Parallel Old没有区别，区别在于Parallel Scavenge和 Parallel Old有自适应调节策略，直接可以适应最大吞吐量。但忽略了停顿时间，不适用于要求用户体验的场景，个别请求可能等待时间较长。而ParNew + CMS主要场景是注重控制单次回收停顿时间。 第三个组合：Parallel Scavenge + Parallel Old JDK6版本之后引入，Parallel Scavenge作为年轻代回收器，Parallel Old作为老年代回收器，在JDK6之前，Parallel Scavenge只能适配Serial Old，现在是JDK7,JDK8的默认组合。特点上面说了就是适应最大吞吐量。 第四个组合：G1回收器 G1回收器，JDK7出现，JDK9之后的默认回收器，老年代和年轻代都可以回收，特点是直接对停顿时间进行设置。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/tags/JVM/"}]},{"title":"SpringCloud框架原理","slug":"Java框架/SpringCloud/SpringCloud框架原理","date":"2020-03-04T07:52:58.339Z","updated":"2020-03-04T07:52:58.339Z","comments":true,"path":"2020/03/04/Java框架/SpringCloud/SpringCloud框架原理/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E6%A1%86%E6%9E%B6/SpringCloud/SpringCloud%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/","excerpt":"","text":"Spring Cloud是一个全家桶式的技术栈，包含了很多组件。本文先从其最核心的几个组件入手，来剖析一下其底层的工作原理。 核心组件 Eureka Feign Ribbon Hystrix Zuul 假设的一个业务场景 直接说他们的原理太空泛了，所以这里我假设了一个电商的业务场景.就把他最核心那个实现支付订单的功能拿出来说一下. 业务流程： 创建一个订单之后，如果用户立刻支付了这个订单，我们需要将订单状态更新为“已支付” 扣减相应的商品库存 通知仓储中心，进行发货 给用户的这次购物增加相应的积分 针对上述流程，我们需要有订单服务、库存服务、仓储服务、积分服务. 整体思路： 用户针对一个订单完成支付之后，就会去找订单服务，更新订单状态（标记为已支付） 订单服务调用库存服务，扣减库存并完成相应功能 订单服务调用仓储服务，通知仓储发货并完成相应功能 订单服务调用积分服务，为用户增加积分并完成相应功能 Spring Cloud微服务架构各组件协作与作用 核心组件：Eureka Eureka是微服务架构中的注册中心，专门负责服务的注册与发现。 说白了，就是告诉Eureka Server，自己在哪台机器上，监听着哪个端口。而Eureka Server是一个注册中心，里面有一个注册表，保存了各服务所在的机器和端口号 订单服务里也有一个Eureka Client组件，这个Eureka Client组件会找Eureka Server问一下：库存服务在哪台机器啊？监听着哪个端口啊？仓储服务呢？积分服务呢？然后就可以把这些相关信息从Eureka Server的注册表中拉取到自己本地缓存起来。 这时如果订单服务想要调用库存服务，不就可以找自己本地的Eureka Client问一下库存服务在哪台机器？监听哪个端口吗？收到响应后，紧接着就可以发送一个请求过去，调用库存服务扣减库存的那个接口！同理，如果订单服务要调用仓储服务、积分服务，也是如法炮制。 总结一下： Eureka Client：负责将这个服务的信息注册到Eureka Server中 Eureka Server：注册中心，里面有一个注册表，保存了各个服务所在的机器和端口号 核心组件：Feign Feign Client会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起靕求、获取响应、解析响应 Feign的一个关键机制就是使用了动态代理。 首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理 接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心 Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址 最后针对这个地址，发起请求、解析响应 核心组件：Ribbon Ribbon的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上. Ribbon的负载均衡默认使用的最经典的Round Robin轮询算法。这是啥？简单来说，就是如果订单服务对库存服务发起10次请求，那就先让你请求第1台机器、然后是第2台机器、第3台机器、第4台机器、第5台机器，接着再来—个循环，第1台机器、第2台机器…以此类推。 此外，Ribbon是和Feign以及Eureka紧密协作，完成工作的，具体如下： 首先Ribbon会从 Eureka Client里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。 然后Ribbon就可以使用默认的Round Robin算法，从中选择一台机器 Feign就会针对这台机器，构造并发起请求。 核心组件：Hystrix Hystrix相当于Springcloud中的保险，作用是隔离、熔断以及降级，避免因为某些服务的不可用导致服务雪崩问题. 业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务自己最多只有100个线程可以处理请求，然后呢，积分服务不幸的挂了，每次订单服务调用积分服务的时候，都会卡住几秒钟，然后抛出—个超时异常。 这样会导致什么问题？ 如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分服务这块。导致订单服务没有一个线程可以处理请求 然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了 这个就是微服务架构中恐怖的服务雪崩问题 服务雪崩问题如何解决？ Hystrix会搞很多个小小的线程池，比如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池。每个线程池里的线程就仅仅用于请求那个服务。 打个比方：现在很不幸，积分服务挂了，会咋样？ 当然会导致订单服务里的那个用来调用积分服务的线程都卡死不能工作了啊！但是由于订单服务调用库存服务、仓储服务的这两个线程池都是正常工作的，所以这两个服务不会受到任何影响。 这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！ 那人家又说，兄弟，积分服务挂了你就熔断，好歹你干点儿什么啊！别啥都不干就直接返回啊？没问题，咱们就来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。 核心组件：Zuul Zuul，也就是微服务网关，这个组件是负责网络路由的. 假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！ 上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。 而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。 总结 Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务","categories":[{"name":"Java框架","slug":"Java框架","permalink":"http://blog.tgyf.com/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/categories/SpringCloud/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/tags/SpringCloud/"}]},{"title":"MQ总结：（六）如果写一个消息队列，应该怎样考虑?","slug":"Middleware/MQ总结：（六）如果写一个消息队列，应该怎样考虑","date":"2020-03-04T06:45:47.084Z","updated":"2020-03-04T06:45:47.084Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（六）如果写一个消息队列，应该怎样考虑/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E5%85%AD%EF%BC%89%E5%A6%82%E6%9E%9C%E5%86%99%E4%B8%80%E4%B8%AA%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%8C%E5%BA%94%E8%AF%A5%E6%80%8E%E6%A0%B7%E8%80%83%E8%99%91/","excerpt":"","text":"很多时候我们都没考虑过这样的问题，因为平时的工作中除非是框架部门的，不然大多数时候我们都是用消息队列，而不是去搞消息队列中间件的开发. 之所以有这篇思考性的文章，主要是之前由于之前去面试一家公司被问到怎样去设计一个mybatis的框架.其实这类问题都是可以发散的，比如还可以思考怎样去设计spring框架、dubbo框架、netty框架、springcloud框架等等. 其实，说白了就是对比几个同类型产品，技术的基本原理，核心组成部分，基本架构构成，然后参照他们拿出一个系统设计出来的思路. 设计考虑的几个方向 可伸缩性 就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -&gt; topic -&gt; partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？ 数据落盘 落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。 可用性 参考一下kafka的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker挂了重新选举leader即可对外服务。 数据零丢失 参考kafka数据零丢失方案","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（五）消息队列里产生积压怎么解决？","slug":"Middleware/MQ总结：（五）消息队列里产生积压怎么解决","date":"2020-03-04T06:18:17.269Z","updated":"2020-03-04T06:18:17.269Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（五）消息队列里产生积压怎么解决/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%BA%94%EF%BC%89%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%87%8C%E4%BA%A7%E7%94%9F%E7%A7%AF%E5%8E%8B%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3/","excerpt":"","text":"消息积压常见的问题 如何解决消息队列的延时以及过期失效问题？ 消息队列满了以后该怎么处理？ 有几百万消息持续积压几小时，怎么解决？ 消息积压情景再现 假设一个场景，我们现在消费端出故障了，然后大量消息在mq里积压，出现生产事故了. 场景一:大量消息在mq里积压了几个小时了还没解决 几千万条数据在MQ里积压了七八个小时，从下午4点多，积压到了晚上很晚，10点多，11点多 这个时候要不然就是修复consumer的问题，让他恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。 一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条，1000多万条 所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来 一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下： 先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉 新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据 这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息 场景二:超过rabbitmq设置过期时间（TTL）数据直接被清理掉 这个情况下，就不是说要增加consumer消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。 这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。 假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次 场景三:大量消息在mq里积压长时间都没处理掉，导致mq快写满了 临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个场景的方案，到了晚上再补数据吧。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（四）从消息队列里拿到的数据按顺序执行怎么保证？","slug":"Middleware/MQ总结：（四）从消息队列里拿到的数据按顺序执行怎么保证","date":"2020-03-04T05:57:17.413Z","updated":"2020-03-04T05:57:17.414Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（四）从消息队列里拿到的数据按顺序执行怎么保证/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E5%9B%9B%EF%BC%89%E4%BB%8E%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%87%8C%E6%8B%BF%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8C%89%E9%A1%BA%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81/","excerpt":"","text":"假设的一个消息的顺序性情景 要做一个mysql binlog同步的系统，在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么. rabbitmq消息的顺序性 rabbitmq错乱的场景 一个queue，多个consumer. rabbitmq如何保证消息的顺序性？ 拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理. kafka消息的顺序性 kafka错乱的场景 一个topic，一个partition，一个consumer，内部多线程. kafka如何保证消息的顺序性？ 一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（三）发到消息队列里面的数据不见了怎么办?","slug":"Middleware/MQ总结：（三）发到消息队列里面的数据不见了怎么办","date":"2020-03-04T05:45:36.942Z","updated":"2020-03-04T05:45:36.942Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（三）发到消息队列里面的数据不见了怎么办/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%B8%89%EF%BC%89%E5%8F%91%E5%88%B0%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%87%8C%E9%9D%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E8%A7%81%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E/","excerpt":"","text":"用mq有个基本原则：数据不能多一条，也不能少一条. 不能多，就是重复消费和幂等性问题. 不能少，就是说这数据别搞丢了. 丢数据的情景 丢数据，mq大体一般分为三种： 要么是我们把消息送达mq的时候弄丢了 要么是mq自己弄丢了 要么是我们消费mq的时候弄丢了 rabbitmq丢数据的三种情景 生产者弄丢了数据 生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。 此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。 所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。 事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。 所以一般在生产者这块避免数据丢失，都是用confirm机制的。 rabbitmq弄丢了数据 就是rabbitmq自己弄丢了数据，这个你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。 设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。 而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。 消费端弄丢了数据 rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。 这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。 kafka丢数据的情景 消费端弄丢了数据 唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。 这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。 生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。 然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了 kafka弄丢了数据 这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。 生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了 所以此时一般是要求起码设置如下4个参数： 给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本 在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧 在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了 在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了 我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失 生产者会不会弄丢数据 如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（一）如果MQ挂了怎么办?","slug":"Middleware/MQ总结：（一）如果MQ挂了怎么办","date":"2020-03-04T05:08:46.039Z","updated":"2020-03-04T05:08:46.039Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（一）如果MQ挂了怎么办/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%B8%80%EF%BC%89%E5%A6%82%E6%9E%9CMQ%E6%8C%82%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E/","excerpt":"","text":"如何保证消息队列的高可用？ 如果MQ挂了，导致几个小时系统不可用，公司损失几千万，Team背锅，你闹的祸，你老大帮你一起背锅. 所以说，在非常核心的系统里，一定要考虑引入MQ所导致系统可用性降低的问题. RabbitMQ的高可用性 Rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式. RabbitMQ – 单机模式 就是demo级别的，一般就是你本地启动了玩玩儿的，用于本地开发环境，没人在生产环境用单机模式. RabbitMQ – 普通集群模式 就是在多台机器上启动多个rabbitmq实例，每个机器启动一个.但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据.完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来. 缺点： 这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群.因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈. 如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据. 总结： 所以综上所述这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作. RabbitMQ – 镜像集群模式 这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步. 优点： 你任何一个机器宕机了，没事儿，别的机器都可以用. 缺点： 第一 这个性能开销太大了，消息同步所有机器，导致网络带宽压力和消耗很重！ 第二 这么玩，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue. 怎么开启镜像集群模式? rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了. kafka的高可用性 kafka最基本的架构认识 多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据. 这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据. 实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据. kafka的HA机制 kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言. kafka 0.8以后，提供了HA机制，就是replica副本机制.每个partition的数据都会同步到吉他机器上，形成自己的多个replica副本.然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower.写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可.只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题.kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性. 就有所谓的高可用性了，因为如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可.这就有所谓的高可用性了. 写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据.一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者.（当然，这只是其中一种模式，还可以适当调整这个行为） 消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到.","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"LinkedList源码分析","slug":"Java基础/LinkedList源码分析","date":"2020-03-04T05:02:08.647Z","updated":"2020-03-04T05:02:08.648Z","comments":true,"path":"2020/03/04/Java基础/LinkedList源码分析/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E5%9F%BA%E7%A1%80/LinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"LinkedList介绍 LinkedList 是 Java 集合框架中一个重要的实现，其底层采用的双向链表结构.和 ArrayList 一样，LinkedList 也支持空值和重复值.由于 LinkedList 基于链表实现，存储元素过程中，无需像 ArrayList 那样进行扩容.但有得必有失，LinkedList 存储元素的节点需要额外的空间存储前驱和后继的引用.另一方面，LinkedList 在链表头部和尾部插入效率比较高，但在指定位置进行插入时，效率一般.原因是，在指定位置插入需要定位到该位置处的节点，此操作的时间复杂度为O(N).最后，LinkedList 是非线程安全的集合类，并发环境下，多个线程同时操作 LinkedList，会引发不可预知的错误. 继承体系 LinkedList 的继承体系较为复杂，继承自 AbstractSequentialList，同时又实现了 List 和 Deque 接口.继承体系图如下: LinkedList 继承自 AbstractSequentialList，AbstractSequentialList 又是什么呢？从实现上，AbstractSequentialList 提供了一套基于顺序访问的接口.通过继承此类，子类仅需实现部分代码即可拥有完整的一套访问某种序列表（比如链表）的接口.深入源码，AbstractSequentialList 提供的方法基本上都是通过 ListIterator 实现的，比如： 123456789101112131415161718public E get(int index) &#123; try &#123; return listIterator(index).next(); &#125; catch (NoSuchElementException exc) &#123; throw new IndexOutOfBoundsException(\"Index: \"+index); &#125;&#125;public void add(int index, E element) &#123; try &#123; listIterator(index).add(element); &#125; catch (NoSuchElementException exc) &#123; throw new IndexOutOfBoundsException(\"Index: \"+index); &#125;&#125;// 留给子类实现public abstract ListIterator&lt;E&gt; listIterator(int index); 所以只要继承类实现了 listIterator 方法，它不需要再额外实现什么即可使用.对于随机访问集合类一般建议继承 AbstractList 而不是 AbstractSequentialList.LinkedList 和其父类一样，也是基于顺序访问.所以 LinkedList 继承了 AbstractSequentialList，但 LinkedList 并没有直接使用父类的方法，而是重新实现了一套的方法. 另外，LinkedList 还实现了 Deque (double ended queue)，Deque 又继承自 Queue 接口.这样 LinkedList 就具备了队列的功能.比如，我们可以这样使用： 1Queue&lt;T&gt; queue = new LinkedList&lt;&gt;(); 除此之外，我们基于 LinkedList 还可以实现一些其他的数据结构，比如栈，以此来替换 Java 集合框架中的 Stack 类（该类实现的不好，《Java 编程思想》一书的作者也对此类进行了吐槽）. 关于 LinkedList 继承体系先说到这，下面进入源码分析部分. 源码分析 查找 LinkedList 底层基于链表结构，无法向 ArrayList 那样随机访问指定位置的元素.LinkedList 查找过程要稍麻烦一些，需要从链表头结点（或尾节点）向后查找，时间复杂度为 O(N).相关源码如下： 1234567891011121314151617181920212223public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;Node&lt;E&gt; node(int index) &#123; /* * 则从头节点开始查找，否则从尾节点查找 * 查找位置 index 如果小于节点数量的一半， */ if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; // 循环向后查找，直至 i == index for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 上面的代码比较简单，主要是通过遍历的方式定位目标位置的节点.获取到节点后，取出节点存储的值返回即可.这里面有个小优化，即通过比较 index 与节点数量 size/2 的大小，决定从头结点还是尾节点进行查找.查找操作的代码没什么复杂的地方，这里先讲到这里. 遍历 链表的遍历过程也很简单，和上面查找过程类似，我们从头节点往后遍历就行了.但对于 LinkedList 的遍历还是需要注意一些，不然可能会导致代码效率低下.通常情况下，我们会使用 foreach 遍历 LinkedList，而 foreach 最终转换成迭代器形式.所以分析 LinkedList 的遍历的核心就是它的迭代器实现，相关代码如下： 1234567891011121314151617181920212223242526272829303132333435public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index);&#125;private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; /** 构造方法将 next 引用指向指定位置的节点 */ ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; // 调用 next 方法后，next 引用都会指向他的后继节点 nextIndex++; return lastReturned.item; &#125; // 省略部分方法&#125; 上面的方法很简单，大家应该都能很快看懂，这里就不多说了.下面来说说遍历 LinkedList 需要注意的一个点. 我们都知道 LinkedList 不擅长随机位置访问，如果大家用随机访问的方式遍历 LinkedList，效率会很差.比如下面的代码： 12345678List&lt;Integet&gt; list = new LinkedList&lt;&gt;();list.add(1)list.add(2)......for (int i = 0; i &lt; list.size(); i++) &#123; Integet item = list.get(i); // do something&#125; 当链表中存储的元素很多时，上面的遍历方式对于效率来说就是灾难.原因在于，通过上面的方式每获取一个元素，LinkedList 都需要从头节点（或尾节点）进行遍历，效率不可谓不低.在我的电脑（MacBook Pro Early 2015, 2.7 GHz Intel Core i5）实测10万级的数据量，耗时约7秒钟.20万级的数据量耗时达到了约34秒的时间.50万级的数据量耗时约250秒.从测试结果上来看，上面的遍历方式在大数据量情况下，效率很差.大家在日常开发中应该尽量避免这种用法. 插入 LinkedList 除了实现了 List 接口相关方法，还实现了 Deque 接口的很多方法，所以我们有很多种方式插入元素.但这里，我只打算分析 List 接口中相关的插入方法，其他的方法大家自己看吧.LinkedList 插入元素的过程实际上就是链表链入节点的过程，学过数据结构的同学对此应该都很熟悉了.这里简单分析一下，先看源码吧： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** 在链表尾部插入元素 */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** 在链表指定位置插入元素 */public void add(int index, E element) &#123; checkPositionIndex(index); // 判断 index 是不是链表尾部位置，如果是，直接将元素节点插入链表尾部即可 if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;/** 将元素节点插入到链表尾部 */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; // 创建节点，并指定节点前驱为链表尾节点 last，后继引用为空 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 将 last 引用指向新节点 last = newNode; // 判断尾节点是否为空，为空表示当前链表还没有节点 if (l == null) first = newNode; else l.next = newNode; // 让原尾节点后继引用 next 指向新的尾节点 size++; modCount++;&#125;/** 将元素节点插入到 succ 之前的位置 */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; // 1. 初始化节点，并指明前驱和后继节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 2. 将 succ 节点前驱引用 prev 指向新节点 succ.prev = newNode; // 判断尾节点是否为空，为空表示当前链表还没有节点 if (pred == null) first = newNode; else pred.next = newNode; // 3. succ 节点前驱的后继引用指向新节点 size++; modCount++;&#125; 上面是插入过程的源码，我对源码进行了比较详细的注释，应该不难看懂.上面两个 add 方法只是对操作链表的方法做了一层包装，核心逻辑在 linkBefore 和 linkLast 中.这里以 linkBefore 为例，它的逻辑流程如下： 创建新节点，并指明新节点的前驱和后继 将 succ 的前驱引用指向新节点 如果 succ 的前驱不为空，则将 succ 前驱的后继引用指向新节点 删除 如果大家看懂了上面的插入源码分析，那么再看删除操作实际上也很简单了.删除操作通过解除待删除节点与前后节点的链接，即可完成任务.过程比较简单，看源码吧： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 遍历链表，找到要删除的节点 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); // 将节点从链表中移除 return true; &#125; &#125; &#125; return false;&#125;public E remove(int index) &#123; checkElementIndex(index); // 通过 node 方法定位节点，并调用 unlink 将节点从链表中移除 return unlink(node(index));&#125;/** 将某个节点从链表中移除 */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // prev 为空，表明删除的是头节点 if (prev == null) &#123; first = next; &#125; else &#123; // 将 x 的前驱的后继指向 x 的后继 prev.next = next; // 将 x 的前驱引用置空，断开与前驱的链接 x.prev = null; &#125; // next 为空，表明删除的是尾节点 if (next == null) &#123; last = prev; &#125; else &#123; // 将 x 的后继的前驱指向 x 的前驱 next.prev = prev; // 将 x 的后继引用置空，断开与后继的链接 x.next = null; &#125; // 将 item 置空，方便 GC 回收 x.item = null; size--; modCount++; return element;&#125; 和插入操作一样，删除操作方法也是对底层方法的一层保证，核心逻辑在底层 unlink 方法中.所以长驱直入，直接分析 unlink 方法吧.unlink 方法的逻辑如下（假设删除的节点既不是头节点，也不是尾节点）： 将待删除节点 x 的前驱的后继指向 x 的后继 将待删除节点 x 的前驱引用置空，断开与前驱的链接 将待删除节点 x 的后继的前驱指向 x 的前驱 将待删除节点 x 的后继引用置空，断开与后继的链接 总结 通过上面的分析，大家对 LinkedList 的底层实现应该很清楚了.总体来看 LinkedList 的源码并不复杂，大家耐心看一下，一般都能看懂.","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.tgyf.com/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"Java集合框架","slug":"Java基础/Java集合框架","permalink":"http://blog.tgyf.com/categories/Java%E5%9F%BA%E7%A1%80/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"LinkedList","slug":"LinkedList","permalink":"http://blog.tgyf.com/tags/LinkedList/"},{"name":"Java集合框架","slug":"Java集合框架","permalink":"http://blog.tgyf.com/tags/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"}]},{"title":"关于中间件的一些思考","slug":"Middleware/ThinkInMiddleware","date":"2020-03-04T01:57:25.884Z","updated":"2020-03-04T01:57:25.885Z","comments":true,"path":"2020/03/04/Middleware/ThinkInMiddleware/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/ThinkInMiddleware/","excerpt":"","text":"为什么有这篇文章？ 在项目团队中往往有这样一些人，并不知道自己为什么要在项目用中间件这个东西.其实说白了，就是为了用而用.或者是别人设计的架构，从头到尾没有思考过.这些人给我的映像就是木头木脑的干呆活儿，一本正经的挖坑.为了避免以后团队中出现这类型人，所以有了这篇思维导图型的文章. 1.为什么使用这个类型中间件？ 其实就是这个中间件都有哪些使用场景，然后在项目里具体是什么场景，这个业务场景有个什么技术挑战，如果不用可能会很麻烦，但是你现在用了之后带给了你很多的好处. 2.有什么优点和缺点？原理是怎样的？ 引入中间件之后会不会有什么坏处？要是没考虑过这个，那盲目弄个中间件进系统里，后面出了问题是不是当事人就溜了，这就是给公司后来接盘的人留坑.要是没考虑过引入一个技术可能存在的弊端和风险，这类哥们，基本可能就是挖坑型选手. 3.同类型产品调研对比，分别适合哪些场景？ 中间件没有绝对的好坏，但是就是看用在哪个场景可以扬长避短，利用其优势，规避其劣势. 如果去设计个什么系统，在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑.","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"}]},{"title":"MQ总结：（二）MQ里消费到重复数据怎么办？","slug":"Middleware/MQ总结：（二）MQ里消费到重复数据怎么办","date":"2020-03-04T01:56:02.060Z","updated":"2020-03-04T01:56:02.060Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（二）MQ里消费到重复数据怎么办/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%BA%8C%EF%BC%89MQ%E9%87%8C%E6%B6%88%E8%B4%B9%E5%88%B0%E9%87%8D%E5%A4%8D%E6%95%B0%E6%8D%AE%E6%80%8E%E4%B9%88%E5%8A%9E/","excerpt":"","text":"如何保证消息消费时的幂等性？（或：如何保证消息不被重复消费？） 既然是消费消息，那肯定要考虑考虑这三点： 会不会重复消费？ 能不能避免重复消费？ 或者重复消费了也别造成系统异常可以吗？ 大概可能会有哪些重复消费 如rabbitmq、rocketmq、kafka，都有可能会出现消费重复消费的问题，正常.因为这问题通常不是mq自己保证的，是给你保证的.然后我们挑一个kafka来举个例子，说说怎么重复消费吧. kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧. 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启.这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了.重启之后，少数消息会再次消费一次. 其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性. 怎么保证消息队列消费的幂等性 其实还是得结合业务来思考，这里给几个思路： 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧 比如你是写redis，那没问题了，反正每次都是set，天然幂等性 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis.如果消费过了，那你就别处理了，保证别重复处理相同的消息即可. 还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据 如何保证MQ的消费是幂等性的，需要结合具体的业务来看","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"RabbitMQ（四） - 优先级队列(PriorityQueue)","slug":"Middleware/RabbitMQ/RabbitMQ-PriorityQueue","date":"2020-02-24T15:11:23.490Z","updated":"2020-02-24T15:11:23.490Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ-PriorityQueue/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ-PriorityQueue/","excerpt":"","text":"RabbitMQ - 优先级队列(PriorityQueue) 在RabbitMQ中使用优先级特性需要的版本为3.5+。 使用优先级特性只需做两件事情： 1. 将队列声明为优先级队列，即在创建队列的时候添加参数 x-max-priority 以指定最大的优先级，值为0-255（整数）。 2. 为优先级消息添加优先级。 注意:没有指定优先级的消息会将优先级以0对待。 对于超过优先级队列所定最大优先级的消息，优先级以最大优先级对待。对于相同优先级的消息，后进的排在前面。 核心代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.tgyf.rabbit.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * direct exchange -- 直接交换器 * 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 * @author 韬光养月巴 * @modify * @createDate 2019/8/24 1:29 PM * @remark */@Configuration@Slf4jpublic class DirectExchangeConf &#123; public static final String QUEUE = \"direct-queue-priority\"; public static final String EXCHANGE = \"exchange-direct\"; public static final String ROUTING_KEY = \"direct.queue.priority\"; @Bean Queue directQueuePriority() &#123; //创建队列的时候添加参数 x-max-priority 以指定最大的优先级，值为0-255 Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); args.put(\"x-max-priority\", 100); return new Queue(QUEUE, false, false, false, args); &#125; @Bean DirectExchange directExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding directQueuePriorityBinding(Queue directQueuePriority, DirectExchange directExchange) &#123; return BindingBuilder.bind(directQueuePriority).to(directExchange).with(ROUTING_KEY); &#125;&#125; 测试 1.测试优先级队列 发送优先级低的消息 100 条到 RabbitMQ curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.priority&quot;, &quot;priority&quot;: 1, &quot;content&quot;:&quot; hello priority queue! &quot;, &quot;count&quot;: 100 }' 发送优先级高的消息 5 条到 RabbitMQ curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.priority&quot;, &quot;priority&quot;: 10, &quot;content&quot;:&quot; &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; hello priority queue! &quot;, &quot;count&quot;: 5 }'","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ（二） - 交换器（Exchange）","slug":"Middleware/RabbitMQ/RabbitMQ-Exchang","date":"2020-02-24T15:11:16.763Z","updated":"2020-02-24T15:11:16.763Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ-Exchang/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ-Exchang/","excerpt":"","text":"RabbitMQ - 交换器（Exchange） 交换器名称 作用 fanout exchange 发送到该交换器的所有消息，会被路由到其绑定的所有队列 direct exchange 发送到该交换器的消息，会通过路由键完全匹配，匹配成功就会路由到指定队列 topic exchange 发送到该交换器的消息，会通过路由键模糊匹配，匹配成功就会路由到指定队列 header exchange 发送到该交换器的消息，会通过消息的 header 信息匹配，匹配成功就会路由到指定队列 核心代码 pom.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tgyf.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;exchange&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; direct exchange – 直接交换器 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * direct exchange -- 直接交换器 * 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:07 PM * @remark */@Configurationpublic class DirectExchangeConf &#123; public static final String QUEUE_1 = \"direct-queue-1\"; public static final String QUEUE_2 = \"direct-queue-2\"; private static final String EXCHANGE = \"exchange-direct\"; private static final String ROUTING_KEY_TO_QUEUE1 = \"queue.direct.key1\"; private static final String ROUTING_KEY_TO_QUEUE2 = \"queue.direct.key2\"; @Bean Queue directQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue directQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean DirectExchange directExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding bindingDirectQueue1(Queue directQueue1, DirectExchange directExchange) &#123; return BindingBuilder.bind(directQueue1).to(directExchange).with(ROUTING_KEY_TO_QUEUE1); &#125; @Bean Binding bindingDirectQueue2(Queue directQueue2, DirectExchange directExchange) &#123; return BindingBuilder.bind(directQueue2).to(directExchange).with(ROUTING_KEY_TO_QUEUE2); &#125;&#125; fanout exchange – 扇出交换器 所有发送到该交换器的消息都会被路由到所有与该交换器绑定的队列中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.FanoutExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * fanout exchange -- 扇出交换器 * 所有发送到该交换器的消息都会被路由到所有与该交换器绑定的队列中 * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:04 PM * @remark */@Configurationpublic class FanoutExchangeConf &#123; public static final String QUEUE_1 = \"fanout-queue-1\"; public static final String QUEUE_2 = \"fanout-queue-2\"; private static final String EXCHANGE = \"exchange-fanout\"; @Bean Queue fanoutQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue fanoutQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean FanoutExchange fanoutExchange() &#123; return new FanoutExchange(EXCHANGE); &#125; @Bean Binding bindingFanoutQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange) &#123; return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); &#125; @Bean Binding bindingFanoutQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange) &#123; return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange); &#125;&#125; headers exchange – headers交换器 发送到该交换器的消息会根据消息的 header 信息路由到对应的队列 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.HeadersExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;/** * headers exchange -- headers交换器 * 发送到该交换器的消息会根据消息的 header 信息路由到对应的队列 * 说明： * where 匹配单个 header * whereAll 同时匹配多个 header * whereAny 匹配一个或多个 header * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:12 PM * @remark */public class HeadersExchangeConf &#123; public static final String QUEUE_1 = \"headers-queue-1\"; public static final String QUEUE_2 = \"headers-queue-2\"; public static final String QUEUE_3 = \"headers-queue-3\"; private static final String EXCHANGE = \"exchange-headers\"; @Bean Queue headersQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue headersQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean Queue headersQueue3() &#123; return new Queue(QUEUE_3, false); &#125; @Bean HeadersExchange headersExchange() &#123; return new HeadersExchange(EXCHANGE); &#125; @Bean Binding bindingHeadersQueue1(Queue headersQueue1, HeadersExchange headersExchange) &#123; return BindingBuilder.bind(headersQueue1).to(headersExchange).where(\"one\").exists(); &#125; @Bean Binding bindingHeadersQueue2(Queue headersQueue1, HeadersExchange headersExchange) &#123; return BindingBuilder.bind(headersQueue1).to(headersExchange).whereAll(\"all1\", \"all2\").exist(); &#125; @Bean Binding bindingHeadersQueue3(Queue headersQueue3, HeadersExchange headersExchange) &#123; return BindingBuilder.bind(headersQueue3).to(headersExchange).whereAny(\"any1\", \"any2\").exist(); &#125;&#125; topic exchange – 主题交换器 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.Queue;import org.springframework.amqp.core.TopicExchange;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * topic exchange -- 主题交换器 * 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 * 说明： * routing key 以 '.' 分隔为多个单词 * routing key 以 '*' 匹配一个单词 * routing key 以 '#' 匹配零个或多个单词 * 例如： * queue.topic.key -&gt; QUEUE_1 + QUEUE_2 * test.topic.key -&gt; QUEUE_1 * queue -&gt; QUEUE_2 * queue.topic -&gt; QUEUE_2 * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:09 PM * @remark */@Configurationpublic class TopicExchangeConf &#123; public static final String QUEUE_1 = \"topic-queue-1\"; public static final String QUEUE_2 = \"topic-queue-2\"; private static final String EXCHANGE = \"exchange-topic\"; private static final String ROUTING_KEY_TO_QUEUE1 = \"*.topic.*\"; private static final String ROUTING_KEY_TO_QUEUE2 = \"queue.#\"; @Bean Queue topicQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue topicQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean TopicExchange topicExchange() &#123; return new TopicExchange(EXCHANGE); &#125; @Bean Binding bindingTopicQueue1(Queue topicQueue1, TopicExchange topicExchange) &#123; return BindingBuilder.bind(topicQueue1).to(topicExchange).with(ROUTING_KEY_TO_QUEUE1); &#125; @Bean Binding bindingTopicQueue2(Queue topicQueue2, TopicExchange topicExchange) &#123; return BindingBuilder.bind(topicQueue2).to(topicExchange).with(ROUTING_KEY_TO_QUEUE2); &#125;&#125; 测试 1.测试fanout exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-fanout&quot;, &quot;routingKey&quot;: &quot;default&quot;, &quot;content&quot;:&quot; hello fanout!&quot;, &quot;count&quot;: 1 }' 2.测试 direct exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;queue.direct.key1&quot;, &quot;content&quot;:&quot; hello direct! &quot;, &quot;count&quot;: 1 }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;queue.direct.key2&quot;, &quot;content&quot;:&quot; hello direct! &quot;, &quot;count&quot;: 1 }' 3.测试 topic exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-topic&quot;, &quot;routingKey&quot;: &quot;queue.topic.key1&quot;, &quot;content&quot;:&quot; hello topic! &quot;, &quot;count&quot;: 1 }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-topic&quot;, &quot;routingKey&quot;: &quot;test.topic.key2&quot;, &quot;content&quot;:&quot; hello topic! &quot;, &quot;count&quot;: 1 }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-topic&quot;, &quot;routingKey&quot;: &quot;queue.hello&quot;, &quot;content&quot;:&quot; hello topic! &quot;, &quot;count&quot;: 1 }' 4.测试 headers exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-headers&quot;, &quot;content&quot;:&quot; hello headers! &quot;, &quot;count&quot;: 1, &quot;headers&quot;:{ &quot;one&quot;:&quot;value&quot; } }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-headers&quot;, &quot;content&quot;:&quot; hello headers! &quot;, &quot;count&quot;: 1, &quot;headers&quot;:{ &quot;all1&quot;:&quot;value&quot;, &quot;all2&quot;:&quot;value&quot; } }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-headers&quot;, &quot;content&quot;:&quot; hello headers! &quot;, &quot;count&quot;: 1, &quot;headers&quot;:{ &quot;any2&quot;:&quot;value&quot;, } }'","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ（三） - 死信队列(DeadLetterQueue)","slug":"Middleware/RabbitMQ/RabbitMQ-DeadletterQueue","date":"2020-02-24T15:11:10.610Z","updated":"2020-02-24T15:11:10.611Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ-DeadletterQueue/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ-DeadletterQueue/","excerpt":"","text":"RabbitMQ - 死信队列(DeadLetterQueue) 什么是死信 “死信”是RabbitMQ中的一种消息机制，当你在消费消息时，如果队列里的消息出现以下情况： 1.消息被否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为false。 2.消息在队列的存活时间超过设置的TTL时间。 3.消息队列的消息数量已经超过最大队列长度。 那么该消息将成为“死信”。 “死信”消息会被RabbitMQ进行特殊处理，如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃。 死信生命周期 死信队列只是一个绑定在死信交换机上的普通队列，而死信交换机也只是一个普通的交换机，不过是用来专门处理死信的交换机。 死信的生命周期： 业务消息被投入业务队列 消费者消费业务队列的消息，由于处理过程中发生异常，于是进行了nck或者reject操作 被nck或reject的消息由RabbitMQ投递到死信交换机中 死信交换机将消息投入相应的死信队列 死信队列的消费者消费死信消息 死信消息是RabbitMQ为我们做的一层保证，其实我们也可以不使用死信队列，而是在消息消费异常时，将消息主动投递到另一个交换机中，关键在于这些Exchange和Queue怎么配合。比如从死信队列拉取消息，然后发送邮件、短信、钉钉通知来通知开发人员关注。或者将消息重新投递到一个队列然后设置过期时间，来进行延时消费。 死信消息的Header 字段名 含义 x-first-death-exchange 第一次被抛入的死信交换机的名称 x-first-death-reason 第一次成为死信的原因，rejected：消息在重新进入队列时被队列拒绝，由于default-requeue-rejected 参数被设置为false。expired ：消息过期。maxlen ： 队列内消息数量超过队列最大容量 x-first-death-queue 第一次成为死信前所在队列名称 x-death 历次被投入死信交换机的信息列表，同一个消息每次进入一个死信交换机，这个数组的信息就会被更新 死信队列应用场景 一般用在较为重要的业务队列中，确保未被正确消费的消息不被丢弃，一般发生消费异常可能原因主要有由于消息信息本身存在错误导致处理异常，处理过程中参数校验异常，或者因网络波动导致的查询异常等等，当发生异常时，当然不能每次通过日志来获取原消息，然后让运维帮忙重新投递消息（没错，以前就是这么干的= =）。通过配置死信队列，可以让未正确处理的消息暂存到另一个队列中，待后续排查清楚问题后，编写相应的处理代码来处理死信消息，这样比手工恢复数据要好太多了。 核心代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.tgyf.rabbit.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 死信交换器 * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 2:18 PM * @remark */@Configuration@Slf4jpublic class DeadLetterExchangeConf &#123; public static final String QUEUE_BY_MAX_LENGTH = \"direct-queue-dead-by-max-length\"; public static final String QUEUE_BY_TTL = \"direct-queue-dead-by-ttl\"; public static final String QUEUE_BY_REJECT = \"direct-queue-dead-by-reject\"; public static final String EXCHANGE = \"exchange-direct-dead\"; public static final String ROUTING_KEY_BY_MAX_LENGTH = \"direct.queue.dead.max.length\"; public static final String ROUTING_KEY_BY_TTL = \"direct.queue.dead.ttl\"; public static final String ROUTING_KEY_BY_REJECT = \"direct.queue.dead.reject\"; @Bean Queue deadByMaxLengthQueue() &#123; return new Queue(QUEUE_BY_MAX_LENGTH, false); &#125; @Bean Queue deadByTTLQueue() &#123; return new Queue(QUEUE_BY_TTL, false); &#125; @Bean Queue deadByRejectQueue() &#123; return new Queue(QUEUE_BY_REJECT, false); &#125; @Bean DirectExchange deadDirectExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding deadByMaxLengthQueueBinding(Queue deadByMaxLengthQueue, DirectExchange deadDirectExchange) &#123; return BindingBuilder.bind(deadByMaxLengthQueue).to(deadDirectExchange).with(ROUTING_KEY_BY_MAX_LENGTH); &#125; @Bean Binding deadByTTLQueueBinding(Queue deadByTTLQueue, DirectExchange deadDirectExchange) &#123; return BindingBuilder.bind(deadByTTLQueue).to(deadDirectExchange).with(ROUTING_KEY_BY_TTL); &#125; @Bean Binding deadByRejectQueueBinding(Queue deadByRejectQueue, DirectExchange deadDirectExchange) &#123; return BindingBuilder.bind(deadByRejectQueue).to(deadDirectExchange).with(ROUTING_KEY_BY_REJECT); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package com.tgyf.rabbit.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * 普通交换器 * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 2:18 PM * @remark */@Configuration@Slf4jpublic class DirectExchangeConf &#123; public static final String QUEUE_MAX_LENGTH = \"direct-queue-max-length\"; public static final String QUEUE_TTL = \"direct-queue-ttl\"; public static final String QUEUE_REJECT = \"direct-queue-reject\"; public static final String EXCHANGE = \"exchange-direct\"; public static final String ROUTING_KEY_MAX_LENGTH = \"direct.queue.max.length\"; public static final String ROUTING_KEY_TTL = \"direct.queue.ttl\"; public static final String ROUTING_KEY_REJECT = \"direct.queue.reject\"; @Bean Queue maxLengthQueue() &#123; Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); // 设置队列最大长度 args.put(\"x-max-length\", 10); // 设置死信转发的 exchange 和 routing key args.put(\"x-dead-letter-exchange\", DeadLetterExchangeConf.EXCHANGE); args.put(\"x-dead-letter-routing-key\", DeadLetterExchangeConf.ROUTING_KEY_BY_MAX_LENGTH); return new Queue(QUEUE_MAX_LENGTH, false, false, false, args); &#125; @Bean Queue ttlQueue() &#123; Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); // 设置消息存活时间 10s args.put(\"x-message-ttl\", 10000); // 设置死信转发的 exchange 和 routing key args.put(\"x-dead-letter-exchange\", DeadLetterExchangeConf.EXCHANGE); args.put(\"x-dead-letter-routing-key\", DeadLetterExchangeConf.ROUTING_KEY_BY_TTL); return new Queue(QUEUE_TTL, false, false, false, args); &#125; @Bean Queue rejectQueue() &#123; Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); // 设置死信转发的 exchange 和 routing key args.put(\"x-dead-letter-exchange\", DeadLetterExchangeConf.EXCHANGE); args.put(\"x-dead-letter-routing-key\", DeadLetterExchangeConf.ROUTING_KEY_BY_REJECT); return new Queue(QUEUE_REJECT, false, false, false, args); &#125; @Bean DirectExchange directExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding maxLengthQueueBinding(Queue maxLengthQueue, DirectExchange directExchange) &#123; return BindingBuilder.bind(maxLengthQueue).to(directExchange).with(ROUTING_KEY_MAX_LENGTH); &#125; @Bean Binding ttlQueueBinding(Queue ttlQueue, DirectExchange directExchange) &#123; return BindingBuilder.bind(ttlQueue).to(directExchange).with(ROUTING_KEY_TTL); &#125; @Bean Binding rejectQueueBinding(Queue rejectQueue, DirectExchange directExchange) &#123; return BindingBuilder.bind(rejectQueue).to(directExchange).with(ROUTING_KEY_REJECT); &#125;&#125; 测试 1.测试消费者否认消息 curl -X POST \\ http://127.0.0.1:8080/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.reject&quot;, &quot;content&quot;:&quot; hello reject queue! &quot;, &quot;count&quot;: 1 }' 2.测试消息超出队列最大长度 curl -X POST \\ http://127.0.0.1:8080/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.max.length&quot;, &quot;content&quot;:&quot; hello max length queue! &quot;, &quot;count&quot;: 30 }' 提示：消息队列遵循先进先出的策略，假设队列最大长度设置为 10，发送 30 条消息到该队列，若无消费者，前 20 条消息会被转发到指定的其他队列，后 10 条会保存在该队列中，除非有新的消息入队，这 10 条消息才会被转发 3.测试消息超时 curl -X POST \\ http://127.0.0.1:8080/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.ttl&quot;, &quot;content&quot;:&quot; hello ttl queue! &quot;, &quot;count&quot;: 10 }' 4.测试延迟队列 curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.delay&quot;, &quot;content&quot;:&quot; hello delay delay! &quot;, &quot;count&quot;: 1, &quot;delayTime&quot;: &quot;10000&quot; }'","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ（一） - 配置详解","slug":"Middleware/RabbitMQ/RabbitMQ","date":"2020-02-24T15:10:50.667Z","updated":"2020-02-24T15:10:50.667Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ/","excerpt":"","text":"启动 RabbitMQ docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 -v `pwd`/data:/var/lib/rabbitmq --hostname rabbit -e RABBITMQ_DEFAULT_VHOST=my_vhost -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin rabbitmq:3.7-management-plugins 构建RabbitMQ镜像参考RabbitMQ 镜像dockerfile 内容结构 序号 内容名称 内容说明 1 exchange 交换器 2 priorityqueue 优先级队列 3 deadletterqueue 死信队列 Spring Boot RabbitMQ 参数配置详解 连接配置 spring.rabbitmq.host=localhost # RabbitMQ 地址 spring.rabbitmq.port=5672 # RabbitMQ 端口 spring.rabbitmq.username=guest # RabbitMQ 用户名 spring.rabbitmq.password=guest # RabbitMQ 密码 spring.rabbitmq.addresses= # 设置 RabbitMQ 集群，多个地址使用 &quot;,&quot; 分隔，例如：192.168.0.100:5672,192.168.0.101:5672 spring.rabbitmq.virtual-host= # 设置 Virtual Host spring.rabbitmq.ssl.algorithm= # SSL 算法，默认情况下，由 Rabbit 客户端配置 spring.rabbitmq.ssl.enabled=false # 是否启用 SSL 支持 spring.rabbitmq.ssl.key-store= # key 存储路径 spring.rabbitmq.ssl.key-store-password= # 用于访问 key 的密码 spring.rabbitmq.ssl.key-store-type=PKCS12 # Key 存储类型 spring.rabbitmq.ssl.trust-store= # Trust 存储路径 spring.rabbitmq.ssl.trust-store-password= # 用于访问 Trust 的密码 spring.rabbitmq.ssl.trust-store-type=JKS # Trust 存储类型 spring.rabbitmq.ssl.validate-server-certificate=true # 是否启用服务端证书验证 spring.rabbitmq.ssl.verify-hostname=true # 是否启用 hostname 验证 Publisher 配置 spring.rabbitmq.publisher-confirms=false # 是否启用 publisher 确认 spring.rabbitmq.publisher-returns=false # 是否启用 publisher 返回 spring.rabbitmq.template.default-receive-queue= # 没有没确定指定队列时的默认队列 spring.rabbitmq.template.exchange= # 发送消息默认的 exchange spring.rabbitmq.template.mandatory= # 是否启用 mandatory 消息 spring.rabbitmq.template.receive-timeout= # `receive()` 操作的超时时间 spring.rabbitmq.template.reply-timeout= # `sendAndReceive()` 操作的超时时间 spring.rabbitmq.template.retry.enabled=false # 是否启用重试 spring.rabbitmq.template.retry.initial-interval=1000ms # 两次重试间的时间间隔 spring.rabbitmq.template.retry.max-attempts=3 # 最大重试次数 spring.rabbitmq.template.retry.max-interval=10000ms # 最长重试时间 spring.rabbitmq.template.retry.multiplier=1 # Multiplier to apply to the previous retry interval. spring.rabbitmq.template.routing-key= # 发送消息默认的 routing key Consumer 设置 spring.rabbitmq.listener.direct.acknowledge-mode= # 确认模式：auto / manual / none spring.rabbitmq.listener.direct.auto-startup=true # 是否在应用启动时自动启动容器 spring.rabbitmq.listener.direct.consumers-per-queue= # 每个队列的消费者数量 spring.rabbitmq.listener.direct.default-requeue-rejected= # 默认情况下，拒收的消息是否重新排队 spring.rabbitmq.listener.direct.idle-event-interval= # 空闲容器事件发布的频率 spring.rabbitmq.listener.direct.missing-queues-fatal=false # 如果容器声明的队列在 broker 上不可用，是否失败 spring.rabbitmq.listener.direct.prefetch= # 预加载的消息数量 spring.rabbitmq.listener.direct.retry.enabled=false # 是否启用发布重试 spring.rabbitmq.listener.direct.retry.initial-interval=1000ms # 两次重试时间间隔 spring.rabbitmq.listener.direct.retry.max-attempts=3 # 最大重试次数 spring.rabbitmq.listener.direct.retry.max-interval=10000ms # 最长重试时间 spring.rabbitmq.listener.direct.retry.multiplier=1 # 上次重试间隔的倍数 spring.rabbitmq.listener.direct.retry.stateless=true # 重试是否有状态 spring.rabbitmq.listener.simple.acknowledge-mode= # 确认模式：auto / manual / none spring.rabbitmq.listener.simple.auto-startup=true # 是否在应用启动时自动启动容器 spring.rabbitmq.listener.simple.concurrency= # 监听器最小线程数 spring.rabbitmq.listener.simple.default-requeue-rejected= # 默认情况下，拒收的消息是否重新排队 spring.rabbitmq.listener.simple.idle-event-interval= # 空闲容器事件发布的频率 spring.rabbitmq.listener.simple.max-concurrency= # 监听器最大线程数 spring.rabbitmq.listener.simple.missing-queues-fatal=true # 如果容器声明的队列在 broker 上不可用，是否失败； 如果在运行时删除队列，容器是否停止 spring.rabbitmq.listener.simple.prefetch= # 预加载的消息数量 spring.rabbitmq.listener.simple.retry.enabled=false # 是否启用发布重试 spring.rabbitmq.listener.simple.retry.initial-interval=1000ms # 两次重试时间间隔 spring.rabbitmq.listener.simple.retry.max-attempts=3 # 最大重试次数 spring.rabbitmq.listener.simple.retry.max-interval=10000ms # 最长重试时间 spring.rabbitmq.listener.simple.retry.multiplier=1 # 上次重试间隔的倍数 spring.rabbitmq.listener.simple.retry.stateless=true # 重试是否有状态 spring.rabbitmq.listener.simple.transaction-size= # 确认模式为 auto 时，在 acks 之间处理的消息数. 如果大于预加载的数量，则预加载的数量增加到此值 rabbitmq listener 类型有两种：simple 和 direct，二者有什么区别呢？ DirectMessageListenerContainer 注释如下： The {@code SimpleMessageListenerContainer} is not so simple. Recent changes to the rabbitmq java client has facilitated a much simpler listener container that invokes the listener directly on the rabbit client consumer thread. There is no txSize property - each message is acked (or nacked) individually. 其他设置 spring.rabbitmq.dynamic=true # 是否创建 AmqpAdmin bean spring.rabbitmq.requested-heartbeat= # 请求心跳超时时间. 设置为 0 代表没有，如果未指定时间后缀，则默认使用秒 Spring Boot RabbitMQ 队列属性详解 属性名称 属性说明 Durable 代表该队列是否持久化至硬盘（若要使队列中消息不丢失，同时也需要将消息声明为持久化 Exclusive 是否声明该队列是否为连接独占，若为独占，连接关闭后队列即被删除 Auto-delete 若没有消费者订阅该队列，队列将被删除 Arguments 可选map类型参数，可以指定队列长度，消息生存时间，镜相设置等 RabbitMQ规定，队列的名字最长不超过UTF-8编码的255字节 RabbitMQ内部的Queue命名规则采用 &quot;amq.&quot;形式，注意不要与此规则冲突 常见问题 1. 声明了一个已经存在的队列？ 如果队列已经存在，再次声明将不会起作用。若原始队列参数和该次声明时不同则会报异常。 2. 队列中消息顺序？ 默认情况下是FIFO，即先进先出，同时也支持发送消息时指定消息的优先级。 3. 队列消息存放位置？ 对于临时消息，RabbitMQ尽量将其存放在内存，当出现内存告警时，MQ会将消息持久化至硬盘。对于持久化消息与Lazy-queues，MQ会先将消息存入硬盘，消费时再取出。 4. 队列中消息的消费？ 默认情况下，MQ会设置消费者的消费确认模式为自动。对于一些重要消息的处理，推荐确认模式改为手动。（nack和reject区别？nack可以一次拒绝多条消息） 5. 队列中消息的消费速度？ 通过Prefetch（通道上最大未确认投递数量）设置消费者每次消费的条数，一般将该值设为1，但他会降低吞吐量。RabbitMQ官网建议的是100-300.（更建议反复试验得到一个表现符合期望的值） 6. 队列中消息状态？ 队列中的消息共有俩种状态，一是准备投递，二是已投递但未确认。队列最大长度？ 声明队列时可以指定最大长度，需要注意的是只限制状态为准备投递的数量，未确认的消息不计算在内。当队列长度超过限制，MQ会根据策略选择丢弃（默认）或者将消息投递进死信队列。 7. 关于死信队列？ 其实更准确的说法是死信交换机，提前声明一个交换机，在声明队列时使用“x-dead-letter-exchange”参数（可指定routKey）将队列绑定到该死信交换机。消息有以下情况之一会成为死信：被reject或者nack，消息超过生存时间，队列长度超过限制。 8. 关于不能路由到队列的消息？ 这个和上面一样，其实不算Queue系列而是Exchange。针对消息无法路由到队列的情况MQ提供了Alternate Exchange处理。声明Exchange时添加args.put(“alternate-exchange”,“my-ae”)参数。即当该交换机存在无法路由的消息时，它将消息发布到AE上，AE把消息路由到绑定在他上面的消息。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"Hexo主题pure使用指南","slug":"Blog/Hexo主题pure使用指南","date":"2020-02-23T15:12:34.123Z","updated":"2020-02-23T15:12:34.123Z","comments":true,"path":"2020/02/23/Blog/Hexo主题pure使用指南/","link":"","permalink":"http://blog.tgyf.com/2020/02/23/Blog/Hexo%E4%B8%BB%E9%A2%98pure%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"123预览地址: https://blog.cofess.com项目地址: https://github.com/cofess/hexo-theme-pure中文使用文档: https://github.com/cofess/hexo-theme-pure/blob/master/README.cn.md 使用前请操作 使用该主题前, 请先复制 theme/pure/_source/ 目录下的所有内容到 blog path/source/ 目录下 原因在于该目录下有建好的菜单 categories(分类)、tags(标签)、repository(项目)、books(书单)、links(友链)、about(关于)页面 当你使用自动生成分类、标签，展示github项目时 文章目录索引 在文章详情页, 展示一个文章目录 主题配置文件中开启配置: 12config toc: true # 是否开启文章章节目录导航 在文章顶部将该文章开启索引, 如: 12345678910111213---title: Hexo主题pure使用指南date: 2019-11-05 14:34:15tags: - hexo主题categories:- hexotoc: true # 是否启用内容索引sidebar: none # 是否启用sidebar侧边栏，none：不启用--- 侧边栏 主题配置项中, 侧边栏可以如下配置: 123456789101112131415# 侧边栏sidebar: right# 侧边栏启用哪些模块widgets: - board # 公告 - category # 分类 - tag # 标签 - tagcloud # 标签云 - archive # 归档 - recent_posts # 最近文章# 归档列表的展示方式archive_type: 'monthly' # 归档方式: yearly | monthlyshow_count: true # 显示每个归档的文章总数 图集 在文章详情页中, 涉及的图片可以使用图集功能, 在点击一张图片时, 放大图片. 主题的图册公告是使用fancybox实现, 可以参照github 1234# Fancybox# 图集功能fancybox: true 展示github项目 在左侧菜单项目中, 点击展示自己的github项目 在主题配置文件中 _config.yml 修改, 请配置自己github用户名 123github: username: caoruiy # github用户名 新建repository页面: 12&gt; hexo new repository 你也可以直接复制 theme/pure/_source/ 目录下 repository文件夹 到 博客根目录/source/ 目录下 将文件内容修改为: 1234567---title: Repositorieslayout: repositorycomments: falsesidebar: none--- 关键内容为 layout: repository, 包含该属性才可以展示github项目 评论功能 主题集成了disqus、友言、来必力、gitment、gitalk评论系统，选择其中一种即可 你可以在主题配置文件中修改评论工具 123comment: type: valine # 启用哪种评论系统 Valine 一个无后端的评论框工具, 其依赖于 Leancloud 开发, 所以使用前需要先注册 Leancloud 账号 如何开始? 你可以从 Valine-快速开始 教程开始, 教程包含了一步一步的指引教程. Valine配置项 主题valine评论框提供了以下配置项 1234567891011121314valine: # Valine官方地址: https://valine.js.org appid: # 你的 leancloud 应用 appid appkey: # 你的 leancloud 应用 appkey notify: true # 是否开始评论邮件提醒, 教程: https://github.com/xCss/Valine/wiki verify: false # 是否开始验证码功能, 开始邮件提醒会自动开启验证码功能 placeholder: 说点什么... # 输入框默认内容 avatar: mm # 头像展示方式, 具体设置项教程: https://valine.js.org/configuration.html#avatar meta: nick,mail,link # 自定义评论信息 pageSize: 10 # 评论列表分页 lang: zh-cn, # 多语言支持 zh-cn | en visitor: true # 文章阅读量统计: https://valine.js.org/visitor.html highlight: true # 代码高亮 recordIP: true # 记录评论者的IP 关于邮件提醒: 只有在回复评论时, 并且填写了邮箱的评论才会收到回复提醒 关于文章阅读量统计: 开启阅读量统计, 会在详情页标题下展示阅读量数据 搜索功能 主题提供内置的搜索功能和百度搜索, 百度搜索就是使用百度的SEO搜索, 个人觉得不是很实用, 不建议开启. 在主题配置文件 _config.yml 中配置: 12345# Searchsearch: insight: true # 在使用搜索功能前, 你需要安装 `hexo-generator-json-content` baidu: false # 使用百度搜索前, 你必须禁用其他所有的搜索功能 内置搜索 使用搜索功能前需要先安装: 12npm i -S hexo-generator-json-content 项目地址: https://github.com/alexbruno/hexo-generator-json-content 在你运行 hexo g 或者 hexo s 时生效，在 hexo g 生成站点时, 会在根目录下生成 content.json 该文件内容即为搜索内容。 你可以对搜索内容进行自定义的配置， 只要在 _config.yml 中配置 jsonContent即可: 1234567891011121314151617181920# 示例: 隐藏分类和标签的搜索jsonContent: dateFormat: DD/MM/YYYY posts: title: true date: true path: true text: true raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: false author: false 文章阅读数量统计 主题提供 不蒜子 和 基于 leancloud 的统计 但是经过验证, 发现基于leancloud的统计不生效, 不知原因, 实现等效的方法就是: 评论框使用valine评论框(主题已经内置), 同时开启 visitor: true 配置项项即可 字数统计&amp;阅读时长 主题内置了该功能, 使用前需要先安装插件: 12npm i -S hexo-wordcount 主题配置文件中, 开启设置即可: 123456# wordcountpostCount: enable: true wordcount: true # 文章字数统计 min2read: true # 阅读时长预计 友情链接 复制 theme/pure/_source/ 目录下 links文件夹 到 blog path/source/ 目录下 在 hexo 目录下的 source 文件夹内创建一个名为 _data（禁止改名）的文件夹。 然后在文件内创建一个名为 links.yml 的文件,在其中添加相关数据即可。 单个友情链接的格式为： 12345Name: link: http://example.com avatar: http://example.com/avatar.png desc: \"这是一个描述\" 添加多个友情链接，我们只需要根据上面的格式重复填写即可。 将 Name 改为友情链接的名字，例如 Cofess。 http://example.com 为友情链接的地址。 http://example.com/avatar.png 为友情链接的头像。 这是一个描述 为友情链接描述。","categories":[{"name":"应用部署","slug":"应用部署","permalink":"http://blog.tgyf.com/categories/%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://blog.tgyf.com/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"搭建个人博客hexo详细步骤","slug":"Blog/搭建个人博客hexo详细步骤","date":"2020-02-23T14:44:47.683Z","updated":"2020-02-23T14:44:47.683Z","comments":true,"path":"2020/02/23/Blog/搭建个人博客hexo详细步骤/","link":"","permalink":"http://blog.tgyf.com/2020/02/23/Blog/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hexo%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start 第一步：下载安装Git与node.js Git下载地址 node.js下载地址 第二步：安装hexo 1$ npm install -g hexo 这里如果地址被“墙”，可以参考这篇文章的“安装Hexo”部分 第三步：初始化Hexo 创建文件夹（我的是在F盘创建的Hexo） 在Hexo文件夹下，右键运行Git Bash，输入命令：hexo init 在_config.yml,进行基础配置 第四步：本地部署博客 分别输入 如下命令： 12hexo ghexo s 更多hexo常用命令","categories":[{"name":"应用部署","slug":"应用部署","permalink":"http://blog.tgyf.com/categories/%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://blog.tgyf.com/tags/%E5%8D%9A%E5%AE%A2/"}]}]}