{"meta":{"title":"韬光养月巴的技术博客","subtitle":"","description":"","author":"韬光养月巴","url":"http://blog.tgyf.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-02-22T13:20:16.531Z","updated":"2020-02-22T12:01:21.685Z","comments":false,"path":"/404.html","permalink":"http://blog.tgyf.com/404.html","excerpt":"","text":""},{"title":"书单","date":"2020-02-22T13:20:16.520Z","updated":"2020-02-22T12:01:21.688Z","comments":false,"path":"books/index.html","permalink":"http://blog.tgyf.com/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-03-04T03:34:15.353Z","updated":"2020-03-04T03:34:15.289Z","comments":false,"path":"about/index.html","permalink":"http://blog.tgyf.com/about/index.html","excerpt":"","text":"欢迎访问我的博客，我会保持不定期更新。 123456789101112131415161718192021222324252627282930313233343536 _______ ______ __ __ _____ /\\_______)\\/_/\\___\\/\\ /\\ /\\ /\\_____\\ \\(___ __\\/) ) ___/\\ \\ \\/ / /( ( ___/ / / / /_/ / ___\\ \\__/ / \\ \\ \\_ ( ( ( \\ \\ \\_/\\__\\\\__/ / / / /_\\ \\ \\ \\ )_) \\/ _// / / / /____/ /_/_/ \\_\\____/ \\/_/ \\/_/ &#123; \"name\": \"韬光养月巴\", \"age\": 30, \"gender\": \"男\", \"profession\": \"Java Developer &amp; Designer\", \"experience\": \"5年\", \"address\": \"四川省成都市\", \"education\": \"本科\", \"github\": \"https://github.com/tgyf\", \"blog\": \"http://blog.tgyf.com\", \"email\": \"back_up[a]foxmail.com\", \"skills\":[ [\"SpringFramework\", \"Netty\", \"Dubbo\", \"Mybatis\"], [\"Html\", \"Javascript\", \"jQuery\", \"CSS\"], [\"Mysql\",\"Orcal\",\"Redis\",\"MongoDB\"], [\"Docker\", \"Swarm\",\"K8s\"], [\"Git\", \"SVN\"], ], \"devTools\":[ [\"IntelliJ IDEA \", \"VisualStudioCode\", \"Notepad++\"], [\"SourceTree\", \"TortoiseSVN\"], [\"Navicat\", \"RedisDesktopManager\",\"Robo3t\"], [\"MobaXterm\",\"Xshell\"] ] &#125;"},{"title":"分类","date":"2020-02-22T13:20:16.515Z","updated":"2020-02-22T13:07:14.116Z","comments":false,"path":"categories/index.html","permalink":"http://blog.tgyf.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-02-22T13:20:16.505Z","updated":"2020-02-22T12:01:21.688Z","comments":true,"path":"links/index.html","permalink":"http://blog.tgyf.com/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-02-22T13:20:16.499Z","updated":"2020-02-22T12:01:21.689Z","comments":false,"path":"repository/index.html","permalink":"http://blog.tgyf.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-02-22T13:20:16.510Z","updated":"2020-02-22T12:01:21.689Z","comments":false,"path":"tags/index.html","permalink":"http://blog.tgyf.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JVM类加载机制","slug":"Java虚拟机/JVM类加载机制","date":"2020-03-05T03:39:58.385Z","updated":"2020-03-05T03:39:58.385Z","comments":true,"path":"2020/03/05/Java虚拟机/JVM类加载机制/","link":"","permalink":"http://blog.tgyf.com/2020/03/05/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"一张总结图（来自牛客网） 一、类加载时机 类从被加载到虚拟机内存中开始，到出内存为止，它的整个生命周期包括 : 加载 (Loading)、验 证(Verification)、准 备 (Preparation)、解 析 (Resolution)、初始化(Initialization)、使用(Using) 和卸载 (Unloading) 7 个阶段。其中验证、准备、解析 3 个部分统称为连接 (Linking)，顺序如图 所示。 其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。 这 7 个阶段中的：加载、验证、准备、初始化、卸载的顺序是固定的。但它们并不一定是严格同步串行执行，它们之间可能会有交叉，但总是以 “开始” 的顺序总是按部就班的。至于解析则有可能在初始化之后才开始，这是为了支持 Java 语言的运行时绑定（也称为动态绑定或晚期绑定）。 Java程序对类的使用方式可以分为两种: 主动引用、被动引用。 所有的Java虚拟机实现必须在每个类或接口被Java程序 &quot;首次主动使用&quot;时才初始化他们。 1、主动引用 虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）： 遇到new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是： 使用 new 关键字实例化对象的时候； 读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候； 以及调用一个类的静态方法的时候； 通过反射(Class.forName())使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化； 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化； 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main()方法的那个类），虚拟机会先初始化这个主类； 当使用 JDK 1.7 的动态语言支持时，如果一个java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化； 2、被动引用 被动使用不会导致类的初始化，只有首次主动引用才会初始化。 以下三种情况是被动引用: 1、通过子类引用父类的静态字段，不会导致子类初始化。 测试: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 1、对于静态字段来说，只有直接定义了该字段的类才会被初始化 * 2、当一个类在初始化时，要求其父类全部已经初始化完毕了 * --X:+TraceClassLoading 用于追踪类的加载信息并打印出来 * jvm参数总结: * a、 -XX:+&lt;option&gt;， 表示开启option选项 * b、 -XX:-&lt;option&gt;， 表示关闭option选项 * c、 -XX:&lt;option&gt;=&lt;value&gt;，表示option选项的值设置为value */public class T1 &#123; public static void main(String[] args) &#123;// System.out.println(P1.p_str); //1、对于静态字段来说，只有直接定义了该字段的类才会被初始化 System.out.println(C1.c_str); //2、当一个类在初始化时，要求其父类全部已经初始化完毕了 &#125;&#125;class P1&#123; public static String p_str = \"parent str\"; static &#123; System.out.println(\"Parent static block~\"); &#125;&#125;class C1 extends P1&#123; public static String c_str = \"child str\"; static &#123; System.out.println(\"Child static block~\"); &#125;&#125;------------------------------------分析运行结果:第一种情况: System.out.println(P1.p_str);输出: Parent static block~parent str原因: 由于p_str是父类的，所以不会去加载C1(子类)第二种情况: System.out.println(C1.c_str); 输出:Parent static block~Child static block~child str原因:因为c_str是子类的，而子类加载完毕之前父类都要加载，所以会先输出父类static块 2、通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。 12345678910111213141516171819202122232425262728293031public class T4 &#123; public static void main(String[] args) &#123; P4 p4_1 = new P4(); System.out.println(\"=================\"); P4 p4_2 = new P4(); //这里不会再 执行P4的初始化代码块，只会在 首次主动引用 的时候初始化 P4[] p4s = new P4[1]; // 数组也不会初始化 System.out.println(p4s.getClass()); // 对于数组实例来说，其类型是由JVM在运行期间动态生成的，表示为[Lcom.zxin...T4 P4[][] p4s1 = new P4[1][1]; System.out.println(p4s1.getClass()); int[] ints = new int[1]; System.out.println(ints.getClass()); &#125;&#125;class P4&#123; static &#123; System.out.println(\"P4 static block~\"); &#125;&#125;输出:(只会进行一次初始化)P4 static block~=================class [Lp1_classloader.P4;class [[Lp1_classloader.P4;class [I 3、常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 1234567891011121314151617181920212223242526/** * final (常量) 对类加载的影响 * 常量在编译阶段会存入到调用这个常量的方法所在的类的常量池中 * 本质上，调用类并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 * 注意: 我们指的是 将常量存放到了T2的常量池中，之后T2与P就没有任何关系了(甚至可以将P.class删除) * * 助记符: * ldc表示将int,float或是String类型的常量值从常量池中推送至栈顶 * bipush表示将单字节(-128~127)的常量值推送至栈顶 * sipush表示将int型(-32768~32767)推送至栈顶 * iconst_1表示将int型的1推动到栈顶(只有-1~5有这种) */public class T2 &#123; public static void main(String[] args) &#123; System.out.println(P2.str); &#125;&#125;class P2&#123; public static final String str = \"P str\"; static &#123; System.out.println(\"P static block~\"); &#125;&#125; 输出: 1P str 但是要注意下面的情况: 当一个常量的值并非编译期间可以确定，那么其值就不会被放到调用类的常量池中，这时在程序运行时，会导致主动使用这个常量所在的类，显然会导致这个列被初始化。 123456789101112131415161718192021222324/** * 当一个常量的值并非编译期间可以确定，那么其值就不会被放到调用类的常量池中， * 这时在程序运行时，会导致主动使用这个常量所在的类，显然会导致这个列被初始化 */public class T3 &#123; public static void main(String[] args) &#123; System.out.println(P3.str); &#125;&#125;class P3&#123; public static final String str = UUID.randomUUID().toString(); static &#123; System.out.println(\"P static block~\"); &#125;&#125;输出(可以看到P3被加载(static块被输出)):P static block~b716f2dd-5a6e-4542-bc88-0cf833216de5 当一个接口在初始化时，并不要求其父接口都完成了初始化，只有在真正用到父接口的时候，如引用接口中定义的常量时，才会初始化。 123456789101112131415161718/** * 都可以删除 * 可以删除父接口PI5的.class文件 和 子接口CI5的.class文件 */public class T5&#123; public static void main(String[] args)&#123; System.out.println(CI5.b); &#125;&#125;interface PI5&#123; public static final int a = new Random().nextInt(4);&#125;interface CI5 extends PI5&#123; public static final int b = 5;&#125; 可以发现删除PI5.class文件之后，也可以运行（如果改成类class，且不加上final关键字，就会抛出异常，因为接口就算不加final关键字，默认也会加上(接口里面的变量默认是public static final)） 但是下面的动态引用还是会需要用到父类的初始化。 123456789101112131415161718/** * 这种情况两个都不能删除 */public class T5&#123; public static void main(String[] args)&#123; System.out.println(CI5.b); &#125;&#125;interface PI5&#123; public static final int a = new Random().nextInt(4);&#125;interface CI5 extends PI5&#123; //public static final int b = 5; public static final int b = new Random().nextInt(5);&#125; 删除父接口的.class之后，再次运行，也会抛出异常。（两个都不能删除） 3、类加载顺序 类的加载由上到下进行。 注意下列代码。 1234567891011121314151617181920212223242526272829303132public class T7 &#123; public static void main(String[] args) &#123; Singleton singleton = Singleton.getInstance(); System.out.println(\"counter1 : \" + Singleton.counter1); System.out.println(\"counter2 : \" + Singleton.counter2); &#125;&#125;/** * 初始化的顺序: 从上往下 */class Singleton&#123; public static int counter1; private static Singleton singleton = new Singleton(); private Singleton()&#123; counter1++; counter2++; //一开始是1，后面又变成了0 (准备阶段的意义)// System.out.println(\"类加载初始化的时候-------counter1 : \"+ counter1 + \", counter2 : \" + counter2); &#125; public static int counter2 = 0; //由1变成0 public static Singleton getInstance()&#123; return singleton; &#125;&#125; 上述代码输出： 12counter1 : 1counter2 : 0 因为类加载从上到下，虽然在私有构造方法中counter2被赋值成了1，但是初始化后面代码的时候，又被赋值成了0。 二、类加载过程 包含了加载、验证、准备、解析和初始化这 5 个阶段（也就是类的生命周期的前5个阶段）。 1、加载 加载是类加载的一个阶段，不要混淆。 加载过程完成以下三件事： 通过一个类的全限定名来获取定义此类的二进制字节流，即将类的.class文件中的二进制数据读入到内存中(这个就是类加载器做的事情)； 将这个字节流所代表的静态存储结构转化为方法区的运行时存储结构； 在内存中生成一个代表这个类的 Class 对象(java.lang.Class)，作为方法区这个类的各种数据的访问入口； 加载源（即二进制字节流可以从以下方式中获取）： 文件：从 ZIP 包读取，这很常见，最终成为日后 JAR、EAR、WAR 格式的基础。 网络：从网络中获取，这种场景最典型的应用是 Applet。 计算生成一个二进制流：运行时计算生成，这种场景使用得最多得就是动态代理技术，在 java.lang.reflect.Proxy 中，就是用了ProxyGenerator.generateProxyClass 的代理类的二进制字节流。 由其他文件生成：由其他文件生成，典型场景是 JSP 应用，即由 JSP 文件生成对应的 Class 类。 数据库：从数据库读取，这种场景相对少见，例如有些中间件服务器（如 SAP Netweaver）可以选择把程序安装到数据库中来完成程序代码在集群间的分发。 2、验证 目的：确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 文件格式验证：验证字节流是否符合 Class 文件格式的规范，并且能被当前版本的虚拟机处理。 是否以 0xCAFEBABE 开头，前四个字节为魔数； 版本号是否合理，如：JDK1.8（52.0）、JDK1.7（51.0）； 常量池中的常量是否有不被支持的类型； 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合 Java 语言规范的要求。 是否有父类-(除了Object类之外，所有的类都应该有父类)； 继承了 final 类？; 非抽象类实现了所有的抽象方法； 字节码验证（很复杂）：通过数据流和控制流分析，确保程序语义是合法、符合逻辑的。 运行检查； 栈数据类型和操作码数据参数吻合； 跳转指令指定到合理的位置；（保证不会跳转到方法体以外的字节码上） 符号引用验证：发生在虚拟机将符号引用转换为直接引用的时候，对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验。 常量池中描述类是否存在； 访问的方法或字段是否存在且有足够的权限； 3、准备 准备阶段正式为类变量分配内存并设置变量的初始值，但在到达初始化之前，类变量都没有初始化为真正的初始值。这些变量使用的内存都将在方法区中进行分配。类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。 实例变量不会在这阶段分配内存，它将会在对象实例化时随着对象一起分配在堆中。注意，实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次。 初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123，在初始化的 &lt;clinit&gt; 中才会被设置为1。 1public static int value = 123; // 只有在初始化的&lt;clinit&gt;中才会是123，在准备阶段只是0 有一个特例就是final型的，即static final型的变量会在准备的阶段就附上正确的值: 1public static final int value = 123; 4、解析 解析阶段是虚拟机将常量池的符号引用替换为直接引用的过程: 类或接口的解析 字段解析 类方法解析 接口方法解析 什么是符号引用和直接引用？ 符号引用：符号引用是一组符号来描述所引用的目标对象，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标对象并不一定已经加载到内存中。 直接引用：直接引用可以是直接指向目标对象的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机内存布局实现相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同，如果有了直接引用，那引用的目标必定已经在内存中存在。 符号引用就是字符串，这个字符串包含足够的信息，以供实际使用时可以找到相应的位置。你比如说某个方法的符号引用，如：“java/io/PrintStream.println:(Ljava/lang/String;)”。里面有类的信息，方法名，方法参数等信息。 当第一次运行时，要根据字符串的内容，到该类的方法表中搜索这个方法。运行一次之后，符号引用会被替换为直接引用，下次就不用搜索了。直接引用就是偏移量，通过偏移量虚拟机可以直接在该类的内存区域中找到方法字节码的起始位置。 5、初始化 初始化阶段才真正开始执行类中定义的 Java 程序代码。初始化阶段即虚拟机执行类构造器 &lt;clinit&gt;() 方法的过程。 在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源，即为类的静态变量赋予正确的初始值。 &lt;clinit&gt;() 方法具有以下特点： 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码： 1234567public class Test &#123; static &#123; i = 0; // 给变量赋值可以正常编译通过 System.out.print(i); // 这句编译器会提示“非法向前引用” &#125; static int i = 1;&#125; 与类的构造函数（或者说实例构造器&lt;init&gt;()）不同，不需要显式的调用父类的构造器。虚拟机会自动保证在子类的 &lt;clinit&gt;() 方法运行之前，父类的 &lt;clinit&gt;() 方法已经执行结束。因此虚拟机中第一个执行&lt;clinit&gt;()方法的类肯定为 java.lang.Object。 由于父类的 &lt;clinit&gt;() 方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。例如以下代码： 12345678910111213141516class Parent &#123; public static int A = 1; static &#123; A = 2; &#125;&#125;class Sub extends Parent &#123; public static int B = A;&#125;public class Test &#123; public static void main(String[] args) &#123; System.out.println(Sub.B); // 2 &#125;&#125; &lt;clinit&gt;() 方法对于类或接口不是必须的，如果一个类中不包含静态语句块，也没有对类变量的赋值操作，编译器可以不为该类生成&lt;clinit&gt;()方法。 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 &lt;clinit&gt;()方法。但接口与类不同的是，执行接口的 &lt;clinit&gt;() 方法不需要先执行父接口的 &lt;clinit&gt;() 方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 &lt;clinit&gt;() 方法。 虚拟机会保证一个类的 &lt;clinit&gt;()方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的&lt;clinit&gt;()方法，其它线程都会阻塞等待，直到活动线程执行&lt;clinit&gt;() 方法完毕。如果在一个类的 &lt;clinit&gt;() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。 三、类加载器 虚拟机设计团队把类加载阶段中的 “通过一个类的全限定名来获取描述此类的二进制字节流（即字节码）” 这个动作放到 Java 虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类（通过一个类的全限之名获取描述此类的二进制字节流）。实现这个动作的代码模块称为 “类加载器”。 简而言之: 类加载器ClassLoader就是加载其他类的类，它负责将字节码文件加载到内存，创建Class对象。 运行Java程序，就是执行java这个命令，指定包含main方法的完整类名，以及一个classpath，即类路径。类路径可以有多个，对于直接的class文件，路径是class文件的根目录，对于jar包，路径是jar包的完整名称（包括路径和jar包名）。 Java运行时，会根据类的完全限定名寻找并加载类，寻找的方式基本就是在系统类和指定的类路径中寻找，如果是class文件的根目录，则直接查看是否有对应的子目录及文件，如果是jar文件，则首先在内存中解压文件，然后再查看是否有对应的类。 负责加载类的类就是类加载器，它的输入是完全限定的类名，输出是Class对象。 1、类与类加载器 两个类相等，需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。 这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom()方法、isInstance()方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true。 2、类加载器分类 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），这个类加载器用 C++ 实现，是虚拟机自身的一部分； 所有其他类的加载器，这些类由 Java 实现，独立于虚拟机外部，并且全都继承自抽象类 java.lang.ClassLoader。 按照开发人员来说，类加载器不是只有一个，一般程序运行时，都会有三个： 启动类加载器(Bootstrap ClassLoader)：这个加载器是Java虚拟机实现的一部分，不是Java语言实现的，一般是C++实现的，它负责加载Java的基础类，主要是&lt;JAVA_HOME&gt;/lib/rt.jar，我们日常用的Java类库比如String，ArrayList等都位于该包内。 扩展类加载器(Extension ClassLoader)：这个加载器的实现类是sun.misc.Launcher$ExtClassLoader，它负责加载Java的一些扩展类，一般是&lt;JAVA_HOME&gt;/lib/ext目录中的jar包。 应用程序类加载器(Application ClassLoader)：这个加载器的实现类是sun.misc.Launcher$AppClassLoader，它负责加载应用程序的类，包括自己写的和引入的第三方法类库，即所有在类路径中指定的类。 3、双亲委派模型 上面的三种加载器有一定的关系，可以认为是父子关系，Application ClassLoader的父亲是Extension ClassLoader，Extension的父亲是Bootstrap ClassLoader，注意不是父子继承关系，而是父子委派关系，子ClassLoader有一个变量parent指向父ClassLoader，在子ClassLoader加载类时，一般会首先通过父ClassLoader加载，具体来说，在加载一个类时，基本过程是： 判断是否已经加载过了，加载过了，直接返回Class对象，一个类只会被一个ClassLoader加载一次。 如果没有被加载，先让父ClassLoader去加载，如果加载成功，返回得到的Class对象。 在父ClassLoader没有加载成功的前提下，自己尝试加载类。 这个过程一般被称为&quot;双亲委派&quot;模型，即优先让父ClassLoader去加载。为什么要先让父ClassLoader去加载呢？这样，可以避免Java类库被覆盖的问题，比如用户程序也定义了一个类java.lang.String，通过双亲委派，java.lang.String只会被Bootstrap ClassLoader加载，避免自定义的String覆盖Java类库的定义。需要了解的是，&quot;双亲委派&quot;虽然是一般模型，但也有一些例外，比如： 自定义的加载顺序：尽管不被建议，自定义的ClassLoader可以不遵从&quot;双亲委派&quot;这个约定，不过，即使不遵从，以&quot;java&quot;开头的类也不能被自定义类加载器加载，这是由Java的安全机制保证的，以避免混乱。 网状加载顺序：在OSGI框架中，类加载器之间的关系是一个网，每个OSGI模块有一个类加载器，不同模块之间可能有依赖关系，在一个模块加载一个类时，可能是从自己模块加载，也可能是委派给其他模块的类加载器加载。 父加载器委派给子加载器加载：典型的例子有JNDI服务(Java Naming and Directory Interface)，它是Java企业级应用中的一项服务。 一个程序运行时，会创建一个Application ClassLoader，在程序中用到ClassLoader的地方，如果没有指定，一般用的都是这个ClassLoader，所以，这个ClassLoader也被称为系统类加载器(System ClassLoader)。 如果加载同一个类，该使用哪一个类？父类的。 为什么要使用双亲委派模型？主要是为了避免重复加载的问题。 4、理解ClassLoader 类ClassLoader是一个抽象类，Application ClassLoader和Extension ClassLoader的具体实现类分别是sun.misc.Launcher$AppClassLoader和sun.misc.Launcher$ExtClassLoader，Bootstrap ClassLoader不是由Java实现的，没有对应的类。 每个Class对象都有一个方法，可以获取实际加载它的ClassLoader，方法是： 1public ClassLoader getClassLoader() ClassLoader有一个方法，可以获取它的父ClassLoader： 1public final ClassLoader getParent() 如果ClassLoader是Bootstrap ClassLoader，返回值为null。 测试: 12345678910111213public class ClassLoaderDemo &#123; public static void main(String[] args) &#123; ClassLoader cl = ClassLoaderDemo.class.getClassLoader(); while (cl != null) &#123; System.out.println(cl.getClass().getName()); cl = cl.getParent(); // 一直向上 &#125; System.out.println(String.class.getClassLoader()); // 最后 = null &#125;&#125; 输出: 123sun.misc.Launcher$AppClassLoadersun.misc.Launcher$ExtClassLoadernull ClassLoader有一个静态方法，可以获取默认的系统类加载器： 1public static ClassLoader getSystemClassLoader() ClassLoader中有一个主要方法，用于加载类： 1public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException 测试: 1234567891011121314151617/** * 由于委派机制，Class的getClassLoader()方法返回的不一定是调用loadClass的ClassLoader， * 比如，下面代码中，java.util.ArrayList实际由BootStrap ClassLoader加载，所以返回值就是null。 */public class Test &#123; public static void main(String[] args) &#123; ClassLoader cl = ClassLoader.getSystemClassLoader(); try &#123; Class&lt;?&gt; cls = cl.loadClass(\"java.util.ArrayList\"); // 加载这个 ClassLoader actualLoader = cls.getClassLoader(); System.out.println(actualLoader); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 由于委派机制，Class的getClassLoader()方法返回的不一定是调用loadClass的ClassLoader，比如，上面代码中，java.util.ArrayList实际由BootStrap ClassLoader加载，所以返回值就是null。 在反射中，有两个方法: 12public static Class&lt;?&gt; forName(String className)public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader) 第一个方法使用系统类加载器加载。第二个指定ClassLoader，参数initialize表示，加载后，是否执行类的初始化代码(如static语句块)，没有指定默认为true。 ClassLoader的loadClass方法和上面forName方法都可以加载类，它们有什么不同呢？基本是一样的，不过，有一个不同，ClassLoader的loadClass不会执行类的初始化代码，看个例子： 12345678910111213141516171819public class CLInitDemo &#123; static class Hello &#123; static &#123; System.out.println(\"hello\"); &#125; &#125; public static void main(String[] args) &#123; ClassLoader cl = ClassLoader.getSystemClassLoader(); String className = CLInitDemo.class.getName() + \"$Hello\"; try &#123;// Class&lt;?&gt; cls = cl.loadClass(className); //没有输出 Class&lt;?&gt; cls = Class.forName(className); //输出 hello &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 使用ClassLoader加载静态内部类Hello，Hello有一个static语句块，输出&quot;hello&quot;，运行该程序，类被加载了，但没有任何输出，即static语句块没有被执行。如果将loadClass的语句换为：Class&lt;?&gt; cls = Class.forName(className);，则static语句块会被执行，屏幕将输出&quot;hello&quot;。 面试题: Java中Class.forName和classloader都可以用来对类进行加载，他们的区别?。 Class.forName()除了将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块。 而classloader只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容，只有在newInstance才会去执行static块。 Class.forName(name,initialize,loader)带参数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象。 看一下ClassLoader的loadClass的源代码: 123public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125; 它调用了另一个loadClass方法，其主要代码为(省略了一些代码，加了注释，以便于理解)： 1234567891011121314151617181920212223242526272829protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先，检查类是否已经被加载了 Class c = findLoadedClass(name); if (c == null) &#123; //没被加载，先委派父ClassLoader或BootStrap ClassLoader去加载 try &#123; if (parent != null) &#123; //委派父ClassLoader，resolve参数固定为false c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; //没找到，捕获异常，以便尝试自己加载 &#125; if (c == null) &#123; // 自己去加载，findClass才是当前ClassLoader的真正加载方法 c = findClass(name); &#125; &#125; if (resolve) &#123; // 链接，执行static语句块 resolveClass(c); &#125; return c; &#125;&#125; 参数resolve类似Class.forName中的参数initialize，可以看出，其默认值为false，即使通过自定义ClassLoader重写loadClass，设置resolve为true，它调用父ClassLoader的时候，传递的也是固定的false。 findClass是一个protected方法，类ClassLoader的默认实现就是抛出ClassNotFoundException，子类应该重写该方法，实现自己的加载逻辑，后文我们会看个具体例子。 5、自定义类加载器 载器步骤： 定义一个类，继承 ClassLoader； 重写 loadClass 方法； 实例化 Class 对象； 自定义类加载器的优势 类加载器是 Java 语言的一项创新，也是 Java 语言流行的重要原因之一，它最初的设计是为了满足 java applet 的需求而开发出来的； 高度的灵活性； 通过自定义类加载器可以实现热部署； 代码加密；","categories":[{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/tags/JVM/"}]},{"title":"高并发下的SpringCloud参数优化","slug":"Java框架/SpringCloud/高并发下的SpringCloud参数优化","date":"2020-03-04T15:53:24.232Z","updated":"2020-03-04T15:53:24.232Z","comments":true,"path":"2020/03/04/Java框架/SpringCloud/高并发下的SpringCloud参数优化/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E6%A1%86%E6%9E%B6/SpringCloud/%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84SpringCloud%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/","excerpt":"","text":"相信不少朋友都在自己公司使用Spring Cloud框架来构建微服务架构，如果只是用户量很少的传统IT系统，使用Spring Cloud可能还暴露不出什么问题. 如果是较多用户量，高峰每秒高达上万并发请求的互联网公司的系统，使用Spring Cloud技术就有一些问题需要注意了. 听说的一个业务场景 故事的开始 朋友A的公司做互联网类的创业，组建了一个小型研发团队，上来就用了Spring Cloud技术栈来构建微服务架构的系统. 一段时间没日没夜的加班，好不容易核心业务系统给做出来了，平时正常QA测试没发现什么大毛病，感觉性能还不错，一切都很完美 问题初现 然后系统就这么上线了，一开始用户规模很小，注册用户量小几十万，日活几千用户. 每天都有新的数据进入数据库的表中，就这么日积月累的，没想到数据规模居然慢慢吞吞增长到了单表几百万. 这个时候呢，看起来也没太大的毛病，就是有用户反映，系统有些操作，会感觉卡顿几秒钟，会刷不出来页面. 这是为啥呢？ 核心原因是单表数据量大了一些，达到了几百万. 有个别服务，跑的SQL比较复杂，一大堆的多表关联 并且还没有设计好索引，或者是设计了索引，但无奈一些小弟写了上百行的大SQL，SQL实在太复杂了，那么一个SQL跑出来好几秒肯定是正常的. 如果大家对微服务框架有点了解的话，应该知道，比如Feign + Ribbon组成的服务调用框架，是有接口调用超时这一说的，有一些参数可以设置接口调用的超时时间. 如果你调用一个接口，好几秒刷不出来，人家就超时异常返回，用户就刷不出来页面了. 饮鸩止渴 一般碰到这种事情，一大坨屎一样的SQL摆在那儿，写SQL的人过一个月自己都看不懂了，80%的工程师看着都不愿意去花时间重写和优化. 一是修改的人力成本太高，二是谁敢负担这责任呢？ 系统跑的好好的，就是慢了点而已，结果你硬是乱改一通，重构，把系统核心业务流程搞挂了怎么办？ 所以，那些兄弟第一反应是：增加超时时间啊！接口慢点可以，但是别超时不响应啊！ 咱们让接口执行个几秒把结果返回，用户不就可以刷出来页面了！不用重构系统了啊！轻松+愉快！ 如何增加呢？看下面的参数 12345678910ribbon: ConnectTimeout: 30000 ReadTimeout: 30000hystrix: command: default: execution: isolation: thread: timeoutInMillisconds: 60000 所以设置超时一般设置两个地方，feign和ribbon那块的超时，还有hystrix那块的超时.其中后者那块的超时一般必须大于前者. 好了，日子在继续… 优化了参数后，看上去效果不错，用户虽然觉得有的页面慢是慢点，但是起码过几秒能刷出来. 这个时候，日活几千的用户量，压根儿没什么并发可言，高峰期每秒最多一二十并发请求罢了. 问题爆发 随着时间的推移，公司业务高速发展…… 那位兄弟的公司，在系统打磨成熟，几万用户试点都ok之后，老板立马拿到一轮几千万的融资. 公司上上下下意气风发啊！紧接着就是组建运营团队，地推团队，全国大范围的推广. 用户量上来后，悲剧的事情就发生了. 高峰期每秒的并发请求居然达到了近万的程度，研发团队的兄弟们哪里敢怠慢！在这个过程中，先是紧张的各种扩容服务，一台变两台，两台变四台. 然后数据库主从架构挂上去，读写分离是必须的，否则单个数据库服务器哪能承载那么大的请求！多搞几个从库，扛一下大量的读请求，这样基本就扛住了. 正准备坐下来喝口茶、松口气，更加悲剧的事情就发生了. 在这个过程中，那些兄弟经常会发现高峰期，系统的某个功能页面，突然就整个hang死了，就是没法再响应任何请求！所有用户刷新这个页面全部都是无法响应！ 这是为什么呢？原因很简单啊！一个服务A的实例里，专门调用服务B的那个线程池里的线程，总共可能就几十个.每个线程调用服务B都会卡住5秒钟. 那如果每秒钟过来几百个请求这个服务实例呢？一下子那个线程池里的线程就全部hang死了，没法再响应任何请求了. 这个时候咋办？兄弟们只能祭出程序员最古老的法宝，重启机器！ 遇到页面刷不出来，只能重启机器，相当于短暂的初始化了一下机器内的资源. 然后接着运行一段时间，又卡死，再次重启！真是令人崩溃啊！用户们的体验是极差的，老板的心情是愤怒的！ 这里学到的经验 12明明应该去优化服务接口性能，结果硬是调大了超时时间.结果导致并发量高了，对那个服务的调用直接hang死，系统的核心页面刷不出来，影响用户体验了. 追本溯源 第一步 关键点，优化图中核心服务B的性能.互联网公司，核心业务逻辑，面向C端用户高并发的请求，不要用上百行的大SQL，多表关联，那样单表几百万行数据量的话，会导致一下执行好几秒. 其实最佳的方式，就是对数据库就执行简单的单表查询和更新，然后复杂的业务逻辑全部放在java系统中来执行，比如一些关联，或者是计算之类的工作. 这一步干完了之后，那个核心服务B的响应速度就已经优化成几十毫秒了，是不是很开心？从几秒变成了几十毫秒！ 第二步 那个超时的时间，也就是上面那段ribbon和hystrix的超时时间设置. 奉劝各位同学，不要因为系统接口的性能过差而懒惰，搞成几秒甚至几十秒的超时，一般超时定义在1秒以内，是比较通用以及合理的. 为什么这么说？ 因为一个接口，理论的最佳响应速度应该在200ms以内，或者慢点的接口就几百毫秒. 如果一个接口响应时间达到1秒+，建议考虑用缓存、索引、NoSQL等各种你能想到的技术手段，优化一下性能. 否则你要是胡乱设置超时时间是几秒，甚至几十秒，万一下游服务偶然出了点问题响应时间长了点呢？那你这个线程池里的线程立马全部卡死！ 具体hystrix的线程池以及超时时间的最佳生产实践，请见下一篇文章：《微服务架构如何保障双11狂欢下的99.99%高可用》 这两步解决之后，其实系统表现就正常了，核心服务B响应速度很快，而且超时时间也在1秒以内，不会出现hystrix线程池频繁卡死的情况了. 第三步 事儿还没完，你要真觉得两步就搞定了，那还是经验不足. 如果你要是超时时间设置成了1秒，如果就是因为偶然发生的网络抖动，导致接口某次调用就是在1.5秒呢？这个是经常发生的，因为网络的问题，接口调用偶然超时. 所以此时配合着超时时间，一般都会设置一个合理的重试，如下所示： 123456ribbon: ConnectTimeout: 10000 ReadTimeout: 10000 OKToRetryOnAllOperations: true MaxAutoRetries: 1 MaxAutoRetriesNextServer: 1 设置这段重试之后，Spring Cloud中的Feign + Ribbon的组合，在进行服务调用的时候，如果发现某台机器超时请求失败，会自动重试这台机器，如果还是不行会换另外一台机器重试. 这样由于偶尔的网络请求造成的超时，不也可以通过自动重试避免了？ 第四步 其实事儿还没完，如果把重试参数配置了，结果你居然就放手了，那还是没对人家负责任啊！ 你的系统架构中，只要涉及到了重试，那么必须上接口的幂等性保障机制. 否则的话，试想一下，你要是对一个接口重试了好几次，结果人家重复插入了多条数据，该怎么办呢？ 其实幂等性保证本身并不复杂，根据业务来，常见的方案： 可以在数据库里建一个唯一索引，插入数据的时候如果唯一索引冲突了就不会插入重复数据 或者是通过redis里放一个唯一id值，然后每次要插入数据，都通过redis判断一下，那个值如果已经存在了，那么就不要插入重复数据了. 类似这样的方案还有一些.总之，要保证一个接口被多次调用的时候，不能插入重复的数据. 优化后","categories":[{"name":"Java框架","slug":"Java框架","permalink":"http://blog.tgyf.com/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/categories/SpringCloud/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/tags/SpringCloud/"}]},{"title":"SpringCloud微服务杂谈","slug":"Java框架/SpringCloud/SpringCloud微服务杂谈","date":"2020-03-04T15:17:25.591Z","updated":"2020-03-04T15:17:25.592Z","comments":true,"path":"2020/03/04/Java框架/SpringCloud/SpringCloud微服务杂谈/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E6%A1%86%E6%9E%B6/SpringCloud/SpringCloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9D%82%E8%B0%88/","excerpt":"","text":"微服务的定义 微服务是一种架构风格，其理念是把一个系统定义成多个微服务组成，每个服务都只关心自己的业务，而且很好的完成一件事情，微服务与微服务之间相互独立，互相不影响。这种思想延续了java高类聚的原则，每个类只负责完成自己的业务。 微服务的演变 单体架构 传统的项目是以一个整体的方式呈现，整个系统打成一个jar包部署，这样的结构会毋庸置疑会存在一些问题。一是开发，所有的开发人员在一个项目上开发，一是增加了复杂度，二是加大了代码的管理成本。其次是部署，不管是多小的改动都需要整个项目上传更新，这无疑加大了更新的工作量，然后是稳定性，如果功能出现问题，很有可能影响到整个系统阻塞。 SOA服务治理 SOA(Service Oriented Architecture)面向服务的架构，这是一种架构的设计理念，其核心思想就是把整个系统的业务模块和功能中心拆分成独立的服务，比如常见的业务订单服务，功能消息推送功能。每个服务相互独立，服务与服务之间通过网络互相调用。其设计沿用的是低耦合，高类聚的思想。 RPC(Remote Procedure call)远程服务调用，既然设计到服务与服务之间的调用，他还有一个作用就是解决了让远程调用时像本地调用一样方便，让作者感知不到远程调用的逻辑。其核心理念是通过反向代理然后注入一个对象给调用着，这样调用着就这样直接使用服务提供方的方法了。 微服务 微服务是将复杂的系统拆分成很多个小的业务系统，这里我们称这些小的业务系统为组件，也就是微服务。组件，相比于传统系统，以代码库的形式调用，微服务把组件以服务的形式提供远程调用。微服务，强调的是更细粒度的拆分，更精细的拆分更加方便解耦和复用，是系统更清晰，更容易维护。微服务，强调的是更独立，独立的数据库，独立部署，独立运行，这使得微服务的应用更加灵活和快速。 REST是一种软件架构风格，可以提高系统的伸缩性，降低开发的复杂度。如果一个系统能满足REST的这几个条件，那么就是Restful 风格。它以资源为中心，名称是资源地址，动词则表示对资源的操作，所有Rest使用的是http协议。相比于RPC 关注于方法的调用，但是RPC支持多种协议，从效率上来说高于http。 解决什么问题 开发维护：把业务分成很小的服务，每个服务都相互独立，这样一是耦合低，结构清晰。不管是编码人员还是维护人员都只需要关注自己负责的服务。 负载均衡：服务最小化有个好处毋庸置疑就是负载，在现在的互联网项目，为了承受大的流量，会用负载的方式来增加服务器的配置和数量。有人说如果传统项目用集群的方式也能实现负载，但是如果以微服务的方式可以更有针对性，更精确的扩容，节约资源。比如订单模块的压力比较大，我就只需要为订单服务增加服务器，而不需要真个系统都增加。 版本迭代：微服务的设计让偶和最低化，实现分而治之。在版本迭代的时候，只需要更新有变动的服务，而不需要整个模块更新。这使得迭代工作更加快速，便捷。 稳定性：既然版本迭代可以分开来实现，这样在宏观上来说多整个系统的稳定性是有好处的。就算是测试不到位，发现bug，这样也只会影响更新的模块，而不会导致整个系统的阻塞，雪崩。比如购物车模块出问题不会影响用户下单功能。","categories":[{"name":"Java框架","slug":"Java框架","permalink":"http://blog.tgyf.com/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/categories/SpringCloud/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/tags/SpringCloud/"}]},{"title":"SpringCloud - Gateway","slug":"Java框架/SpringCloud/SpringCloud - Gateway","date":"2020-03-04T15:08:29.343Z","updated":"2020-03-04T15:08:29.343Z","comments":true,"path":"2020/03/04/Java框架/SpringCloud/SpringCloud - Gateway/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E6%A1%86%E6%9E%B6/SpringCloud/SpringCloud%20-%20Gateway/","excerpt":"","text":"Spring Cloud Gateway Gateway是spring cloud 推出的新的网关路由，它关注于安全性，网关路由，限流控制等，是第二代网关路由器。 Spring Cloud Gateway使用的是Spring Boot和Spring Webflux提供的Netty底层环境，不能和传统的Servlet容器一起使用，也不能打包成一个WAR包。 引入了依赖默认即开启gateway了，如果暂时不想使用这个功能，这可以配置spring.cloud.gateway.enabled=false即可。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; (一)工作原理 当客户端发送请求到Spring Cloud Gateway，Gateway Handler Mapping会匹配Route映射分发到Gateway Web Handler。handler会将请求经过一系列的filter处理，代理请求前，会执行左右的”pre” filter逻辑，代理请求后，会执行所有”post” filter逻辑。 (二)谓词工厂 建议仔细阅读: 官方文档1 官方文档2 2.1 Datetime 接受一个时间参数，满足时间条件后路由 技巧：时间可使用 System.out.println(ZonedDateTime.now()); 打印，然后即可看到时区。例如：2019-09-29T16:50:42.579+08:00[Asia/Shanghai] 时间格式的相关逻辑： 默认时间格式：org.springframework.format.support.DefaultFormattingConversionService#addDefaultFormatters 时间格式注册：org.springframework.format.datetime.standard.DateTimeFormatterRegistrar#regi Before Route Predicate Factory:使用时间作为匹配规则，只要当前时间小于设定时间，路由才会匹配请求。 id:表示路由名称 uri:路由转发的地址 predicates:断言规则 Before:表示当前时间小于设定时间 123456789101112spring: cloud: gateway: routes: - id: before_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当请求时的时间Before配置的时间时，才会转发到用户微服务 # 目前配置不会进该路由配置，所以返回404 # 将时间改成 &gt; now的时间，则访问localhost:8040&#x2F;** -&gt; user-center&#x2F;** # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - Before&#x3D;2019-09-30T17:42:47.789-07:00[America&#x2F;Denver] After Route Predicate Factory:使用的是时间作为匹配规则，只要当前时间大于设定时间，路由才会匹配请求 id:表示路由名称 uri:路由转发的地址 predicates:断言规则 After:表示大于设定时间 123456789101112spring: cloud: gateway: routes: - id: after_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当请求时的时间After配置的时间时，才会转发到用户微服务 # 目前配置不会进该路由配置，所以返回404 # 将时间改成 &lt; now的时间，则访问localhost:8040&#x2F;** -&gt; user-center&#x2F;** # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - After&#x3D;2030-01-20T17:42:47.789-07:00[America&#x2F;Denver] Between Route Predicate Factory:使用两个时间作为匹配规则，只要当前时间大于第一个设定时间，并小于第二个设定时间，路由才会匹配请求。 id:表示路由名称 uri:路由转发的地址 predicates:断言规则 Between:表示大于第一个设定时间并小于第二个设定时间 1234567891011spring: cloud: gateway: routes: - id: between_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当请求时的时间Between配置的时间时，才会转发到用户微服务 # 因此，访问localhost:8040&#x2F;** -&gt; user-center&#x2F;** # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - Between&#x3D;2019-01-20T17:42:47.789-07:00[America&#x2F;Denver], 2027-01-21T17:42:47.789-07:00[America&#x2F;Denver] 2.2 Cookie Cookie Route Predicate Factory:使用的是cookie名字和正则表达式的value作为两个输入参数，请求的cookie需要匹配cookie名和符合其中value的正则。 1234567891011spring: cloud: gateway: routes: - id: cookie_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当带有名为somecookie，并且值符合正则ch.p的Cookie时，才会转发到用户微服务 # 如Cookie满足条件，则访问http:&#x2F;&#x2F;localhost:8040&#x2F;** -&gt; user-center&#x2F;** # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - Cookie&#x3D;somecookie, ch.p 2.3 Header Header Route Predicate Factory:使用的是两个参数，一个header的name，一个是正则匹配的value。 请求头 header中带 X-Request-Id，且值为数字，允许路由。 1234567891011spring: cloud: gateway: routes: - id: header_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当带有名为X-Request-Id，并且值符合正则\\d+的Header时，才会转发到用户微服务 # 如Header满足条件，则访问http:&#x2F;&#x2F;localhost:8040&#x2F;** -&gt; user-center&#x2F;** # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - Header&#x3D;X-Request-Id, \\d+ 2.4 Host 1234567891011spring: cloud: gateway: routes: - id: host_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当名为Host的Header符合**.somehost.org或**.anotherhost.org时，才会转发用户微服务 # 如Host满足条件，则访问http:&#x2F;&#x2F;localhost:8040&#x2F;** -&gt; user-center&#x2F;** # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - Host&#x3D;**.somehost.org,**.anotherhost.org 2.5 Method 1234567891011spring: cloud: gateway: routes: - id: method_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当HTTP请求方法是GET时，才会转发用户微服务 # 如请求方法满足条件，访问http:&#x2F;&#x2F;localhost:8040&#x2F;** -&gt; user-center&#x2F;** # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - Method&#x3D;GET 2.6 Path 官方文档：segment小技巧 1234567891011spring: cloud: gateway: routes: - id: path_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当访问路径是&#x2F;users&#x2F;*或者&#x2F;some-path&#x2F;**，才会转发用户微服务 # segment是一个特殊的占位符，单层路径匹配 # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center&#x2F;users&#x2F;1 - Path&#x3D;&#x2F;users&#x2F;&#123;segment&#125;,&#x2F;some-path&#x2F;** 2.7 Query 示例1： 12345678910spring: cloud: gateway: routes: - id: query_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当请求带有baz的参数，才会转发到用户微服务 # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1?baz&#x3D;xx -&gt; user-center的&#x2F;users&#x2F;1 - Query&#x3D;baz 示例2： 12345678910spring: cloud: gateway: routes: - id: query_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当请求带有名为foo的参数，且参数值符合正则ba.，才会转发到用户微服务 # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1?baz&#x3D;baz -&gt; user-center的&#x2F;users&#x2F;1?baz&#x3D;baz - Query&#x3D;foo, ba. 2.8 RemoteAddr 官方文档：代理的ip小技巧 XForwardedRemoteAddressResolver::trustAll得到的RemoteAddressResolver总是获取X-Forwarded-For的第一个ip地址作为remote address，这种方式就比较容易被伪装的请求欺骗，模拟请求很容易通过设置初始的X-Forwarded-For头信息，就可以欺骗到gateway。 XForwardedRemoteAddressResolver::maxTrustedIndex得到的RemoteAddressResolver则会在X-Forwarded-For信息里面，从右到左选择信任最多maxTrustedIndex个ip，因为X-Forwarded-For是越往右是越接近gateway的代理机器ip，所以是越往右的ip，信任度是越高的。 那么如果前面只是挡了一层Nginx的话，如果只需要Nginx前面客户端的ip，则maxTrustedIndex取1，就可以比较安全地获取真实客户端ip。 12345678910spring: cloud: gateway: routes: - id: remoteaddr_route uri: lb:&#x2F;&#x2F;user-center predicates: # 当且仅当请求IP是192.168.1.1&#x2F;24网段，例如192.168.1.10，才会转发到用户微服务 # eg. 访问http:&#x2F;&#x2F;localhost:8040&#x2F;users&#x2F;1 -&gt; user-center的&#x2F;users&#x2F;1 - RemoteAddr&#x3D;192.168.1.1&#x2F;24 2.9 Weigth Weight Route Predicate Factory: 12 (三)过滤器工厂 Route Predicate 决定路由到哪个路径，那么过滤器就是允许修改HTTP请求的一些属性。spring cloud 内置了一部分过滤器，也可以自定义过滤器 3.1. AddRequestHeader GatewayFilter Factory 3.2. AddRequestParameter GatewayFilter Factory 3.3. AddResponseHeader GatewayFilter Factory 3.4. DedupeResponseHeader GatewayFilter Factory 3.5. Hystrix GatewayFilter Factory 3.6. FallbackHeaders GatewayFilter Factory 3.7. MapRequestHeader GatewayFilter Factory 3.8. PrefixPath GatewayFilter Factory 3.9. PreserveHostHeader GatewayFilter Factory 3.10. RequestRateLimiter GatewayFilter Factory 3.11. RedirectTo GatewayFilter Factory 3.12. RemoveHopByHopHeadersFilter GatewayFilter Factory 3.13. RemoveRequestHeader GatewayFilter Factory 3.14. RemoveResponseHeader GatewayFilter Factory 3.15. RemoveRequestParameter GatewayFilter Factory 3.16. RewritePath GatewayFilter Factory 3.17. RewriteLocationResponseHeader GatewayFilter Factory 3.18. RewriteResponseHeader GatewayFilter Factory 3.19. SaveSession GatewayFilter Factory 3.20. SecureHeaders GatewayFilter Factory 3.21. SetPath GatewayFilter Factory 3.22. SetRequestHeader GatewayFilter Factory 3.23. SetResponseHeader GatewayFilter Factory 3.24. SetStatus GatewayFilter Factory 3.25. StripPrefix GatewayFilter Factory 3.26. Retry GatewayFilter Factory 3.27. RequestSize GatewayFilter Factory 3.28. Modify Request Body GatewayFilter Factory 3.29. Modify Response Body GatewayFilter Factory 3.30. Default Filters","categories":[{"name":"Java框架","slug":"Java框架","permalink":"http://blog.tgyf.com/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/categories/SpringCloud/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"http://blog.tgyf.com/tags/Gateway/"}]},{"title":"SpringCloud - Eureka","slug":"Java框架/SpringCloud/SpringCloud - Eureka","date":"2020-03-04T14:56:55.247Z","updated":"2020-03-04T14:56:55.248Z","comments":true,"path":"2020/03/04/Java框架/SpringCloud/SpringCloud - Eureka/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E6%A1%86%E6%9E%B6/SpringCloud/SpringCloud%20-%20Eureka/","excerpt":"","text":"服务发现之Eureka/Ribbon 深度剖析服务发现组件~Netflix Eureka https://zhuanlan.zhihu.com/p/24829766 深入理解Ribbon之源码解析 https://blog.csdn.net/forezp/article/details/74820899 (一)Spring Cloud Eureka服务端主要配置项 配置参数(eureka.server.*) 默认值 说明 enableSelfPreservation true 启用注册中心的自保护机制，Eureka 如果统计到15分钟之内损失&gt;15%的微服务心跳，则将会触发自保护机制，不再剔除服务提供者。 waitTimeInMsWhenSyncEmpty 1000 * 60 * 5 在Eureka服务器获取不到集群里对等服务器上的实例时，需要等待的时间，单位为毫秒，默认为1000 * 60 * 5。单机开发模式建议设置为0。 (二)Spring Cloud Eureka客户端主要配置项 配置参数(eureka.client.*) 默认值 说明 serviceUrl 指定服务注册中心地址，类型为 HashMap，并设置有一组默认值，默认的Key为defaultZone；默认的Value为 http://localhost:8761/eureka ，如果服务注册中心为高可用集群时，多个注册中心地址以逗号分隔。如果服务注册中心加入了安全验证，这里配置的地址格式为：http://:@localhost:8761/eureka 其中 为安全校验的用户名； 为该用户的密码 fetchRegistry true 是否从Eureka服务端获取注册信息 registryFetchIntervalSeconds 30 从Eureka服务端获取注册信息的间隔时间，单位为秒 registerWithEureka true 是否要将自身的实例信息注册到Eureka服务端 (三)Spring Cloud Eureka实例主要配置项 配置参数(eureka.instance.*) 默认值 说明 leaseRenewalIntervalInSeconds 30 Eureka客户端向服务端发送心跳的时间间隔，单位为秒 leaseExpirationDurationInSeconds 90 Eureka服务端在收到最后一次心跳之后等待的过期时间上限，单位为秒。超过该时间没有收到心跳，则服务端会将该服务实例从服务清单中剔除，从而禁止服务调用请求被发送到该实例上 appname 服务名，默认取spring.application.name的配置值，如果没有则为unknown hostname 主机名，不配置的时候将根据操作系统的主机名来获取 instance-id 主机名 注册到eureka的实例id，推荐spring.cloud.client.ipaddress:{spring.cloud.client.ipaddress}:spring.cloud.client.ipaddress:{spring.application.name}😒{server.port} (四)Spring Cloud Ribbon主要配置项 配置参数({svc}.ribbon.*) 默认值 说明 ConnectionTimeout 1000ms 连接超时时间 ReadTimeout 1000ms 读取超时时间 ServerListRefreshInterval 30秒 刷新服务列表源的间隔时间 NFLoadBalancerClassName com.netflix.loadbalancer.ZoneAwareLoadBalancer 定制ILoadBalancer实现 NFLoadBalancerRuleClassName com.netflix.loadbalancer.ZoneAvoidanceRule 定制IRule实现 NFLoadBalancerPingClassName com.netflix.loadbalancer.DummyPing 定制IPing NIWSServerListClassName com.netflix.loadbalancer.ConfigurationBasedServerList 定制ServerList ServerListUpdateClassName com.netflix.loadbalancer.PollingServerListUpdater 定制ServerListUpdater NIWSServerListFilterClassName com.netflix.loadbalancer.ZonePreferenceServerListFilter 定制SeverListFilter (五)Spring Cloud Eureka 自保护模式 翻墙查阅：https://medium.com/@fahimfarookme/the-mystery-of-eureka-self-preservation-c7aa0ed1b799 (六)健康检查和蓝绿发布 状态API例子： PUT /eureka/apps/{appId}/{instanceId}?status=UP PUT /eureka/apps/ORDER-SERVICE/localhost:order-service:8886?status=UP PUT /eureka/apps/{app id}/{instance id}/status?value={status} DELETE /eureka/apps/{app id}/{instance id}/status PUT /eureka/apps/ORDER-SERVICE/localhost:order-service:8886/status?value=OUT_OF_SERVICE HealthCheckHandler： 定制注册 EurekaClient#registerHealthCheck Spring Cloud eureka.client.healthcheck.enabled=true EurekaHealthCheckHandler DiskSpaceHealthIndicator RefreshScopeHealthIndicator HystrixHealthIndicator Ribbon软负载实例信息更新延迟： 注册延时（30秒） Eureka服务器响应延迟（30秒） Eureka客户端更新延迟（30秒） Ribbon服务列表更新延迟（30秒） 最大可能有2分钟延迟 测试 配置服务启动端 第一次运行使用8081服务器端口 12server.port&#x3D;8081eureka.client.service-url.defaultZone&#x3D;http:&#x2F;&#x2F;localhost:8082&#x2F;eureka&#x2F; 第二次运行使用8082服务器端口 12server.port&#x3D;8082eureka.client.service-url.defaultZone&#x3D;http:&#x2F;&#x2F;localhost:8081&#x2F;eureka&#x2F; UI校验： 12http:&#x2F;&#x2F;localhost:8081&#x2F;http:&#x2F;&#x2F;localhost:8082&#x2F; API校验： 12http:&#x2F;&#x2F;localhost:8081&#x2F;eureka&#x2F;appshttp:&#x2F;&#x2F;localhost:8082&#x2F;eureka&#x2F;apps","categories":[{"name":"Java框架","slug":"Java框架","permalink":"http://blog.tgyf.com/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/categories/SpringCloud/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/tags/SpringCloud/"},{"name":"Eureka","slug":"Eureka","permalink":"http://blog.tgyf.com/tags/Eureka/"}]},{"title":"JVM调优到底调什么怎么调?","slug":"Java虚拟机/JVM调优到底调什么怎么调","date":"2020-03-04T14:32:18.344Z","updated":"2020-03-04T14:32:18.344Z","comments":true,"path":"2020/03/04/Java虚拟机/JVM调优到底调什么怎么调/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/JVM%E8%B0%83%E4%BC%98%E5%88%B0%E5%BA%95%E8%B0%83%E4%BB%80%E4%B9%88%E6%80%8E%E4%B9%88%E8%B0%83/","excerpt":"","text":"调优三步曲(发现/分析/解决) 通过监控, 客户, 老板得知问题 分析定位问题 调优解决问题 发现 JVM性能指标 JVM性能指标简单说有三点：CPU、IO、内存 基本检测工具 CPU检测工具 12top, vmstat, ps, jpstop -Hp &lt;pid&gt; IO检测工具 1vmstat,netstat, iostat , pidstat 内存(JVM内存)检测工具 1234567891011jps -lvm 查看当前用户下java应用进程jinfo &lt;pid&gt; 查看进程信息及jvm垃圾回收参数jstat -gcutil &lt;pid&gt; period count jvm统计信息监控jmap -heap &lt;pid&gt; 内存映射工具jhat jstack -l &lt;pid&gt; 堆栈跟踪工具jcmdjvisualvm jconsolejmcgcview gclog图形化查看 分析/解决 情景一：内存泄漏 Java heap space java.lang.OutOfMemoryError:Java heap space Java heap space，Java应用程序创建的对象存放在这片区域，垃圾回收（Garbage Collection）也发生在这块区域。导致该异常通常有：创建大量的对象，层次比较深的递归操作等。 解决方案有两种: 一是优化应用，找到消耗大量内存的地方，然后优化代码或者算法。这种方式比较推荐，但是难度比较大，尤其是在生产环境中出现这种问题，开发人员不能很好的重现问题。 第二种方案是提升Java heap size，这种方式虽然感觉有点治标不治本，但是可行性非常高，操作简单。 对于一般的应用，采用如下方式即可（数字根据自己的需要调整）： -Xms -Set initial Java heap size -Xmx -Set maximum Java heap size 如: java -Xms512m -Xmx1024m JavaApp 如果是在tomcat中，出现的这种问题，解决办法是在{tomcat_dir}/bin/catalina.bat加上一行（内存设置大小根据自己的需要调整）： set CATALINA_OPTS=-Xms512m -Xmx512m 情景二：内存泄漏 PermGen space java.lang.OutOfMemoryError:PermGen space Perm Gen Size（Permanent Generation Size），用来存储被加载的类的定义（class definition）和元数据（metadata），比如：Class Object和Method Object等。这是内存中的一块永久保存区域，JVM的垃圾回收不会触及这块区域。通常在加载一个大项目的时候才会出现该异常。 对于一般的应用，采用如下方式即可（数字根据自己的需要调整）： -XX:PermSize -Set initial PermGen Size. -XX:MaxPermSize -Set the maximum PermGen Size. 如: java -XX:PermSize=64m -XX:MaxPermSize=128m JavaApp 如果是在tomcat中出现这个问题，解决办法是在{tomcat_dir}/bin/catalina.bat中添加如下一行： set CATALINA_OPTS=-server -Xms256m -Xmx1024m -XX:PermSize=512m -XX:MaxPermSize=512m 情景三：内存泄漏 Metaspace java.lang.OutOfMemoryError:Metaspace 在Java8中,将之前PermGen 中的所有内容, 都移到了Metaspace 空间。 例如: class 名称, 字段, 方法, 字节码, 常量池, JIT优化代码, 等等。 -XX:MaxMetaspaceSize=64m 情景三：内存泄漏 GC overhead limit exceeded java.lang.OutOfMemoryError:GC overhead limit exceeded 这个错误会出现在这个场景中：GC占用了多于98%（默认值）的CPU时间却只回收了少于2%（默认值）的堆空间。目的是为了让应用终止，给开发者机会去诊断问题。 一般是应用程序在有限的内存上创建了大量的临时对象或者弱引用对象，从而导致该异常。虽然加大内存可以暂时解决这个问题，但是还是强烈建议去优化代码，后者更加有效。 首先，你可以关闭JVM这个默认的策略：java -XX:-UseGCOverheadLimit JavaApp 其次，你也可以尝试去加大Heap Size：java -Xmx512m JavaApp JVM启动参数 标准参数 参数 参数说明 -version -Dkey=value -Dfile.encoding=UTF-8 用于指定文件编码格式 -Djava.awt.headless=true #Headless模式是系统的一种配置模式。在该模式下，系统缺少了显示设备、键盘或鼠标。 -Djava.library.path=/bin/native 指定非java类包的位置（如：dll，so） -Djava.security.egd=file:/dev/./urandom 使用伪随机数-verbose:class输出jvm载入类的相关信息，当jvm报告说找不到类或者类冲突时可此进行诊断。 -verbose:gc 输出每次GC的相关情况。 -verbose:jni 输出native方法调用的相关情况，一般用于诊断jni调用错误信息。 非标准参数 -X 参数 参数说明 -Xmsn 指定jvm堆的初始大小，默认为物理内存的1/64，最小为1M；可以指定单位，比如k、m，若不指定，则默认为字节。 -Xmxn 指定jvm堆的最大值，默认为物理内存的1/4或者1G，最小为2M；单位与-Xms一致。 -Xmnn 指定jvm堆中年轻代的大小 -Xssn 设置单个线程栈的大小，一般默认为512k。 -Xint 设置jvm以解释模式运行，所有的字节码将被直接执行，而不会编译成本地码。 -Xbatch 关闭后台代码编译，强制在前台编译，编译完成之后才能进行代码执行；默认情况下，jvm在后台进行编译，若没有编译完成，则前台运行代码时以解释模式运行。 -Xbootclasspath:bootclasspath 让jvm从指定路径（可以是分号分隔的目录、jar、或者zip）中加载bootclass，用来替换jdk的rt.jar；若非必要，一般不会用到； -Xbootclasspath/a:path 将指定路径的所有文件追加到默认bootstrap路径中； -Xbootclasspath/p:path 让jvm优先于bootstrap默认路径加载指定路径的所有文件； -Xcheck:jni 对JNI函数进行附加check；此时jvm将校验传递给JNI函数参数的合法性，在本地代码中遇到非法数据时，jmv将报一个致命错误而终止；使用该参数后将造成性能下降，请慎用。 -Xfuture 让jvm对类文件执行严格的格式检查（默认jvm不进行严格格式检查），以符合类文件格式规范，推荐开发人员使用该参数。 -Xnoclassgc 关闭针对class的gc功能；因为其阻止内存回收，所以可能会导致OutOfMemoryError错误，慎用； -Xincgc 开启增量gc（默认为关闭）；这有助于减少长时间GC时应用程序出现的停顿；但由于可能和应用程序并发执行，所以会降低CPU对应用的处理能力。 -Xloggc:file 与-verbose:gc功能类似，只是将每次GC事件的相关情况记录到一个文件中，文件的位置最好在本地，以避免网络的潜在问题。若与verbose命令同时出现在命令行中，则以-Xloggc为准。 扩展参数，非Stable -XX 行为参数 参数 参数说明 -XX:-DisableExplicitGC 禁止调用System.gc()；但jvm的gc仍然有效 -XX:+MaxFDLimit 最大化文件描述符的数量限制 -XX:+ScavengeBeforeFullGC 新生代GC优先于Full GC执行 -XX:+UseGCOverheadLimit 在抛出OOM之前限制jvm耗费在GC上的时间比例 -XX:-UseConcMarkSweepGC 对老生代采用并发标记交换算法进行GC -XX:-UseParallelGC 启用并行GC -XX:-UseParallelOldGC 对Full GC启用并行，当-XX:-UseParallelGC启用时该项自动启用 -XX:-UseSerialGC 启用串行GC -XX:+UseThreadPriorities 启用本地线程优先级 性能调优参数 参数 参数说明 -XX:LargePageSizeInBytes=4m 设置用于Java堆的大页面尺寸 -XX:MaxHeapFreeRatio=70 GC后java堆中空闲量占的最大比例 -XX:MaxNewSize=size 新生成对象能占用内存的最大值 -XX:MaxPermSize=64m 老生代对象能占用内存的最大值 -XX:MinHeapFreeRatio=40 GC后java堆中空闲量占的最小比例 -XX:NewRatio=2 老年代内存容量与新生代内存容量的比例，此处表示新生代为1/3，老年代为2/3。 -XX:SurvivorRatio=3 新生代中eden区和survivor区的比例，此处表示Eden:survivor:survivor=3:1:1，即Eden占新生代2/5。 -XX:NewSize=2.125m 新生代对象生成时占用内存的默认值-XX:PretenureSizeThreshold大于这个设置值(单位：byte)的对象直接在老年代分配。 -XX:MaxTenuringThreshold 对象晋升老年代的年龄阈值（默认为15岁）,如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。(动态对象年龄判定) -XX:ReservedCodeCacheSize=32m 保留代码占用的内存容量 -XX:ThreadStackSize=512 设置线程栈大小，若为0则使用系统默认值 -XX:+UseLargePages 使用大页面内存 调试参数 参数 参数说明 -XX:-CITime 打印消耗在JIT编译的时间 -XX:ErrorFile=./hs_err_pid.log 保存错误日志或者数据到文件中 -XX:-ExtendedDTraceProbes 开启solaris特有的dtrace探针 -XX:HeapDumpPath=./java_pid.hprof 指定导出堆信息时的路径或文件名 -XX:-HeapDumpOnOutOfMemoryError 当首次遭遇OOM时导出此时堆中相关信息 -XX:OnError=&quot;;&quot; 出现致命ERROR之后运行自定义命令 -XX:OnOutOfMemoryError=&quot;;&quot; 当首次遭遇OOM时执行自定义命令 -XX:-PrintClassHistogram 遇到Ctrl-Break后打印类实例的柱状信息，与jmap -histo功能相同 -XX:-PrintConcurrentLocks 遇到Ctrl-Break后打印并发锁的相关信息，与jstack -l功能相同 -XX:-PrintCommandLineFlags 打印在命令行中出现过的标记 -XX:-PrintCompilation 当一个方法被编译时打印相关信息 -XX:-PrintGC 每次GC时打印相关信息 -XX:-PrintGCDetails 每次GC时打印详细信息 -XX:-PrintGCTimeStamps 打印每次GC的时间戳 -XX:-TraceClassLoading 跟踪类的加载信息 -XX:-TraceClassLoadingPreorder 跟踪被引用到的所有类的加载信息 -XX:-TraceClassResolution 跟踪常量池 -XX:-TraceClassUnloading 跟踪类的卸载信息 -XX:-TraceLoaderConstraints 跟踪类加载器约束的相关信息 JVM GC日志查看 开启GC日志 12345678910111213141516-verbose:gc -Djava.awt.headless=true -DAPP_NAME=myapp-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.port=20189 -Dcom.sun.management.jmxremote.authenticate=false-Dcom.sun.management.jmxremote.ssl=false-XX:NewRatio=1 -XX:SurvivorRatio=2 -XX:+PrintGCApplicationStoppedTime -XX:+PrintReferenceGC -Xloggc:gc.log -XX:+PrintCommandLineFlags -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=.-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps jstat 看懂GC日志 https://blog.csdn.net/renfufei/article/details/54885190 Option Displays Ex class 用于查看类加载情况的统计 jstat -class pid:显示加载class的数量，及所占空间等信息。 compiler 查看HotSpot中即时编译器编译情况的统计 jstat -compiler pid:显示VM实时编译的数量等信息。 gc 查看JVM中堆的垃圾收集情况的统计 jstat -gc pid:可以显示gc的信息，查看gc的次数，及时间。其中最后五项，分别是young gc的次数，young gc的时间，full gc的次数，full gc的时间，gc的总时间。 gccapacity 查看新生代、老生代及持久代的存储容量情况 jstat -gccapacity:可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小 gccause 查看垃圾收集的统计情况（这个和-gcutil选项一样），如果有发生垃圾收集，它还会显示最后一次及当前正在发生垃圾收集的原因。 jstat -gccause:显示gc原因 gcnew 查看新生代垃圾收集的情况 jstat -gcnew pid:new对象的信息 gcnewcapacity 用于查看新生代的存储容量情况 jstat -gcnewcapacity pid:new对象的信息及其占用量 gcold 用于查看老生代及持久代发生GC的情况 jstat -gcold pid:old对象的信息 gcoldcapacity 用于查看老生代的容量 jstat -gcoldcapacity pid:old对象的信息及其占用量 gcpermcapacity 用于查看持久代的容量 jstat -gcpermcapacity pid: perm对象的信息及其占用量 gcutil 查看新生代、老生代及持代垃圾收集的情况 jstat -util pid:统计gc信息统计 printcompilation HotSpot编译方法的统计 jstat -printcompilation pid:当前VM执行的信息 GCViewer 图形化GC日志分析利器 https://github.com/chewiebug/GCViewer 12mvn packagejava -jar target\\gcviewer-1.36-SNAPSHOT.jar gc.log summary.csv chart.png JVM调优案例 后端服务，增加Eden占比，减少Eden到Suvivor复制 123-XX:SurvivorRatio=6 增加了Eden在新生代中的比例后, 如果对象很快可以使用完成则直接被清理, 不需要被复制到Survivor区域 服务转发应用，增加新生代空间减少Eden占比，避免清理老年代 12-XX:SurvivorRatio=3减少Eden占比后，对象能保存到Survivor区域，后续不需要被复制到老年代 CMS-Remark之前强制进行年轻代的GC https://segmentfault.com/a/1190000005174819 线程死锁检查（jstack分析线程快照） https://www.jianshu.com/p/f36a1db63ad2","categories":[{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/tags/JVM/"}]},{"title":"JVM内存模型及垃圾回收","slug":"Java虚拟机/JVM内存模型及垃圾回收","date":"2020-03-04T12:08:31.852Z","updated":"2020-03-04T12:08:31.852Z","comments":true,"path":"2020/03/04/Java虚拟机/JVM内存模型及垃圾回收/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"内存布局 示意图 基本介绍 方法区和堆是所有线程共享的内存区域；而java栈、本地方法栈和程序计数器是运行时线程私有的内存区域。堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用; Java堆（Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 方法区（MethodArea）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 程序计数器（ProgramCounterRegister）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。 JVM栈（JVMStacks）全称Java虚拟机栈（JavaVirtualMachineStacks）与程序计数器一样，也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（StackFrame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 本地方法栈（NativeMethodStacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。 类生命周期 类生命周期(内存中) 加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象。 连接，连接又包含三块内容：验证、准备、解析。 1231）验证，文件格式、元数据、字节码、符号引用验证；2）准备，为类的静态变量分配内存，并将其初始化为默认值；3）解析，把类中的符号引用转换为直接引用； 初始化，为类的静态变量赋予正确的初始值。 使用，new出对象程序中使用。 卸载，执行垃圾回收。 堆及垃圾回收 堆及垃圾回收（空间使用方式） 整个堆大小=年轻代大小+年老代大小+持久代大小； 年轻代分三个区。一个Eden区，两个Survivor区(一般而言)。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从 第 一 个S u r v i v o r区 复 制 过 来 的 并 且 此 时 还 存 活 的 对 象，将被复制“年 老 区( Te n u r e d )”；-XX:PretenureSizeThreshold即对象的大小大于此值，就会绕过新生代，直接在老年代分配； 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象； 持久代:用于存放静态文件，如今Java类、方法等。-XX:MaxPermSize（JDK8去除了永久代，引入了元空间Metaspace，-XX:MaxMetaspaceSize=64m） 垃圾回收算法 引用计数 比较古老的回收算法。 原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。 标记-清除（Mark-Sweep） 此算法执行分两阶段。 第一阶段从引用根节点开始标记所有被引用的对象 第二阶段遍历整个堆，把未标记的对象清除 此算法需要暂停整个应用，同时，会产生内存碎片。碎片太多可能引发另一次GC； 复制（Copying） 此算法把内存空间划为两个相等的区域，每次只使用其中一个区域。 垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。 此方法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。 当然，此算法的缺点也是很明显的，就是需要两倍内存空间。 4. 标记-整理（Mark-Compact） 此算法结合了“标记-清除”和“复制”两个算法的优点。 也是分两阶段: 第一阶段从根节点开始标记所有被引用对象， 第二阶段遍历整个堆，清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。 此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。 垃圾回收性能指标 吞吐量（用户时间占比） 1吞吐量（Throughput）=运行用户代码时间/（运行用户代码时间+垃圾收集时间） 系统停顿时间（用户时间延迟） 1GC造成的用户线程最长停顿时间 垃圾回收器（算法实现） Serial串行收集器 特点: 仅仅使用单线程进行内存回收； 它是独占式的内存回收； 进行内存回收时,暂停所有的工作线程(“Stop-The-World”)； 使用复制算法； 适合CPU等硬件一般的场合； 到JDK1.7为止，是JVMClient模式下默认的新生代收集器； 设置参数: 1-XX:+UseSerialGC指定使用新生代SerialGC和老年代SerialOldGC SerialOld收集器（单线程独占，标记整理算法） 特点: 同新生代Serial收集器一样，单线程、独占式的垃圾收集器； 使用“标记-整理”算法； 通常老年代内存回收比新生代内存回收要更长时间，所以可能会使应用程序停顿较长时间； 设置参数: 123-XX:+UseSerialGC新生代、老年代都使用串行GC；（分别是Serial和SerialOld）-XX:+UseParNewGC新生代使用ParNew，老年代使用SerialOld；-XX:+UseParallelGC新生代使用Parallel，老年代使用SerialOld； ParNew收集器，并行GC 特点: Serial的多线程版本； 使用复制算法； 垃圾回收时，应用程序仍会暂停，只不过由于是多线程回收，在多核CPU上，回收效率会高于串行GC。反之在单核CPU，效率会不如串行GC； 设置参数: 123-XX:+UseParNewGC新生代使用ParNew，老年代使用SerialOld；-XX:+UseConcMarkSweepGC新生代使用ParNew，老年代使用CMS；-XX:ParallelGCThreads=n指定ParNew收集器工作时的收集线程数，当CPU核数小于8时，默认开启的线程数等于CPU数量，当高于8时，可使用公式：3+((5*CPU_count)/8)。 在JVMServer模式下首选的新生代收集器，其中一个很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器(并发GC)配合工作。 ParNew收集器在单CPU环境中绝对不会有比Serial收集器更好的效果。 Parallel收集器 特点: 同ParNew回收器一样，不同的地方在于，它非常关注系统的吞吐量(通过参数控制)； 使用复制算法； 支持自适应的GC调节策略； 设置参数: 12345-XX:+UseParallelGC新生代使用Parallel，老年代使用SerialOld；-XX:+UseParallelOldGC新生代使用Parallel，老年代使用ParallelOld；-XX:MaxGCPauseMillis=n设置内存回收的最大停顿时间，单位ms；-XX:GCTimeRatio=n设置吞吐量的大小，假设值为n(在0-100之间)，那么系统将花费不超过1/(n+1)的时间用于内存回收。默认值为99，就是允许最大1%的垃圾收集时间；-XX:+UseAdaptiveSizePolicy自适应GC策略的开关参数。 ParallelOld收集器 特点: 关注吞吐量的老年代并发收集器； 使用“标记-整理”算法； 设置参数: 1-XX:+UseParallelOldGC新生代使用Parallel，老年代使用ParallelOld。这个收集器是在JDK1.6中才开始提供，在此之前，如果新生代选择了Parallel收集器，老年代除了SerialOld收集器外别无选择。 CMS收集器（Concurrent Mark Sweep） 特点: 非独占式的老年代并发收集器，大部分时候应用程序不会停止运行；–使用“标记-清除”算法，因此回收后会有内存碎片，可设置参数进行内存碎片的压缩整理； 与Parallel和ParallelOld不同，CMS主要关注系统停顿时间； 缺点: 对CPU资源敏感； 无法处理浮动垃圾（FloatingGarbage）； 内存碎片问题 设置参数: 12345678-XX:-CMSPrecleaningEnabled关闭预清理，默认在并发标记后会有一个预清理的操作；-XX:+UseConcMarkSweepGC新生代使用ParNew，老年代使用CMS-XX:ConcGCThreads=n设置并发线程数；（早期版本是-XX:ParallelCMSThreads=n）-XX:CMSInitiatingOccupancyFraction=n指定老年代回收阀值，默认值为68；-XX:+UseCMSCompactAtFullCollection开启内存碎片整理；-XX:CMSFullGCsBeforeCompation=n指定进行多少次CMS垃圾回收后再进行一次内存压缩；-XX:+CMSParallelRemarkEnabled在使用UseParNewGC参数的情况下，尽量减少mark(标记)的时间；-XX:+UseCMSInitiatingOccupancyOnly表示只有达到阀值时才进行CMS垃圾回收 G1 取代了CMS 由于G1的出现，CMS在Java9中已被废弃；http://openjdk.java.net/jeps/291 G1（GarbageFirst）是一个横跨新生代和老年代的垃圾回收器。实际上，它已经打乱了前面所说的堆结构，直接将堆分成极其多个区域。每个区域都可以充当Eden区、Survivor区或者老年代中的一个。它采用的是标记-压缩算法(标记-清除-整理)，所以不会产生内存碎片。而且和CMS一样都能够在应用程序运行过程中并发地进行垃圾回收。 G1是逻辑分代，物理不分代 除此之外不仅逻辑分代，而且物理分代 G1能够针对每个细分的区域来进行垃圾回收。在选择进行垃圾回收的区域时，它会优先回收死亡对象较多的区域。这也是G1名字的由来。 https://blog.csdn.net/baiye_xing/article/details/73743395 关于G1的细节，如果想了解得更多，可以参考如下资料： http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html https://www.zhihu.com/question/50398881/answer/120831226 ZGC “Zero”零暂停垃圾回收器暂停时间不超过10ms 参考如下资料： http://openjdk.java.net/projects/zgc/ 垃圾回收器组合 查看命令 1java -XX:+PrintCommandLineFlags -version 在网上找了张图，这样可以直观的展示出他们是怎样组合的. 上图展示了JDK1.7+后，Hotspot JVM的所有垃圾收集器以及它们适用的“代”,适合新生代的垃圾收集器有：Serial、ParNew、Parallel Scavenge、G1。适合年老代的垃圾收集器有：CMS、Serial Old、Parallel Old、G1。它们之间的组合关系如上图连线（粗线相连的是最佳组合），其中G1是JDK1.7 Update14这个版本中正式提供的商业收集器，它可以同时适用于新生代和年老代。 组合相关JVM参数，如图： 第一个组合：Serial + Serial Old Serial作为年轻代回收器和Serial Old垃圾回收器(JDK1.3版本之前)作为老年代回收器。在JDK1.3版本之前是唯一选择，现在基本不用，因为是单进程收集器，没有发挥出现在多核并行处理的优势。 第二个组合：ParNew + CMS ParNew作为年轻代回收器，CMS作为老年代回收器,一般需要手动指定，参数是： -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 因为现在jdk7,8默认不是使用这个策略。而是使用的下面的Parallel Scavenge + Parallel Old。其基本收集原理和下面的Parallel Scavenge + Parallel Old没有区别，区别在于Parallel Scavenge和 Parallel Old有自适应调节策略，直接可以适应最大吞吐量。但忽略了停顿时间，不适用于要求用户体验的场景，个别请求可能等待时间较长。而ParNew + CMS主要场景是注重控制单次回收停顿时间。 第三个组合：Parallel Scavenge + Parallel Old JDK6版本之后引入，Parallel Scavenge作为年轻代回收器，Parallel Old作为老年代回收器，在JDK6之前，Parallel Scavenge只能适配Serial Old，现在是JDK7,JDK8的默认组合。特点上面说了就是适应最大吞吐量。 第四个组合：G1回收器 G1回收器，JDK7出现，JDK9之后的默认回收器，老年代和年轻代都可以回收，特点是直接对停顿时间进行设置。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://blog.tgyf.com/tags/JVM/"}]},{"title":"SpringCloud框架原理","slug":"Java框架/SpringCloud/SpringCloud框架原理","date":"2020-03-04T07:52:58.339Z","updated":"2020-03-04T07:52:58.339Z","comments":true,"path":"2020/03/04/Java框架/SpringCloud/SpringCloud框架原理/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E6%A1%86%E6%9E%B6/SpringCloud/SpringCloud%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/","excerpt":"","text":"Spring Cloud是一个全家桶式的技术栈，包含了很多组件。本文先从其最核心的几个组件入手，来剖析一下其底层的工作原理。 核心组件 Eureka Feign Ribbon Hystrix Zuul 假设的一个业务场景 直接说他们的原理太空泛了，所以这里我假设了一个电商的业务场景.就把他最核心那个实现支付订单的功能拿出来说一下. 业务流程： 创建一个订单之后，如果用户立刻支付了这个订单，我们需要将订单状态更新为“已支付” 扣减相应的商品库存 通知仓储中心，进行发货 给用户的这次购物增加相应的积分 针对上述流程，我们需要有订单服务、库存服务、仓储服务、积分服务. 整体思路： 用户针对一个订单完成支付之后，就会去找订单服务，更新订单状态（标记为已支付） 订单服务调用库存服务，扣减库存并完成相应功能 订单服务调用仓储服务，通知仓储发货并完成相应功能 订单服务调用积分服务，为用户增加积分并完成相应功能 Spring Cloud微服务架构各组件协作与作用 核心组件：Eureka Eureka是微服务架构中的注册中心，专门负责服务的注册与发现。 说白了，就是告诉Eureka Server，自己在哪台机器上，监听着哪个端口。而Eureka Server是一个注册中心，里面有一个注册表，保存了各服务所在的机器和端口号 订单服务里也有一个Eureka Client组件，这个Eureka Client组件会找Eureka Server问一下：库存服务在哪台机器啊？监听着哪个端口啊？仓储服务呢？积分服务呢？然后就可以把这些相关信息从Eureka Server的注册表中拉取到自己本地缓存起来。 这时如果订单服务想要调用库存服务，不就可以找自己本地的Eureka Client问一下库存服务在哪台机器？监听哪个端口吗？收到响应后，紧接着就可以发送一个请求过去，调用库存服务扣减库存的那个接口！同理，如果订单服务要调用仓储服务、积分服务，也是如法炮制。 总结一下： Eureka Client：负责将这个服务的信息注册到Eureka Server中 Eureka Server：注册中心，里面有一个注册表，保存了各个服务所在的机器和端口号 核心组件：Feign Feign Client会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起靕求、获取响应、解析响应 Feign的一个关键机制就是使用了动态代理。 首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理 接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心 Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址 最后针对这个地址，发起请求、解析响应 核心组件：Ribbon Ribbon的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上. Ribbon的负载均衡默认使用的最经典的Round Robin轮询算法。这是啥？简单来说，就是如果订单服务对库存服务发起10次请求，那就先让你请求第1台机器、然后是第2台机器、第3台机器、第4台机器、第5台机器，接着再来—个循环，第1台机器、第2台机器…以此类推。 此外，Ribbon是和Feign以及Eureka紧密协作，完成工作的，具体如下： 首先Ribbon会从 Eureka Client里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。 然后Ribbon就可以使用默认的Round Robin算法，从中选择一台机器 Feign就会针对这台机器，构造并发起请求。 核心组件：Hystrix Hystrix相当于Springcloud中的保险，作用是隔离、熔断以及降级，避免因为某些服务的不可用导致服务雪崩问题. 业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务自己最多只有100个线程可以处理请求，然后呢，积分服务不幸的挂了，每次订单服务调用积分服务的时候，都会卡住几秒钟，然后抛出—个超时异常。 这样会导致什么问题？ 如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分服务这块。导致订单服务没有一个线程可以处理请求 然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了 这个就是微服务架构中恐怖的服务雪崩问题 服务雪崩问题如何解决？ Hystrix会搞很多个小小的线程池，比如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池。每个线程池里的线程就仅仅用于请求那个服务。 打个比方：现在很不幸，积分服务挂了，会咋样？ 当然会导致订单服务里的那个用来调用积分服务的线程都卡死不能工作了啊！但是由于订单服务调用库存服务、仓储服务的这两个线程池都是正常工作的，所以这两个服务不会受到任何影响。 这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！ 那人家又说，兄弟，积分服务挂了你就熔断，好歹你干点儿什么啊！别啥都不干就直接返回啊？没问题，咱们就来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。 核心组件：Zuul Zuul，也就是微服务网关，这个组件是负责网络路由的. 假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！ 上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。 而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。 总结 Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务","categories":[{"name":"Java框架","slug":"Java框架","permalink":"http://blog.tgyf.com/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/categories/SpringCloud/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.tgyf.com/tags/SpringCloud/"}]},{"title":"MQ总结：（六）如果写一个消息队列，应该怎样考虑?","slug":"Middleware/MQ总结：（六）如果写一个消息队列，应该怎样考虑","date":"2020-03-04T06:45:47.084Z","updated":"2020-03-04T06:45:47.084Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（六）如果写一个消息队列，应该怎样考虑/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E5%85%AD%EF%BC%89%E5%A6%82%E6%9E%9C%E5%86%99%E4%B8%80%E4%B8%AA%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%8C%E5%BA%94%E8%AF%A5%E6%80%8E%E6%A0%B7%E8%80%83%E8%99%91/","excerpt":"","text":"很多时候我们都没考虑过这样的问题，因为平时的工作中除非是框架部门的，不然大多数时候我们都是用消息队列，而不是去搞消息队列中间件的开发. 之所以有这篇思考性的文章，主要是之前由于之前去面试一家公司被问到怎样去设计一个mybatis的框架.其实这类问题都是可以发散的，比如还可以思考怎样去设计spring框架、dubbo框架、netty框架、springcloud框架等等. 其实，说白了就是对比几个同类型产品，技术的基本原理，核心组成部分，基本架构构成，然后参照他们拿出一个系统设计出来的思路. 设计考虑的几个方向 可伸缩性 就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -&gt; topic -&gt; partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？ 数据落盘 落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。 可用性 参考一下kafka的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker挂了重新选举leader即可对外服务。 数据零丢失 参考kafka数据零丢失方案","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（五）消息队列里产生积压怎么解决？","slug":"Middleware/MQ总结：（五）消息队列里产生积压怎么解决","date":"2020-03-04T06:18:17.269Z","updated":"2020-03-04T06:18:17.269Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（五）消息队列里产生积压怎么解决/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%BA%94%EF%BC%89%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%87%8C%E4%BA%A7%E7%94%9F%E7%A7%AF%E5%8E%8B%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3/","excerpt":"","text":"消息积压常见的问题 如何解决消息队列的延时以及过期失效问题？ 消息队列满了以后该怎么处理？ 有几百万消息持续积压几小时，怎么解决？ 消息积压情景再现 假设一个场景，我们现在消费端出故障了，然后大量消息在mq里积压，出现生产事故了. 场景一:大量消息在mq里积压了几个小时了还没解决 几千万条数据在MQ里积压了七八个小时，从下午4点多，积压到了晚上很晚，10点多，11点多 这个时候要不然就是修复consumer的问题，让他恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。 一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条，1000多万条 所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来 一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下： 先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉 新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据 这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息 场景二:超过rabbitmq设置过期时间（TTL）数据直接被清理掉 这个情况下，就不是说要增加consumer消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。 这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。 假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次 场景三:大量消息在mq里积压长时间都没处理掉，导致mq快写满了 临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个场景的方案，到了晚上再补数据吧。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（四）从消息队列里拿到的数据按顺序执行怎么保证？","slug":"Middleware/MQ总结：（四）从消息队列里拿到的数据按顺序执行怎么保证","date":"2020-03-04T05:57:17.413Z","updated":"2020-03-04T05:57:17.414Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（四）从消息队列里拿到的数据按顺序执行怎么保证/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E5%9B%9B%EF%BC%89%E4%BB%8E%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%87%8C%E6%8B%BF%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8C%89%E9%A1%BA%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81/","excerpt":"","text":"假设的一个消息的顺序性情景 要做一个mysql binlog同步的系统，在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么. rabbitmq消息的顺序性 rabbitmq错乱的场景 一个queue，多个consumer. rabbitmq如何保证消息的顺序性？ 拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理. kafka消息的顺序性 kafka错乱的场景 一个topic，一个partition，一个consumer，内部多线程. kafka如何保证消息的顺序性？ 一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（三）发到消息队列里面的数据不见了怎么办?","slug":"Middleware/MQ总结：（三）发到消息队列里面的数据不见了怎么办","date":"2020-03-04T05:45:36.942Z","updated":"2020-03-04T05:45:36.942Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（三）发到消息队列里面的数据不见了怎么办/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%B8%89%EF%BC%89%E5%8F%91%E5%88%B0%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%87%8C%E9%9D%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E8%A7%81%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E/","excerpt":"","text":"用mq有个基本原则：数据不能多一条，也不能少一条. 不能多，就是重复消费和幂等性问题. 不能少，就是说这数据别搞丢了. 丢数据的情景 丢数据，mq大体一般分为三种： 要么是我们把消息送达mq的时候弄丢了 要么是mq自己弄丢了 要么是我们消费mq的时候弄丢了 rabbitmq丢数据的三种情景 生产者弄丢了数据 生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。 此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。 所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。 事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。 所以一般在生产者这块避免数据丢失，都是用confirm机制的。 rabbitmq弄丢了数据 就是rabbitmq自己弄丢了数据，这个你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。 设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。 而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。 消费端弄丢了数据 rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。 这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。 kafka丢数据的情景 消费端弄丢了数据 唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。 这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。 生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。 然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了 kafka弄丢了数据 这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。 生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了 所以此时一般是要求起码设置如下4个参数： 给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本 在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧 在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了 在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了 我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失 生产者会不会弄丢数据 如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"MQ总结：（一）如果MQ挂了怎么办?","slug":"Middleware/MQ总结：（一）如果MQ挂了怎么办","date":"2020-03-04T05:08:46.039Z","updated":"2020-03-04T05:08:46.039Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（一）如果MQ挂了怎么办/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%B8%80%EF%BC%89%E5%A6%82%E6%9E%9CMQ%E6%8C%82%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E/","excerpt":"","text":"如何保证消息队列的高可用？ 如果MQ挂了，导致几个小时系统不可用，公司损失几千万，Team背锅，你闹的祸，你老大帮你一起背锅. 所以说，在非常核心的系统里，一定要考虑引入MQ所导致系统可用性降低的问题. RabbitMQ的高可用性 Rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式. RabbitMQ – 单机模式 就是demo级别的，一般就是你本地启动了玩玩儿的，用于本地开发环境，没人在生产环境用单机模式. RabbitMQ – 普通集群模式 就是在多台机器上启动多个rabbitmq实例，每个机器启动一个.但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据.完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来. 缺点： 这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群.因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈. 如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据. 总结： 所以综上所述这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作. RabbitMQ – 镜像集群模式 这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步. 优点： 你任何一个机器宕机了，没事儿，别的机器都可以用. 缺点： 第一 这个性能开销太大了，消息同步所有机器，导致网络带宽压力和消耗很重！ 第二 这么玩，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue. 怎么开启镜像集群模式? rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了. kafka的高可用性 kafka最基本的架构认识 多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据. 这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据. 实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据. kafka的HA机制 kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言. kafka 0.8以后，提供了HA机制，就是replica副本机制.每个partition的数据都会同步到吉他机器上，形成自己的多个replica副本.然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower.写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可.只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题.kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性. 就有所谓的高可用性了，因为如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可.这就有所谓的高可用性了. 写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据.一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者.（当然，这只是其中一种模式，还可以适当调整这个行为） 消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到.","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"LinkedList源码分析","slug":"Java基础/LinkedList源码分析","date":"2020-03-04T05:02:08.647Z","updated":"2020-03-04T05:02:08.648Z","comments":true,"path":"2020/03/04/Java基础/LinkedList源码分析/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Java%E5%9F%BA%E7%A1%80/LinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"LinkedList介绍 LinkedList 是 Java 集合框架中一个重要的实现，其底层采用的双向链表结构.和 ArrayList 一样，LinkedList 也支持空值和重复值.由于 LinkedList 基于链表实现，存储元素过程中，无需像 ArrayList 那样进行扩容.但有得必有失，LinkedList 存储元素的节点需要额外的空间存储前驱和后继的引用.另一方面，LinkedList 在链表头部和尾部插入效率比较高，但在指定位置进行插入时，效率一般.原因是，在指定位置插入需要定位到该位置处的节点，此操作的时间复杂度为O(N).最后，LinkedList 是非线程安全的集合类，并发环境下，多个线程同时操作 LinkedList，会引发不可预知的错误. 继承体系 LinkedList 的继承体系较为复杂，继承自 AbstractSequentialList，同时又实现了 List 和 Deque 接口.继承体系图如下: LinkedList 继承自 AbstractSequentialList，AbstractSequentialList 又是什么呢？从实现上，AbstractSequentialList 提供了一套基于顺序访问的接口.通过继承此类，子类仅需实现部分代码即可拥有完整的一套访问某种序列表（比如链表）的接口.深入源码，AbstractSequentialList 提供的方法基本上都是通过 ListIterator 实现的，比如： 123456789101112131415161718public E get(int index) &#123; try &#123; return listIterator(index).next(); &#125; catch (NoSuchElementException exc) &#123; throw new IndexOutOfBoundsException(\"Index: \"+index); &#125;&#125;public void add(int index, E element) &#123; try &#123; listIterator(index).add(element); &#125; catch (NoSuchElementException exc) &#123; throw new IndexOutOfBoundsException(\"Index: \"+index); &#125;&#125;// 留给子类实现public abstract ListIterator&lt;E&gt; listIterator(int index); 所以只要继承类实现了 listIterator 方法，它不需要再额外实现什么即可使用.对于随机访问集合类一般建议继承 AbstractList 而不是 AbstractSequentialList.LinkedList 和其父类一样，也是基于顺序访问.所以 LinkedList 继承了 AbstractSequentialList，但 LinkedList 并没有直接使用父类的方法，而是重新实现了一套的方法. 另外，LinkedList 还实现了 Deque (double ended queue)，Deque 又继承自 Queue 接口.这样 LinkedList 就具备了队列的功能.比如，我们可以这样使用： 1Queue&lt;T&gt; queue = new LinkedList&lt;&gt;(); 除此之外，我们基于 LinkedList 还可以实现一些其他的数据结构，比如栈，以此来替换 Java 集合框架中的 Stack 类（该类实现的不好，《Java 编程思想》一书的作者也对此类进行了吐槽）. 关于 LinkedList 继承体系先说到这，下面进入源码分析部分. 源码分析 查找 LinkedList 底层基于链表结构，无法向 ArrayList 那样随机访问指定位置的元素.LinkedList 查找过程要稍麻烦一些，需要从链表头结点（或尾节点）向后查找，时间复杂度为 O(N).相关源码如下： 1234567891011121314151617181920212223public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;Node&lt;E&gt; node(int index) &#123; /* * 则从头节点开始查找，否则从尾节点查找 * 查找位置 index 如果小于节点数量的一半， */ if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; // 循环向后查找，直至 i == index for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 上面的代码比较简单，主要是通过遍历的方式定位目标位置的节点.获取到节点后，取出节点存储的值返回即可.这里面有个小优化，即通过比较 index 与节点数量 size/2 的大小，决定从头结点还是尾节点进行查找.查找操作的代码没什么复杂的地方，这里先讲到这里. 遍历 链表的遍历过程也很简单，和上面查找过程类似，我们从头节点往后遍历就行了.但对于 LinkedList 的遍历还是需要注意一些，不然可能会导致代码效率低下.通常情况下，我们会使用 foreach 遍历 LinkedList，而 foreach 最终转换成迭代器形式.所以分析 LinkedList 的遍历的核心就是它的迭代器实现，相关代码如下： 1234567891011121314151617181920212223242526272829303132333435public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index);&#125;private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; /** 构造方法将 next 引用指向指定位置的节点 */ ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; // 调用 next 方法后，next 引用都会指向他的后继节点 nextIndex++; return lastReturned.item; &#125; // 省略部分方法&#125; 上面的方法很简单，大家应该都能很快看懂，这里就不多说了.下面来说说遍历 LinkedList 需要注意的一个点. 我们都知道 LinkedList 不擅长随机位置访问，如果大家用随机访问的方式遍历 LinkedList，效率会很差.比如下面的代码： 12345678List&lt;Integet&gt; list = new LinkedList&lt;&gt;();list.add(1)list.add(2)......for (int i = 0; i &lt; list.size(); i++) &#123; Integet item = list.get(i); // do something&#125; 当链表中存储的元素很多时，上面的遍历方式对于效率来说就是灾难.原因在于，通过上面的方式每获取一个元素，LinkedList 都需要从头节点（或尾节点）进行遍历，效率不可谓不低.在我的电脑（MacBook Pro Early 2015, 2.7 GHz Intel Core i5）实测10万级的数据量，耗时约7秒钟.20万级的数据量耗时达到了约34秒的时间.50万级的数据量耗时约250秒.从测试结果上来看，上面的遍历方式在大数据量情况下，效率很差.大家在日常开发中应该尽量避免这种用法. 插入 LinkedList 除了实现了 List 接口相关方法，还实现了 Deque 接口的很多方法，所以我们有很多种方式插入元素.但这里，我只打算分析 List 接口中相关的插入方法，其他的方法大家自己看吧.LinkedList 插入元素的过程实际上就是链表链入节点的过程，学过数据结构的同学对此应该都很熟悉了.这里简单分析一下，先看源码吧： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** 在链表尾部插入元素 */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** 在链表指定位置插入元素 */public void add(int index, E element) &#123; checkPositionIndex(index); // 判断 index 是不是链表尾部位置，如果是，直接将元素节点插入链表尾部即可 if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;/** 将元素节点插入到链表尾部 */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; // 创建节点，并指定节点前驱为链表尾节点 last，后继引用为空 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 将 last 引用指向新节点 last = newNode; // 判断尾节点是否为空，为空表示当前链表还没有节点 if (l == null) first = newNode; else l.next = newNode; // 让原尾节点后继引用 next 指向新的尾节点 size++; modCount++;&#125;/** 将元素节点插入到 succ 之前的位置 */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; // 1. 初始化节点，并指明前驱和后继节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 2. 将 succ 节点前驱引用 prev 指向新节点 succ.prev = newNode; // 判断尾节点是否为空，为空表示当前链表还没有节点 if (pred == null) first = newNode; else pred.next = newNode; // 3. succ 节点前驱的后继引用指向新节点 size++; modCount++;&#125; 上面是插入过程的源码，我对源码进行了比较详细的注释，应该不难看懂.上面两个 add 方法只是对操作链表的方法做了一层包装，核心逻辑在 linkBefore 和 linkLast 中.这里以 linkBefore 为例，它的逻辑流程如下： 创建新节点，并指明新节点的前驱和后继 将 succ 的前驱引用指向新节点 如果 succ 的前驱不为空，则将 succ 前驱的后继引用指向新节点 删除 如果大家看懂了上面的插入源码分析，那么再看删除操作实际上也很简单了.删除操作通过解除待删除节点与前后节点的链接，即可完成任务.过程比较简单，看源码吧： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 遍历链表，找到要删除的节点 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); // 将节点从链表中移除 return true; &#125; &#125; &#125; return false;&#125;public E remove(int index) &#123; checkElementIndex(index); // 通过 node 方法定位节点，并调用 unlink 将节点从链表中移除 return unlink(node(index));&#125;/** 将某个节点从链表中移除 */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // prev 为空，表明删除的是头节点 if (prev == null) &#123; first = next; &#125; else &#123; // 将 x 的前驱的后继指向 x 的后继 prev.next = next; // 将 x 的前驱引用置空，断开与前驱的链接 x.prev = null; &#125; // next 为空，表明删除的是尾节点 if (next == null) &#123; last = prev; &#125; else &#123; // 将 x 的后继的前驱指向 x 的前驱 next.prev = prev; // 将 x 的后继引用置空，断开与后继的链接 x.next = null; &#125; // 将 item 置空，方便 GC 回收 x.item = null; size--; modCount++; return element;&#125; 和插入操作一样，删除操作方法也是对底层方法的一层保证，核心逻辑在底层 unlink 方法中.所以长驱直入，直接分析 unlink 方法吧.unlink 方法的逻辑如下（假设删除的节点既不是头节点，也不是尾节点）： 将待删除节点 x 的前驱的后继指向 x 的后继 将待删除节点 x 的前驱引用置空，断开与前驱的链接 将待删除节点 x 的后继的前驱指向 x 的前驱 将待删除节点 x 的后继引用置空，断开与后继的链接 总结 通过上面的分析，大家对 LinkedList 的底层实现应该很清楚了.总体来看 LinkedList 的源码并不复杂，大家耐心看一下，一般都能看懂.","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.tgyf.com/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"Java集合框架","slug":"Java基础/Java集合框架","permalink":"http://blog.tgyf.com/categories/Java%E5%9F%BA%E7%A1%80/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.tgyf.com/tags/Java/"},{"name":"LinkedList","slug":"LinkedList","permalink":"http://blog.tgyf.com/tags/LinkedList/"},{"name":"Java集合框架","slug":"Java集合框架","permalink":"http://blog.tgyf.com/tags/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"}]},{"title":"关于中间件的一些思考","slug":"Middleware/ThinkInMiddleware","date":"2020-03-04T01:57:25.884Z","updated":"2020-03-04T01:57:25.885Z","comments":true,"path":"2020/03/04/Middleware/ThinkInMiddleware/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/ThinkInMiddleware/","excerpt":"","text":"为什么有这篇文章？ 在项目团队中往往有这样一些人，并不知道自己为什么要在项目用中间件这个东西.其实说白了，就是为了用而用.或者是别人设计的架构，从头到尾没有思考过.这些人给我的映像就是木头木脑的干呆活儿，一本正经的挖坑.为了避免以后团队中出现这类型人，所以有了这篇思维导图型的文章. 1.为什么使用这个类型中间件？ 其实就是这个中间件都有哪些使用场景，然后在项目里具体是什么场景，这个业务场景有个什么技术挑战，如果不用可能会很麻烦，但是你现在用了之后带给了你很多的好处. 2.有什么优点和缺点？原理是怎样的？ 引入中间件之后会不会有什么坏处？要是没考虑过这个，那盲目弄个中间件进系统里，后面出了问题是不是当事人就溜了，这就是给公司后来接盘的人留坑.要是没考虑过引入一个技术可能存在的弊端和风险，这类哥们，基本可能就是挖坑型选手. 3.同类型产品调研对比，分别适合哪些场景？ 中间件没有绝对的好坏，但是就是看用在哪个场景可以扬长避短，利用其优势，规避其劣势. 如果去设计个什么系统，在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑.","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"}]},{"title":"MQ总结：（二）MQ里消费到重复数据怎么办？","slug":"Middleware/MQ总结：（二）MQ里消费到重复数据怎么办","date":"2020-03-04T01:56:02.060Z","updated":"2020-03-04T01:56:02.060Z","comments":true,"path":"2020/03/04/Middleware/MQ总结：（二）MQ里消费到重复数据怎么办/","link":"","permalink":"http://blog.tgyf.com/2020/03/04/Middleware/MQ%E6%80%BB%E7%BB%93%EF%BC%9A%EF%BC%88%E4%BA%8C%EF%BC%89MQ%E9%87%8C%E6%B6%88%E8%B4%B9%E5%88%B0%E9%87%8D%E5%A4%8D%E6%95%B0%E6%8D%AE%E6%80%8E%E4%B9%88%E5%8A%9E/","excerpt":"","text":"如何保证消息消费时的幂等性？（或：如何保证消息不被重复消费？） 既然是消费消息，那肯定要考虑考虑这三点： 会不会重复消费？ 能不能避免重复消费？ 或者重复消费了也别造成系统异常可以吗？ 大概可能会有哪些重复消费 如rabbitmq、rocketmq、kafka，都有可能会出现消费重复消费的问题，正常.因为这问题通常不是mq自己保证的，是给你保证的.然后我们挑一个kafka来举个例子，说说怎么重复消费吧. kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧. 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启.这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了.重启之后，少数消息会再次消费一次. 其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性. 怎么保证消息队列消费的幂等性 其实还是得结合业务来思考，这里给几个思路： 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧 比如你是写redis，那没问题了，反正每次都是set，天然幂等性 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis.如果消费过了，那你就别处理了，保证别重复处理相同的消息即可. 还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据 如何保证MQ的消费是幂等性的，需要结合具体的业务来看","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"}],"tags":[{"name":"一些思考","slug":"一些思考","permalink":"http://blog.tgyf.com/tags/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"}]},{"title":"RabbitMQ（四） - 优先级队列(PriorityQueue)","slug":"Middleware/RabbitMQ/RabbitMQ-PriorityQueue","date":"2020-02-24T15:11:23.490Z","updated":"2020-02-24T15:11:23.490Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ-PriorityQueue/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ-PriorityQueue/","excerpt":"","text":"RabbitMQ - 优先级队列(PriorityQueue) 在RabbitMQ中使用优先级特性需要的版本为3.5+。 使用优先级特性只需做两件事情： 1. 将队列声明为优先级队列，即在创建队列的时候添加参数 x-max-priority 以指定最大的优先级，值为0-255（整数）。 2. 为优先级消息添加优先级。 注意:没有指定优先级的消息会将优先级以0对待。 对于超过优先级队列所定最大优先级的消息，优先级以最大优先级对待。对于相同优先级的消息，后进的排在前面。 核心代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.tgyf.rabbit.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * direct exchange -- 直接交换器 * 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 * @author 韬光养月巴 * @modify * @createDate 2019/8/24 1:29 PM * @remark */@Configuration@Slf4jpublic class DirectExchangeConf &#123; public static final String QUEUE = \"direct-queue-priority\"; public static final String EXCHANGE = \"exchange-direct\"; public static final String ROUTING_KEY = \"direct.queue.priority\"; @Bean Queue directQueuePriority() &#123; //创建队列的时候添加参数 x-max-priority 以指定最大的优先级，值为0-255 Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); args.put(\"x-max-priority\", 100); return new Queue(QUEUE, false, false, false, args); &#125; @Bean DirectExchange directExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding directQueuePriorityBinding(Queue directQueuePriority, DirectExchange directExchange) &#123; return BindingBuilder.bind(directQueuePriority).to(directExchange).with(ROUTING_KEY); &#125;&#125; 测试 1.测试优先级队列 发送优先级低的消息 100 条到 RabbitMQ curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.priority&quot;, &quot;priority&quot;: 1, &quot;content&quot;:&quot; hello priority queue! &quot;, &quot;count&quot;: 100 }' 发送优先级高的消息 5 条到 RabbitMQ curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.priority&quot;, &quot;priority&quot;: 10, &quot;content&quot;:&quot; &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; hello priority queue! &quot;, &quot;count&quot;: 5 }'","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ（二） - 交换器（Exchange）","slug":"Middleware/RabbitMQ/RabbitMQ-Exchang","date":"2020-02-24T15:11:16.763Z","updated":"2020-02-24T15:11:16.763Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ-Exchang/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ-Exchang/","excerpt":"","text":"RabbitMQ - 交换器（Exchange） 交换器名称 作用 fanout exchange 发送到该交换器的所有消息，会被路由到其绑定的所有队列 direct exchange 发送到该交换器的消息，会通过路由键完全匹配，匹配成功就会路由到指定队列 topic exchange 发送到该交换器的消息，会通过路由键模糊匹配，匹配成功就会路由到指定队列 header exchange 发送到该交换器的消息，会通过消息的 header 信息匹配，匹配成功就会路由到指定队列 核心代码 pom.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tgyf.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;exchange&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; direct exchange – 直接交换器 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * direct exchange -- 直接交换器 * 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:07 PM * @remark */@Configurationpublic class DirectExchangeConf &#123; public static final String QUEUE_1 = \"direct-queue-1\"; public static final String QUEUE_2 = \"direct-queue-2\"; private static final String EXCHANGE = \"exchange-direct\"; private static final String ROUTING_KEY_TO_QUEUE1 = \"queue.direct.key1\"; private static final String ROUTING_KEY_TO_QUEUE2 = \"queue.direct.key2\"; @Bean Queue directQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue directQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean DirectExchange directExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding bindingDirectQueue1(Queue directQueue1, DirectExchange directExchange) &#123; return BindingBuilder.bind(directQueue1).to(directExchange).with(ROUTING_KEY_TO_QUEUE1); &#125; @Bean Binding bindingDirectQueue2(Queue directQueue2, DirectExchange directExchange) &#123; return BindingBuilder.bind(directQueue2).to(directExchange).with(ROUTING_KEY_TO_QUEUE2); &#125;&#125; fanout exchange – 扇出交换器 所有发送到该交换器的消息都会被路由到所有与该交换器绑定的队列中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.FanoutExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * fanout exchange -- 扇出交换器 * 所有发送到该交换器的消息都会被路由到所有与该交换器绑定的队列中 * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:04 PM * @remark */@Configurationpublic class FanoutExchangeConf &#123; public static final String QUEUE_1 = \"fanout-queue-1\"; public static final String QUEUE_2 = \"fanout-queue-2\"; private static final String EXCHANGE = \"exchange-fanout\"; @Bean Queue fanoutQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue fanoutQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean FanoutExchange fanoutExchange() &#123; return new FanoutExchange(EXCHANGE); &#125; @Bean Binding bindingFanoutQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange) &#123; return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); &#125; @Bean Binding bindingFanoutQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange) &#123; return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange); &#125;&#125; headers exchange – headers交换器 发送到该交换器的消息会根据消息的 header 信息路由到对应的队列 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.HeadersExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;/** * headers exchange -- headers交换器 * 发送到该交换器的消息会根据消息的 header 信息路由到对应的队列 * 说明： * where 匹配单个 header * whereAll 同时匹配多个 header * whereAny 匹配一个或多个 header * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:12 PM * @remark */public class HeadersExchangeConf &#123; public static final String QUEUE_1 = \"headers-queue-1\"; public static final String QUEUE_2 = \"headers-queue-2\"; public static final String QUEUE_3 = \"headers-queue-3\"; private static final String EXCHANGE = \"exchange-headers\"; @Bean Queue headersQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue headersQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean Queue headersQueue3() &#123; return new Queue(QUEUE_3, false); &#125; @Bean HeadersExchange headersExchange() &#123; return new HeadersExchange(EXCHANGE); &#125; @Bean Binding bindingHeadersQueue1(Queue headersQueue1, HeadersExchange headersExchange) &#123; return BindingBuilder.bind(headersQueue1).to(headersExchange).where(\"one\").exists(); &#125; @Bean Binding bindingHeadersQueue2(Queue headersQueue1, HeadersExchange headersExchange) &#123; return BindingBuilder.bind(headersQueue1).to(headersExchange).whereAll(\"all1\", \"all2\").exist(); &#125; @Bean Binding bindingHeadersQueue3(Queue headersQueue3, HeadersExchange headersExchange) &#123; return BindingBuilder.bind(headersQueue3).to(headersExchange).whereAny(\"any1\", \"any2\").exist(); &#125;&#125; topic exchange – 主题交换器 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.tgyf.rabbit.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.Queue;import org.springframework.amqp.core.TopicExchange;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * topic exchange -- 主题交换器 * 发送到该交换器的消息都会被路由到与 routing key 匹配的队列中 * 说明： * routing key 以 '.' 分隔为多个单词 * routing key 以 '*' 匹配一个单词 * routing key 以 '#' 匹配零个或多个单词 * 例如： * queue.topic.key -&gt; QUEUE_1 + QUEUE_2 * test.topic.key -&gt; QUEUE_1 * queue -&gt; QUEUE_2 * queue.topic -&gt; QUEUE_2 * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 12:09 PM * @remark */@Configurationpublic class TopicExchangeConf &#123; public static final String QUEUE_1 = \"topic-queue-1\"; public static final String QUEUE_2 = \"topic-queue-2\"; private static final String EXCHANGE = \"exchange-topic\"; private static final String ROUTING_KEY_TO_QUEUE1 = \"*.topic.*\"; private static final String ROUTING_KEY_TO_QUEUE2 = \"queue.#\"; @Bean Queue topicQueue1() &#123; return new Queue(QUEUE_1, false); &#125; @Bean Queue topicQueue2() &#123; return new Queue(QUEUE_2, false); &#125; @Bean TopicExchange topicExchange() &#123; return new TopicExchange(EXCHANGE); &#125; @Bean Binding bindingTopicQueue1(Queue topicQueue1, TopicExchange topicExchange) &#123; return BindingBuilder.bind(topicQueue1).to(topicExchange).with(ROUTING_KEY_TO_QUEUE1); &#125; @Bean Binding bindingTopicQueue2(Queue topicQueue2, TopicExchange topicExchange) &#123; return BindingBuilder.bind(topicQueue2).to(topicExchange).with(ROUTING_KEY_TO_QUEUE2); &#125;&#125; 测试 1.测试fanout exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-fanout&quot;, &quot;routingKey&quot;: &quot;default&quot;, &quot;content&quot;:&quot; hello fanout!&quot;, &quot;count&quot;: 1 }' 2.测试 direct exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;queue.direct.key1&quot;, &quot;content&quot;:&quot; hello direct! &quot;, &quot;count&quot;: 1 }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;queue.direct.key2&quot;, &quot;content&quot;:&quot; hello direct! &quot;, &quot;count&quot;: 1 }' 3.测试 topic exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-topic&quot;, &quot;routingKey&quot;: &quot;queue.topic.key1&quot;, &quot;content&quot;:&quot; hello topic! &quot;, &quot;count&quot;: 1 }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-topic&quot;, &quot;routingKey&quot;: &quot;test.topic.key2&quot;, &quot;content&quot;:&quot; hello topic! &quot;, &quot;count&quot;: 1 }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-topic&quot;, &quot;routingKey&quot;: &quot;queue.hello&quot;, &quot;content&quot;:&quot; hello topic! &quot;, &quot;count&quot;: 1 }' 4.测试 headers exchange curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-headers&quot;, &quot;content&quot;:&quot; hello headers! &quot;, &quot;count&quot;: 1, &quot;headers&quot;:{ &quot;one&quot;:&quot;value&quot; } }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-headers&quot;, &quot;content&quot;:&quot; hello headers! &quot;, &quot;count&quot;: 1, &quot;headers&quot;:{ &quot;all1&quot;:&quot;value&quot;, &quot;all2&quot;:&quot;value&quot; } }' curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-headers&quot;, &quot;content&quot;:&quot; hello headers! &quot;, &quot;count&quot;: 1, &quot;headers&quot;:{ &quot;any2&quot;:&quot;value&quot;, } }'","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ（三） - 死信队列(DeadLetterQueue)","slug":"Middleware/RabbitMQ/RabbitMQ-DeadletterQueue","date":"2020-02-24T15:11:10.610Z","updated":"2020-02-24T15:11:10.611Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ-DeadletterQueue/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ-DeadletterQueue/","excerpt":"","text":"RabbitMQ - 死信队列(DeadLetterQueue) 什么是死信 “死信”是RabbitMQ中的一种消息机制，当你在消费消息时，如果队列里的消息出现以下情况： 1.消息被否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为false。 2.消息在队列的存活时间超过设置的TTL时间。 3.消息队列的消息数量已经超过最大队列长度。 那么该消息将成为“死信”。 “死信”消息会被RabbitMQ进行特殊处理，如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃。 死信生命周期 死信队列只是一个绑定在死信交换机上的普通队列，而死信交换机也只是一个普通的交换机，不过是用来专门处理死信的交换机。 死信的生命周期： 业务消息被投入业务队列 消费者消费业务队列的消息，由于处理过程中发生异常，于是进行了nck或者reject操作 被nck或reject的消息由RabbitMQ投递到死信交换机中 死信交换机将消息投入相应的死信队列 死信队列的消费者消费死信消息 死信消息是RabbitMQ为我们做的一层保证，其实我们也可以不使用死信队列，而是在消息消费异常时，将消息主动投递到另一个交换机中，关键在于这些Exchange和Queue怎么配合。比如从死信队列拉取消息，然后发送邮件、短信、钉钉通知来通知开发人员关注。或者将消息重新投递到一个队列然后设置过期时间，来进行延时消费。 死信消息的Header 字段名 含义 x-first-death-exchange 第一次被抛入的死信交换机的名称 x-first-death-reason 第一次成为死信的原因，rejected：消息在重新进入队列时被队列拒绝，由于default-requeue-rejected 参数被设置为false。expired ：消息过期。maxlen ： 队列内消息数量超过队列最大容量 x-first-death-queue 第一次成为死信前所在队列名称 x-death 历次被投入死信交换机的信息列表，同一个消息每次进入一个死信交换机，这个数组的信息就会被更新 死信队列应用场景 一般用在较为重要的业务队列中，确保未被正确消费的消息不被丢弃，一般发生消费异常可能原因主要有由于消息信息本身存在错误导致处理异常，处理过程中参数校验异常，或者因网络波动导致的查询异常等等，当发生异常时，当然不能每次通过日志来获取原消息，然后让运维帮忙重新投递消息（没错，以前就是这么干的= =）。通过配置死信队列，可以让未正确处理的消息暂存到另一个队列中，待后续排查清楚问题后，编写相应的处理代码来处理死信消息，这样比手工恢复数据要好太多了。 核心代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.tgyf.rabbit.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 死信交换器 * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 2:18 PM * @remark */@Configuration@Slf4jpublic class DeadLetterExchangeConf &#123; public static final String QUEUE_BY_MAX_LENGTH = \"direct-queue-dead-by-max-length\"; public static final String QUEUE_BY_TTL = \"direct-queue-dead-by-ttl\"; public static final String QUEUE_BY_REJECT = \"direct-queue-dead-by-reject\"; public static final String EXCHANGE = \"exchange-direct-dead\"; public static final String ROUTING_KEY_BY_MAX_LENGTH = \"direct.queue.dead.max.length\"; public static final String ROUTING_KEY_BY_TTL = \"direct.queue.dead.ttl\"; public static final String ROUTING_KEY_BY_REJECT = \"direct.queue.dead.reject\"; @Bean Queue deadByMaxLengthQueue() &#123; return new Queue(QUEUE_BY_MAX_LENGTH, false); &#125; @Bean Queue deadByTTLQueue() &#123; return new Queue(QUEUE_BY_TTL, false); &#125; @Bean Queue deadByRejectQueue() &#123; return new Queue(QUEUE_BY_REJECT, false); &#125; @Bean DirectExchange deadDirectExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding deadByMaxLengthQueueBinding(Queue deadByMaxLengthQueue, DirectExchange deadDirectExchange) &#123; return BindingBuilder.bind(deadByMaxLengthQueue).to(deadDirectExchange).with(ROUTING_KEY_BY_MAX_LENGTH); &#125; @Bean Binding deadByTTLQueueBinding(Queue deadByTTLQueue, DirectExchange deadDirectExchange) &#123; return BindingBuilder.bind(deadByTTLQueue).to(deadDirectExchange).with(ROUTING_KEY_BY_TTL); &#125; @Bean Binding deadByRejectQueueBinding(Queue deadByRejectQueue, DirectExchange deadDirectExchange) &#123; return BindingBuilder.bind(deadByRejectQueue).to(deadDirectExchange).with(ROUTING_KEY_BY_REJECT); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package com.tgyf.rabbit.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * 普通交换器 * * @author 韬光养月巴 * @modify * @createDate 2019/8/24 2:18 PM * @remark */@Configuration@Slf4jpublic class DirectExchangeConf &#123; public static final String QUEUE_MAX_LENGTH = \"direct-queue-max-length\"; public static final String QUEUE_TTL = \"direct-queue-ttl\"; public static final String QUEUE_REJECT = \"direct-queue-reject\"; public static final String EXCHANGE = \"exchange-direct\"; public static final String ROUTING_KEY_MAX_LENGTH = \"direct.queue.max.length\"; public static final String ROUTING_KEY_TTL = \"direct.queue.ttl\"; public static final String ROUTING_KEY_REJECT = \"direct.queue.reject\"; @Bean Queue maxLengthQueue() &#123; Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); // 设置队列最大长度 args.put(\"x-max-length\", 10); // 设置死信转发的 exchange 和 routing key args.put(\"x-dead-letter-exchange\", DeadLetterExchangeConf.EXCHANGE); args.put(\"x-dead-letter-routing-key\", DeadLetterExchangeConf.ROUTING_KEY_BY_MAX_LENGTH); return new Queue(QUEUE_MAX_LENGTH, false, false, false, args); &#125; @Bean Queue ttlQueue() &#123; Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); // 设置消息存活时间 10s args.put(\"x-message-ttl\", 10000); // 设置死信转发的 exchange 和 routing key args.put(\"x-dead-letter-exchange\", DeadLetterExchangeConf.EXCHANGE); args.put(\"x-dead-letter-routing-key\", DeadLetterExchangeConf.ROUTING_KEY_BY_TTL); return new Queue(QUEUE_TTL, false, false, false, args); &#125; @Bean Queue rejectQueue() &#123; Map&lt;String, Object&gt; args= new HashMap&lt;&gt;(); // 设置死信转发的 exchange 和 routing key args.put(\"x-dead-letter-exchange\", DeadLetterExchangeConf.EXCHANGE); args.put(\"x-dead-letter-routing-key\", DeadLetterExchangeConf.ROUTING_KEY_BY_REJECT); return new Queue(QUEUE_REJECT, false, false, false, args); &#125; @Bean DirectExchange directExchange() &#123; return new DirectExchange(EXCHANGE); &#125; @Bean Binding maxLengthQueueBinding(Queue maxLengthQueue, DirectExchange directExchange) &#123; return BindingBuilder.bind(maxLengthQueue).to(directExchange).with(ROUTING_KEY_MAX_LENGTH); &#125; @Bean Binding ttlQueueBinding(Queue ttlQueue, DirectExchange directExchange) &#123; return BindingBuilder.bind(ttlQueue).to(directExchange).with(ROUTING_KEY_TTL); &#125; @Bean Binding rejectQueueBinding(Queue rejectQueue, DirectExchange directExchange) &#123; return BindingBuilder.bind(rejectQueue).to(directExchange).with(ROUTING_KEY_REJECT); &#125;&#125; 测试 1.测试消费者否认消息 curl -X POST \\ http://127.0.0.1:8080/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.reject&quot;, &quot;content&quot;:&quot; hello reject queue! &quot;, &quot;count&quot;: 1 }' 2.测试消息超出队列最大长度 curl -X POST \\ http://127.0.0.1:8080/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.max.length&quot;, &quot;content&quot;:&quot; hello max length queue! &quot;, &quot;count&quot;: 30 }' 提示：消息队列遵循先进先出的策略，假设队列最大长度设置为 10，发送 30 条消息到该队列，若无消费者，前 20 条消息会被转发到指定的其他队列，后 10 条会保存在该队列中，除非有新的消息入队，这 10 条消息才会被转发 3.测试消息超时 curl -X POST \\ http://127.0.0.1:8080/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.ttl&quot;, &quot;content&quot;:&quot; hello ttl queue! &quot;, &quot;count&quot;: 10 }' 4.测试延迟队列 curl -X POST \\ http://127.0.0.1/send \\ -H 'Content-Type: application/json' \\ -d '{ &quot;exchange&quot;:&quot;exchange-direct&quot;, &quot;routingKey&quot;: &quot;direct.queue.delay&quot;, &quot;content&quot;:&quot; hello delay delay! &quot;, &quot;count&quot;: 1, &quot;delayTime&quot;: &quot;10000&quot; }'","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ（一） - 配置详解","slug":"Middleware/RabbitMQ/RabbitMQ","date":"2020-02-24T15:10:50.667Z","updated":"2020-02-24T15:10:50.667Z","comments":true,"path":"2020/02/24/Middleware/RabbitMQ/RabbitMQ/","link":"","permalink":"http://blog.tgyf.com/2020/02/24/Middleware/RabbitMQ/RabbitMQ/","excerpt":"","text":"启动 RabbitMQ docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 -v `pwd`/data:/var/lib/rabbitmq --hostname rabbit -e RABBITMQ_DEFAULT_VHOST=my_vhost -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin rabbitmq:3.7-management-plugins 构建RabbitMQ镜像参考RabbitMQ 镜像dockerfile 内容结构 序号 内容名称 内容说明 1 exchange 交换器 2 priorityqueue 优先级队列 3 deadletterqueue 死信队列 Spring Boot RabbitMQ 参数配置详解 连接配置 spring.rabbitmq.host=localhost # RabbitMQ 地址 spring.rabbitmq.port=5672 # RabbitMQ 端口 spring.rabbitmq.username=guest # RabbitMQ 用户名 spring.rabbitmq.password=guest # RabbitMQ 密码 spring.rabbitmq.addresses= # 设置 RabbitMQ 集群，多个地址使用 &quot;,&quot; 分隔，例如：192.168.0.100:5672,192.168.0.101:5672 spring.rabbitmq.virtual-host= # 设置 Virtual Host spring.rabbitmq.ssl.algorithm= # SSL 算法，默认情况下，由 Rabbit 客户端配置 spring.rabbitmq.ssl.enabled=false # 是否启用 SSL 支持 spring.rabbitmq.ssl.key-store= # key 存储路径 spring.rabbitmq.ssl.key-store-password= # 用于访问 key 的密码 spring.rabbitmq.ssl.key-store-type=PKCS12 # Key 存储类型 spring.rabbitmq.ssl.trust-store= # Trust 存储路径 spring.rabbitmq.ssl.trust-store-password= # 用于访问 Trust 的密码 spring.rabbitmq.ssl.trust-store-type=JKS # Trust 存储类型 spring.rabbitmq.ssl.validate-server-certificate=true # 是否启用服务端证书验证 spring.rabbitmq.ssl.verify-hostname=true # 是否启用 hostname 验证 Publisher 配置 spring.rabbitmq.publisher-confirms=false # 是否启用 publisher 确认 spring.rabbitmq.publisher-returns=false # 是否启用 publisher 返回 spring.rabbitmq.template.default-receive-queue= # 没有没确定指定队列时的默认队列 spring.rabbitmq.template.exchange= # 发送消息默认的 exchange spring.rabbitmq.template.mandatory= # 是否启用 mandatory 消息 spring.rabbitmq.template.receive-timeout= # `receive()` 操作的超时时间 spring.rabbitmq.template.reply-timeout= # `sendAndReceive()` 操作的超时时间 spring.rabbitmq.template.retry.enabled=false # 是否启用重试 spring.rabbitmq.template.retry.initial-interval=1000ms # 两次重试间的时间间隔 spring.rabbitmq.template.retry.max-attempts=3 # 最大重试次数 spring.rabbitmq.template.retry.max-interval=10000ms # 最长重试时间 spring.rabbitmq.template.retry.multiplier=1 # Multiplier to apply to the previous retry interval. spring.rabbitmq.template.routing-key= # 发送消息默认的 routing key Consumer 设置 spring.rabbitmq.listener.direct.acknowledge-mode= # 确认模式：auto / manual / none spring.rabbitmq.listener.direct.auto-startup=true # 是否在应用启动时自动启动容器 spring.rabbitmq.listener.direct.consumers-per-queue= # 每个队列的消费者数量 spring.rabbitmq.listener.direct.default-requeue-rejected= # 默认情况下，拒收的消息是否重新排队 spring.rabbitmq.listener.direct.idle-event-interval= # 空闲容器事件发布的频率 spring.rabbitmq.listener.direct.missing-queues-fatal=false # 如果容器声明的队列在 broker 上不可用，是否失败 spring.rabbitmq.listener.direct.prefetch= # 预加载的消息数量 spring.rabbitmq.listener.direct.retry.enabled=false # 是否启用发布重试 spring.rabbitmq.listener.direct.retry.initial-interval=1000ms # 两次重试时间间隔 spring.rabbitmq.listener.direct.retry.max-attempts=3 # 最大重试次数 spring.rabbitmq.listener.direct.retry.max-interval=10000ms # 最长重试时间 spring.rabbitmq.listener.direct.retry.multiplier=1 # 上次重试间隔的倍数 spring.rabbitmq.listener.direct.retry.stateless=true # 重试是否有状态 spring.rabbitmq.listener.simple.acknowledge-mode= # 确认模式：auto / manual / none spring.rabbitmq.listener.simple.auto-startup=true # 是否在应用启动时自动启动容器 spring.rabbitmq.listener.simple.concurrency= # 监听器最小线程数 spring.rabbitmq.listener.simple.default-requeue-rejected= # 默认情况下，拒收的消息是否重新排队 spring.rabbitmq.listener.simple.idle-event-interval= # 空闲容器事件发布的频率 spring.rabbitmq.listener.simple.max-concurrency= # 监听器最大线程数 spring.rabbitmq.listener.simple.missing-queues-fatal=true # 如果容器声明的队列在 broker 上不可用，是否失败； 如果在运行时删除队列，容器是否停止 spring.rabbitmq.listener.simple.prefetch= # 预加载的消息数量 spring.rabbitmq.listener.simple.retry.enabled=false # 是否启用发布重试 spring.rabbitmq.listener.simple.retry.initial-interval=1000ms # 两次重试时间间隔 spring.rabbitmq.listener.simple.retry.max-attempts=3 # 最大重试次数 spring.rabbitmq.listener.simple.retry.max-interval=10000ms # 最长重试时间 spring.rabbitmq.listener.simple.retry.multiplier=1 # 上次重试间隔的倍数 spring.rabbitmq.listener.simple.retry.stateless=true # 重试是否有状态 spring.rabbitmq.listener.simple.transaction-size= # 确认模式为 auto 时，在 acks 之间处理的消息数. 如果大于预加载的数量，则预加载的数量增加到此值 rabbitmq listener 类型有两种：simple 和 direct，二者有什么区别呢？ DirectMessageListenerContainer 注释如下： The {@code SimpleMessageListenerContainer} is not so simple. Recent changes to the rabbitmq java client has facilitated a much simpler listener container that invokes the listener directly on the rabbit client consumer thread. There is no txSize property - each message is acked (or nacked) individually. 其他设置 spring.rabbitmq.dynamic=true # 是否创建 AmqpAdmin bean spring.rabbitmq.requested-heartbeat= # 请求心跳超时时间. 设置为 0 代表没有，如果未指定时间后缀，则默认使用秒 Spring Boot RabbitMQ 队列属性详解 属性名称 属性说明 Durable 代表该队列是否持久化至硬盘（若要使队列中消息不丢失，同时也需要将消息声明为持久化 Exclusive 是否声明该队列是否为连接独占，若为独占，连接关闭后队列即被删除 Auto-delete 若没有消费者订阅该队列，队列将被删除 Arguments 可选map类型参数，可以指定队列长度，消息生存时间，镜相设置等 RabbitMQ规定，队列的名字最长不超过UTF-8编码的255字节 RabbitMQ内部的Queue命名规则采用 &quot;amq.&quot;形式，注意不要与此规则冲突 常见问题 1. 声明了一个已经存在的队列？ 如果队列已经存在，再次声明将不会起作用。若原始队列参数和该次声明时不同则会报异常。 2. 队列中消息顺序？ 默认情况下是FIFO，即先进先出，同时也支持发送消息时指定消息的优先级。 3. 队列消息存放位置？ 对于临时消息，RabbitMQ尽量将其存放在内存，当出现内存告警时，MQ会将消息持久化至硬盘。对于持久化消息与Lazy-queues，MQ会先将消息存入硬盘，消费时再取出。 4. 队列中消息的消费？ 默认情况下，MQ会设置消费者的消费确认模式为自动。对于一些重要消息的处理，推荐确认模式改为手动。（nack和reject区别？nack可以一次拒绝多条消息） 5. 队列中消息的消费速度？ 通过Prefetch（通道上最大未确认投递数量）设置消费者每次消费的条数，一般将该值设为1，但他会降低吞吐量。RabbitMQ官网建议的是100-300.（更建议反复试验得到一个表现符合期望的值） 6. 队列中消息状态？ 队列中的消息共有俩种状态，一是准备投递，二是已投递但未确认。队列最大长度？ 声明队列时可以指定最大长度，需要注意的是只限制状态为准备投递的数量，未确认的消息不计算在内。当队列长度超过限制，MQ会根据策略选择丢弃（默认）或者将消息投递进死信队列。 7. 关于死信队列？ 其实更准确的说法是死信交换机，提前声明一个交换机，在声明队列时使用“x-dead-letter-exchange”参数（可指定routKey）将队列绑定到该死信交换机。消息有以下情况之一会成为死信：被reject或者nack，消息超过生存时间，队列长度超过限制。 8. 关于不能路由到队列的消息？ 这个和上面一样，其实不算Queue系列而是Exchange。针对消息无法路由到队列的情况MQ提供了Alternate Exchange处理。声明Exchange时添加args.put(“alternate-exchange”,“my-ae”)参数。即当该交换机存在无法路由的消息时，它将消息发布到AE上，AE把消息路由到绑定在他上面的消息。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blog.tgyf.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/categories/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/categories/RabbitMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.tgyf.com/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.tgyf.com/tags/RabbitMQ/"}]},{"title":"Hexo主题pure使用指南","slug":"Blog/Hexo主题pure使用指南","date":"2020-02-23T15:12:34.123Z","updated":"2020-02-23T15:12:34.123Z","comments":true,"path":"2020/02/23/Blog/Hexo主题pure使用指南/","link":"","permalink":"http://blog.tgyf.com/2020/02/23/Blog/Hexo%E4%B8%BB%E9%A2%98pure%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"123预览地址: https://blog.cofess.com项目地址: https://github.com/cofess/hexo-theme-pure中文使用文档: https://github.com/cofess/hexo-theme-pure/blob/master/README.cn.md 使用前请操作 使用该主题前, 请先复制 theme/pure/_source/ 目录下的所有内容到 blog path/source/ 目录下 原因在于该目录下有建好的菜单 categories(分类)、tags(标签)、repository(项目)、books(书单)、links(友链)、about(关于)页面 当你使用自动生成分类、标签，展示github项目时 文章目录索引 在文章详情页, 展示一个文章目录 主题配置文件中开启配置: 12config toc: true # 是否开启文章章节目录导航 在文章顶部将该文章开启索引, 如: 12345678910111213---title: Hexo主题pure使用指南date: 2019-11-05 14:34:15tags: - hexo主题categories:- hexotoc: true # 是否启用内容索引sidebar: none # 是否启用sidebar侧边栏，none：不启用--- 侧边栏 主题配置项中, 侧边栏可以如下配置: 123456789101112131415# 侧边栏sidebar: right# 侧边栏启用哪些模块widgets: - board # 公告 - category # 分类 - tag # 标签 - tagcloud # 标签云 - archive # 归档 - recent_posts # 最近文章# 归档列表的展示方式archive_type: 'monthly' # 归档方式: yearly | monthlyshow_count: true # 显示每个归档的文章总数 图集 在文章详情页中, 涉及的图片可以使用图集功能, 在点击一张图片时, 放大图片. 主题的图册公告是使用fancybox实现, 可以参照github 1234# Fancybox# 图集功能fancybox: true 展示github项目 在左侧菜单项目中, 点击展示自己的github项目 在主题配置文件中 _config.yml 修改, 请配置自己github用户名 123github: username: caoruiy # github用户名 新建repository页面: 12&gt; hexo new repository 你也可以直接复制 theme/pure/_source/ 目录下 repository文件夹 到 博客根目录/source/ 目录下 将文件内容修改为: 1234567---title: Repositorieslayout: repositorycomments: falsesidebar: none--- 关键内容为 layout: repository, 包含该属性才可以展示github项目 评论功能 主题集成了disqus、友言、来必力、gitment、gitalk评论系统，选择其中一种即可 你可以在主题配置文件中修改评论工具 123comment: type: valine # 启用哪种评论系统 Valine 一个无后端的评论框工具, 其依赖于 Leancloud 开发, 所以使用前需要先注册 Leancloud 账号 如何开始? 你可以从 Valine-快速开始 教程开始, 教程包含了一步一步的指引教程. Valine配置项 主题valine评论框提供了以下配置项 1234567891011121314valine: # Valine官方地址: https://valine.js.org appid: # 你的 leancloud 应用 appid appkey: # 你的 leancloud 应用 appkey notify: true # 是否开始评论邮件提醒, 教程: https://github.com/xCss/Valine/wiki verify: false # 是否开始验证码功能, 开始邮件提醒会自动开启验证码功能 placeholder: 说点什么... # 输入框默认内容 avatar: mm # 头像展示方式, 具体设置项教程: https://valine.js.org/configuration.html#avatar meta: nick,mail,link # 自定义评论信息 pageSize: 10 # 评论列表分页 lang: zh-cn, # 多语言支持 zh-cn | en visitor: true # 文章阅读量统计: https://valine.js.org/visitor.html highlight: true # 代码高亮 recordIP: true # 记录评论者的IP 关于邮件提醒: 只有在回复评论时, 并且填写了邮箱的评论才会收到回复提醒 关于文章阅读量统计: 开启阅读量统计, 会在详情页标题下展示阅读量数据 搜索功能 主题提供内置的搜索功能和百度搜索, 百度搜索就是使用百度的SEO搜索, 个人觉得不是很实用, 不建议开启. 在主题配置文件 _config.yml 中配置: 12345# Searchsearch: insight: true # 在使用搜索功能前, 你需要安装 `hexo-generator-json-content` baidu: false # 使用百度搜索前, 你必须禁用其他所有的搜索功能 内置搜索 使用搜索功能前需要先安装: 12npm i -S hexo-generator-json-content 项目地址: https://github.com/alexbruno/hexo-generator-json-content 在你运行 hexo g 或者 hexo s 时生效，在 hexo g 生成站点时, 会在根目录下生成 content.json 该文件内容即为搜索内容。 你可以对搜索内容进行自定义的配置， 只要在 _config.yml 中配置 jsonContent即可: 1234567891011121314151617181920# 示例: 隐藏分类和标签的搜索jsonContent: dateFormat: DD/MM/YYYY posts: title: true date: true path: true text: true raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: false author: false 文章阅读数量统计 主题提供 不蒜子 和 基于 leancloud 的统计 但是经过验证, 发现基于leancloud的统计不生效, 不知原因, 实现等效的方法就是: 评论框使用valine评论框(主题已经内置), 同时开启 visitor: true 配置项项即可 字数统计&amp;阅读时长 主题内置了该功能, 使用前需要先安装插件: 12npm i -S hexo-wordcount 主题配置文件中, 开启设置即可: 123456# wordcountpostCount: enable: true wordcount: true # 文章字数统计 min2read: true # 阅读时长预计 友情链接 复制 theme/pure/_source/ 目录下 links文件夹 到 blog path/source/ 目录下 在 hexo 目录下的 source 文件夹内创建一个名为 _data（禁止改名）的文件夹。 然后在文件内创建一个名为 links.yml 的文件,在其中添加相关数据即可。 单个友情链接的格式为： 12345Name: link: http://example.com avatar: http://example.com/avatar.png desc: \"这是一个描述\" 添加多个友情链接，我们只需要根据上面的格式重复填写即可。 将 Name 改为友情链接的名字，例如 Cofess。 http://example.com 为友情链接的地址。 http://example.com/avatar.png 为友情链接的头像。 这是一个描述 为友情链接描述。","categories":[{"name":"应用部署","slug":"应用部署","permalink":"http://blog.tgyf.com/categories/%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://blog.tgyf.com/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"搭建个人博客hexo详细步骤","slug":"Blog/搭建个人博客hexo详细步骤","date":"2020-02-23T14:44:47.683Z","updated":"2020-02-23T14:44:47.683Z","comments":true,"path":"2020/02/23/Blog/搭建个人博客hexo详细步骤/","link":"","permalink":"http://blog.tgyf.com/2020/02/23/Blog/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hexo%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start 第一步：下载安装Git与node.js Git下载地址 node.js下载地址 第二步：安装hexo 1$ npm install -g hexo 这里如果地址被“墙”，可以参考这篇文章的“安装Hexo”部分 第三步：初始化Hexo 创建文件夹（我的是在F盘创建的Hexo） 在Hexo文件夹下，右键运行Git Bash，输入命令：hexo init 在_config.yml,进行基础配置 第四步：本地部署博客 分别输入 如下命令： 12hexo ghexo s 更多hexo常用命令","categories":[{"name":"应用部署","slug":"应用部署","permalink":"http://blog.tgyf.com/categories/%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://blog.tgyf.com/tags/%E5%8D%9A%E5%AE%A2/"}]}]}